{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7UmKcn1-Jfdw"
      },
      "source": [
        "# **Traitement des Données**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SpGiHXpqJoaR"
      },
      "source": [
        "## **Filtrage des Commentaires Négatifs**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0nw02wdxkHn_",
        "outputId": "2b58d721-0377-4ade-dd36-9fb2b0053de8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TO9cGoUQkXBC"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Path to kaggle CSV file\n",
        "file_path = '/content/drive/My Drive/AI_project_dataset/Reviews.csv'\n",
        "\n",
        "# Load the dataset\n",
        "reviews_df = pd.read_csv(file_path, engine='python')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "avM03buNAIEW",
        "outputId": "71b5bdcc-bc5e-4d72-a2b6-c58dc8858b82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "            UserId   ProductId  Score                               Summary  \\\n",
            "1   A1D87F6ZCVE5NK  B00813GRG4      1                     Not as Advertised   \n",
            "3   A395BORC6FGVXV  B000UA0QIQ      2                        Cough Medicine   \n",
            "12   A327PCT23YH90  B0009XLVG0      1  My Cats Are Not Fans of the New Food   \n",
            "16  A3KLWF6WQ5BNYO  B001GVISJM      2                            poor taste   \n",
            "26  A3RXAU2N8KV45G  B001GVISJM      1                       Nasty No flavor   \n",
            "\n",
            "                                                 Text  \n",
            "1   Product arrived labeled as Jumbo Salted Peanut...  \n",
            "3   If you are looking for the secret ingredient i...  \n",
            "12  My cats have been happily eating Felidae Plati...  \n",
            "16  I love eating them and they are good for watch...  \n",
            "26  The candy is just red , No flavor . Just  plan...  \n",
            "We have found 82037 negative reviews over 568454 total reviews\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Keep only interesting columns\n",
        "reviews_df = reviews_df[['UserId', 'ProductId', 'Score', 'Summary', 'Text']]\n",
        "\n",
        "# Keep scores between 1 and 2 stars\n",
        "negative_reviews = reviews_df[reviews_df['Score'] <= 2]\n",
        "print(negative_reviews.head())\n",
        "print(\"We have found\",len(negative_reviews), \"negative reviews over\", len(reviews_df), \"total reviews\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYBl0y6wtWC5"
      },
      "source": [
        "## **Get only first 5 rows**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_bPtKN0WBfgS"
      },
      "outputs": [],
      "source": [
        "#negative_reviews = negative_reviews.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UNMWISbu9TN"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLUxEWVVJ58b"
      },
      "source": [
        "## **Cleaning the text**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "fBYVKFaZCQ_y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57cb139c-84d1-46e7-bbea-c2fa135dd0b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "import spacy\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Download stopwords (à faire une seule fois)\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Initialize spaCy model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "# Cleaning text function\n",
        "def clean_text(text):\n",
        "    text = text.lower()  # Convertir en minuscule\n",
        "    text = re.sub(r'\\d+', '', text)  # Retirer les chiffres\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  # Retirer les ponctuations\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()  # Retirer les espaces multiples\n",
        "    # Process the text with spaCy\n",
        "    doc = nlp(text)\n",
        "    #print(\"doc\", doc)\n",
        "    # Extract lemmas and return as a single string\n",
        "    text = \" \".join([token.lemma_ for token in doc])\n",
        "    #print(\"lemmatized_text\", text)\n",
        "    return text\n",
        "\n",
        "#negative_reviews['lemmatized_text'] = negative_reviews['Text'].apply(clean_text)\n",
        "#negative_reviews['Cleaned_Summary'] = negative_reviews['Summary'].apply(clean_text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "js5JlvBxKFU5"
      },
      "source": [
        "## **Tokenization**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19MeSDWIG4sK",
        "outputId": "27198d10-9bb1-4637-aba9-fc5207e6d029"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-30-a1fcfb76bb86>:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  negative_reviews['Tokens'] = negative_reviews['lemmatized_text'].apply(word_tokenize)\n"
          ]
        }
      ],
      "source": [
        "# Tokenization\n",
        "negative_reviews['Tokens'] = negative_reviews['lemmatized_text'].apply(word_tokenize)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_dxkEd9hHypT",
        "outputId": "07879a4b-31e4-4c30-8154-fb8252dc39a6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1         [product, arrive, label, as, jumbo, salt, pean...\n",
              "3         [if, you, be, look, for, the, secret, ingredie...\n",
              "12        [my, cat, have, be, happily, eat, felidae, pla...\n",
              "16        [I, love, eat, they, and, they, be, good, for,...\n",
              "26        [the, candy, be, just, red, no, flavor, just, ...\n",
              "                                ...                        \n",
              "568433    [I, just, buy, this, soup, today, at, my, loca...\n",
              "568434    [this, soup, be, mostly, broth, although, it, ...\n",
              "568435    [it, be, mostly, broth, with, the, advertised,...\n",
              "568446    [I, have, order, some, of, these, a, few, mont...\n",
              "568450    [I, m, disappointed, with, the, flavor, the, c...\n",
              "Name: Tokens, Length: 82037, dtype: object"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "negative_reviews['Tokens']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7B4qUbCEKKm8"
      },
      "source": [
        "## **Delete Stop Words**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OnC98BGQF50d",
        "outputId": "0edd6ffc-55b0-4487-fa6d-8a9a55054c7a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-34-e1ed51d99cd2>:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  negative_reviews['Tokens'] = negative_reviews['Tokens'].apply(lambda x: [word for word in x if word not in stop_words])\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Retirer les mots vides (stopwords)\n",
        "stop_words = set(stopwords.words('english'))  # Utiliser 'french' pour le français\n",
        "negative_reviews['Tokens'] = negative_reviews['Tokens'].apply(lambda x: [word for word in x if word not in stop_words])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZxWodY6-H5Li",
        "outputId": "7a5f7492-484b-4041-9da3-ecdf191acb10"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1         [product, arrive, label, jumbo, salt, peanutst...\n",
              "3         [look, secret, ingredient, robitussin, I, beli...\n",
              "12        [cat, happily, eat, felidae, platinum, two, ye...\n",
              "16        [I, love, eat, good, watch, tv, look, movie, s...\n",
              "26        [candy, red, flavor, plan, chewy, I, would, ne...\n",
              "                                ...                        \n",
              "568433    [I, buy, soup, today, local, grocer, bring, ba...\n",
              "568434    [soup, mostly, broth, although, kick, also, sw...\n",
              "568435    [mostly, broth, advertised, cup, vegetable, ho...\n",
              "568446    [I, order, month, back, great, late, batch, te...\n",
              "568450    [I, disappointed, flavor, chocolate, note, esp...\n",
              "Name: Tokens, Length: 82037, dtype: object"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "negative_reviews['Tokens']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xt5iq8tWKTLd"
      },
      "source": [
        "## **Remove duplicates**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQlOen9CC8vk",
        "outputId": "5b5e88ce-1153-44fe-8d5e-b174139fbe7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UserId              0\n",
            "ProductId           0\n",
            "Score               0\n",
            "Summary            25\n",
            "Text                0\n",
            "lemmatized_text     0\n",
            "Tokens              0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Check missing data\n",
        "print(negative_reviews.isnull().sum())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3p9eCNl5F9L8",
        "outputId": "217d2b38-5401-4c76-9357-8104f9f396f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of duplicate rows: 347\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Check duplicates\n",
        "duplicate_rows = negative_reviews[negative_reviews.duplicated(subset=['lemmatized_text','ProductId'])]\n",
        "print(f\"Number of duplicate rows: {duplicate_rows.shape[0]}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAPNT9-tIDcw",
        "outputId": "d2c8ceee-c445-4e08-b40b-0b21ec349f24"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                UserId   ProductId  Score  \\\n",
            "2647    A2NLZ3M0OJV9NX  B0016FY6H6      2   \n",
            "2946    A2ISKAWUPGGOLZ  B0002TJAZK      1   \n",
            "2947    A3TVZM3ZIXG8YW  B0002TJAZK      1   \n",
            "5929     A3L27V7TOG1JZ  B001O2IX8E      1   \n",
            "5958    A3KDZCQ82JFWLN  B001O2IX8E      1   \n",
            "...                ...         ...    ...   \n",
            "539358   AF3BYMPWKWO8F  B001BDDT8K      1   \n",
            "539359   AF3BYMPWKWO8F  B001BDDT8K      1   \n",
            "555968  A1RR835I8VF0VV  B005DGIAUI      1   \n",
            "558042  A2RNYW2HIQBGSM  B000EM9E2Y      1   \n",
            "561051  A2NLZ3M0OJV9NX  B0012BSMHY      2   \n",
            "\n",
            "                                                  Summary  \\\n",
            "2647                           way too weak for my tastes   \n",
            "2946                                      Kitty Junk Food   \n",
            "2947    Filler food is empty, leaves your cat always n...   \n",
            "5929            careful, moldy product, USDA now involved   \n",
            "5958                                     Some broken jars   \n",
            "...                                                   ...   \n",
            "539358                        Warning: Contains Menadione   \n",
            "539359                        Warning: Contains Menadione   \n",
            "555968                                       It's hollow!   \n",
            "558042                    Inedible, gave them to the dogs   \n",
            "561051                         way too weak for my tastes   \n",
            "\n",
            "                                                     Text  \\\n",
            "2647    What can i say, I love iced tea. I drink a lot...   \n",
            "2946    We have five cats - one an elderly cat of 15 y...   \n",
            "2947    This review will make me sound really stupid, ...   \n",
            "5929    My baby enjoyed this flavor when I purchased i...   \n",
            "5958    When I saw some of the Earth's Best jars offer...   \n",
            "...                                                   ...   \n",
            "539358  According to the manufacturer's website, this ...   \n",
            "539359  According to the manufacturer's website, this ...   \n",
            "555968  My dogs are 55lbs and 25lbs, within a few days...   \n",
            "558042  These are just awful.  I love all kinds of toa...   \n",
            "561051  What can i say, I love iced tea. I drink a lot...   \n",
            "\n",
            "                                          lemmatized_text  \\\n",
            "2647    what can I say I love ice tea I drink a lot of...   \n",
            "2946    we have five cat one an elderly cat of year th...   \n",
            "2947    this review will make I sound really stupid bu...   \n",
            "5929    my baby enjoy this flavor when I purchase it a...   \n",
            "5958    when I see some of the earth good jar offer as...   \n",
            "...                                                   ...   \n",
            "539358  accord to the manufacturer website this and ma...   \n",
            "539359  accord to the manufacturer website this and ma...   \n",
            "555968  my dog be lbs and lbs within a few day they ch...   \n",
            "558042  these be just awful I love all kind of toast c...   \n",
            "561051  what can I say I love ice tea I drink a lot of...   \n",
            "\n",
            "                                                   Tokens  \n",
            "2647    [I, say, I, love, ice, tea, I, drink, lot, lov...  \n",
            "2946    [five, cat, one, elderly, cat, year, four, yea...  \n",
            "2947    [review, make, I, sound, really, stupid, whate...  \n",
            "5929    [baby, enjoy, flavor, I, purchase, store, I, o...  \n",
            "5958    [I, see, earth, good, jar, offer, gold, box, d...  \n",
            "...                                                   ...  \n",
            "539358  [accord, manufacturer, website, many, product,...  \n",
            "539359  [accord, manufacturer, website, many, product,...  \n",
            "555968  [dog, lbs, lbs, within, day, chew, bone, start...  \n",
            "558042  [awful, I, love, kind, toast, cheese, simply, ...  \n",
            "561051  [I, say, I, love, ice, tea, I, drink, lot, lov...  \n",
            "\n",
            "[347 rows x 7 columns]\n",
            "Number of rows after removing duplicates: 56968\n"
          ]
        }
      ],
      "source": [
        "# Delete duplicates\n",
        "negative_reviews = negative_reviews.drop_duplicates(subset=['lemmatized_text'])\n",
        "if duplicate_rows.shape[0] == 0:\n",
        "  print(\"No duplicates where found\")\n",
        "else:\n",
        "  print(f\"Number of rows after removing duplicates: {negative_reviews.shape[0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JINM-go0fhgy"
      },
      "source": [
        "\n",
        "## **Save csv**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "id": "Kv6zfrkKlM_G",
        "outputId": "b563ca59-78d5-4d10-9c9c-70ba0437fff7"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'negative_reviews' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-8ee8857b2b8f>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Assume 'negative_reviews' is your DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/My Drive/AI_project_dataset/negative_reviews.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnegative_reviews\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'negative_reviews' is not defined"
          ]
        }
      ],
      "source": [
        "# Assume 'negative_reviews' is your DataFrame\n",
        "file_path = '/content/drive/My Drive/AI_project/dataset/negative_reviews.csv'\n",
        "negative_reviews.to_csv(file_path, index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Os5nM01J9Jtp"
      },
      "source": [
        "##**Load data precleaned**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unwN4UM5ZCMh",
        "outputId": "f9a11084-59d2-427c-bf10-ff7c88baca39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Path to your CSV file\n",
        "file_path = '/content/drive/My Drive/AI_project/dataset/negative_reviews.csv'\n",
        "\n",
        "# Load the dataset\n",
        "clean_df = pd.read_csv(file_path, engine='python')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4GI2JkOma9w"
      },
      "source": [
        "## **Label data using GPT3**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "kpCAGbmBYLdr",
        "outputId": "37dce4be-83ba-4eb6-c6fb-0e48cee86bf9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (0.28.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.9.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2024.6.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VdSKlCSWgeRS",
        "outputId": "f1c905df-0b4f-4708-97e1-8ac7ad2f3c52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2000"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# Path to your CSV file\n",
        "file_path = '/content/drive/My Drive/AI_project/dataset/negative_reviews_topics.csv'\n",
        "# Load the dataset\n",
        "clean_df = pd.read_csv(file_path, engine='python')\n",
        "clean_df\n",
        "df=clean_df.head(2000)\n",
        "#df=clean_df\n",
        "len(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vfPt8wIheKbt",
        "outputId": "d1e6a868-9dbc-47fa-da86-437b4b838feb"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 1/2000 [00:00<22:36,  1.47it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 2/2000 [00:01<27:17,  1.22it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 2, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 3/2000 [00:02<22:56,  1.45it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 3, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 4/2000 [00:03<25:47,  1.29it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 4, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 5/2000 [00:03<25:04,  1.33it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 5, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 6/2000 [00:04<20:43,  1.60it/s]INFO:backoff:Backing off get_labels_batch(...) for 1.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9804, Requested 264. Please try again in 408ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 6, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 7/2000 [00:05<33:49,  1.02s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9768, Requested 360. Please try again in 768ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 7, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 8/2000 [00:08<51:13,  1.54s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9678, Requested 656. Please try again in 2.004s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 8, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9630, Requested 656. Please try again in 1.716s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 3.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9486, Requested 656. Please try again in 852ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "  0%|          | 9/2000 [00:13<1:24:57,  2.56s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 9, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 10/2000 [00:14<1:07:07,  2.02s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 10, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 11/2000 [00:14<52:51,  1.59s/it]  INFO:backoff:Backing off get_labels_batch(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9779, Requested 291. Please try again in 420ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 11, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9733, Requested 291. Please try again in 144ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "  1%|          | 12/2000 [00:19<1:23:19,  2.52s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 12, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 13/2000 [00:20<1:06:29,  2.01s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 13, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 14/2000 [00:20<50:46,  1.53s/it]  INFO:backoff:Backing off get_labels_batch(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9685, Requested 451. Please try again in 816ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 14, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9656, Requested 451. Please try again in 642ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "  1%|          | 15/2000 [00:22<51:28,  1.56s/it]INFO:backoff:Backing off get_labels_batch(...) for 2.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9841, Requested 294. Please try again in 810ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 15, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 16/2000 [00:24<1:00:29,  1.83s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9727, Requested 309. Please try again in 216ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 16, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 17/2000 [00:25<52:31,  1.59s/it]  INFO:backoff:Backing off get_labels_batch(...) for 1.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9867, Requested 344. Please try again in 1.266s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 17, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 18/2000 [00:28<58:54,  1.78s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9835, Requested 296. Please try again in 786ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 18, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 19/2000 [00:30<1:00:51,  1.84s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9796, Requested 333. Please try again in 774ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 19, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 20/2000 [00:32<1:04:12,  1.95s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9752, Requested 376. Please try again in 768ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 20, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 21/2000 [00:34<1:02:38,  1.90s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9823, Requested 306. Please try again in 774ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 21, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 22/2000 [00:36<1:09:04,  2.10s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9705, Requested 683. Please try again in 2.328s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 2.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9688, Requested 683. Please try again in 2.226s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 22, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 6.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9330, Requested 683. Please try again in 78ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "  1%|          | 23/2000 [00:46<2:25:15,  4.41s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 23, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 24/2000 [00:46<1:46:44,  3.24s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 24, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|▏         | 25/2000 [00:47<1:20:16,  2.44s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 25, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|▏         | 26/2000 [00:48<1:04:23,  1.96s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 26, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|▏         | 27/2000 [00:48<50:27,  1.53s/it]  "
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 27, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|▏         | 28/2000 [00:49<42:00,  1.28s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9770, Requested 425. Please try again in 1.17s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 28, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|▏         | 29/2000 [00:52<56:12,  1.71s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9724, Requested 280. Please try again in 24ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 29, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 30/2000 [00:54<1:00:51,  1.85s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 30, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 31/2000 [00:55<48:11,  1.47s/it]  INFO:backoff:Backing off get_labels_batch(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9832, Requested 554. Please try again in 2.316s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 31, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9726, Requested 554. Please try again in 1.68s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "  2%|▏         | 32/2000 [00:58<1:09:29,  2.12s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9734, Requested 413. Please try again in 882ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 32, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 33/2000 [01:00<1:09:16,  2.11s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9768, Requested 401. Please try again in 1.013s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 33, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 34/2000 [01:03<1:16:50,  2.34s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9669, Requested 424. Please try again in 558ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 3.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9652, Requested 424. Please try again in 456ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 34, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 35/2000 [01:08<1:37:02,  2.96s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 35, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 36/2000 [01:08<1:15:36,  2.31s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 36, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 37/2000 [01:09<59:26,  1.82s/it]  INFO:backoff:Backing off get_labels_batch(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9815, Requested 311. Please try again in 756ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 37, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9767, Requested 311. Please try again in 468ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "  2%|▏         | 38/2000 [01:12<1:14:28,  2.28s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 38, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 39/2000 [01:13<57:28,  1.76s/it]  INFO:backoff:Backing off get_labels_batch(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9762, Requested 268. Please try again in 180ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 39, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 40/2000 [01:15<56:39,  1.73s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9753, Requested 282. Please try again in 210ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 40, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 41/2000 [01:17<1:03:18,  1.94s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 41, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 42/2000 [01:18<52:53,  1.62s/it]  INFO:backoff:Backing off get_labels_batch(...) for 0.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9796, Requested 295. Please try again in 546ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 2.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9780, Requested 295. Please try again in 450ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 42, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 43/2000 [01:22<1:13:03,  2.24s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 43, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 44/2000 [01:22<57:37,  1.77s/it]  "
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 44, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 45/2000 [01:23<45:58,  1.41s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9844, Requested 303. Please try again in 882ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 45, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 46/2000 [01:25<54:02,  1.66s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9775, Requested 282. Please try again in 342ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 46, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 47/2000 [01:27<54:08,  1.66s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9785, Requested 297. Please try again in 492ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 47, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 48/2000 [01:29<58:19,  1.79s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9734, Requested 281. Please try again in 90ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 48, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 49/2000 [01:30<49:31,  1.52s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9869, Requested 351. Please try again in 1.32s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 49, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▎         | 50/2000 [01:33<1:02:30,  1.92s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9739, Requested 340. Please try again in 474ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 50, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  3%|▎         | 51/2000 [01:34<1:00:31,  1.86s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9789, Requested 309. Please try again in 588ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 51, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  3%|▎         | 52/2000 [01:37<1:09:19,  2.14s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 52, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  3%|▎         | 53/2000 [01:38<55:00,  1.70s/it]  INFO:backoff:Backing off get_labels_batch(...) for 1.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9803, Requested 329. Please try again in 792ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 53, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  3%|▎         | 54/2000 [01:40<55:53,  1.72s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9822, Requested 281. Please try again in 618ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 2.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9808, Requested 281. Please try again in 534ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 54, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  3%|▎         | 55/2000 [01:43<1:08:35,  2.12s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 55, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  3%|▎         | 56/2000 [01:43<51:51,  1.60s/it]  INFO:backoff:Backing off get_labels_batch(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9864, Requested 477. Please try again in 2.046s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 56, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9578, Requested 477. Please try again in 330ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 7.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9536, Requested 477. Please try again in 78ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "  3%|▎         | 57/2000 [01:54<2:19:09,  4.30s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 57, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  3%|▎         | 58/2000 [01:54<1:44:56,  3.24s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 58, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  3%|▎         | 59/2000 [01:55<1:22:04,  2.54s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 59, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  3%|▎         | 60/2000 [01:56<1:02:44,  1.94s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9082, Requested 921. Please try again in 18ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 60, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  3%|▎         | 61/2000 [01:57<52:46,  1.63s/it]  INFO:backoff:Backing off get_labels_batch(...) for 1.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9737, Requested 412. Please try again in 894ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 61, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  3%|▎         | 62/2000 [01:59<59:45,  1.85s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9745, Requested 313. Please try again in 348ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 62, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  3%|▎         | 63/2000 [02:01<57:00,  1.77s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9789, Requested 281. Please try again in 420ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 63, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  3%|▎         | 64/2000 [02:02<52:09,  1.62s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9860, Requested 352. Please try again in 1.272s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 64, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9692, Requested 352. Please try again in 264ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "  3%|▎         | 65/2000 [02:07<1:30:25,  2.80s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 65, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  3%|▎         | 66/2000 [02:08<1:12:11,  2.24s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 66, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  3%|▎         | 67/2000 [02:09<55:12,  1.71s/it]  "
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 67, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  3%|▎         | 68/2000 [02:09<42:48,  1.33s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9903, Requested 408. Please try again in 1.866s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 68, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9714, Requested 408. Please try again in 732ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "  3%|▎         | 69/2000 [02:15<1:27:36,  2.72s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 69, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  4%|▎         | 70/2000 [02:16<1:05:31,  2.04s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 70, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  4%|▎         | 71/2000 [02:17<56:35,  1.76s/it]  INFO:backoff:Backing off get_labels_batch(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9715, Requested 330. Please try again in 270ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 71, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  4%|▎         | 72/2000 [02:19<1:02:11,  1.94s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 72, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  4%|▎         | 73/2000 [02:20<49:17,  1.53s/it]  INFO:backoff:Backing off get_labels_batch(...) for 1.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9885, Requested 438. Please try again in 1.938s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 73, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9569, Requested 438. Please try again in 42ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "  4%|▎         | 74/2000 [02:25<1:28:42,  2.76s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 74, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  4%|▍         | 75/2000 [02:26<1:07:08,  2.09s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 75, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  4%|▍         | 76/2000 [02:26<51:02,  1.59s/it]  INFO:backoff:Backing off get_labels_batch(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9802, Requested 288. Please try again in 540ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 76, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9759, Requested 288. Please try again in 282ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "  4%|▍         | 77/2000 [02:28<48:58,  1.53s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9869, Requested 284. Please try again in 918ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 77, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  4%|▍         | 78/2000 [02:30<52:24,  1.64s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9843, Requested 280. Please try again in 738ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 78, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  4%|▍         | 79/2000 [02:32<1:01:33,  1.92s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9690, Requested 490. Please try again in 1.08s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 79, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9645, Requested 490. Please try again in 810ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "  4%|▍         | 80/2000 [02:36<1:19:54,  2.50s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 80, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  4%|▍         | 81/2000 [02:37<1:02:27,  1.95s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9754, Requested 440. Please try again in 1.164s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 81, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  4%|▍         | 82/2000 [02:39<1:04:48,  2.03s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9806, Requested 379. Please try again in 1.11s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 82, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9731, Requested 379. Please try again in 660ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "  4%|▍         | 83/2000 [02:43<1:20:44,  2.53s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 83, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  4%|▍         | 84/2000 [02:43<1:02:03,  1.94s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9814, Requested 336. Please try again in 900ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 84, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  4%|▍         | 85/2000 [02:45<1:04:29,  2.02s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9780, Requested 300. Please try again in 480ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 85, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  4%|▍         | 86/2000 [02:47<58:51,  1.84s/it]  INFO:backoff:Backing off get_labels_batch(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9839, Requested 404. Please try again in 1.458s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 86, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9814, Requested 404. Please try again in 1.308s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "  4%|▍         | 87/2000 [02:50<1:08:51,  2.16s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9752, Requested 541. Please try again in 1.758s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 2.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9733, Requested 541. Please try again in 1.644s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 87, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  4%|▍         | 88/2000 [02:53<1:19:35,  2.50s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9694, Requested 330. Please try again in 144ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 88, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  4%|▍         | 89/2000 [02:56<1:20:17,  2.52s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9596, Requested 418. Please try again in 84ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 89, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  4%|▍         | 90/2000 [02:56<1:04:07,  2.01s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9862, Requested 315. Please try again in 1.062s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 90, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9739, Requested 315. Please try again in 324ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 5.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9689, Requested 315. Please try again in 24ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "  5%|▍         | 91/2000 [03:03<1:47:43,  3.39s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 91, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  5%|▍         | 92/2000 [03:04<1:23:22,  2.62s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 92, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  5%|▍         | 93/2000 [03:05<1:06:42,  2.10s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 93, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  5%|▍         | 94/2000 [03:05<51:58,  1.64s/it]  "
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 94, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  5%|▍         | 95/2000 [03:06<41:46,  1.32s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9902, Requested 392. Please try again in 1.764s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 95, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9740, Requested 392. Please try again in 792ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "  5%|▍         | 96/2000 [03:10<1:08:00,  2.14s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 96, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  5%|▍         | 97/2000 [03:11<55:54,  1.76s/it]  INFO:backoff:Backing off get_labels_batch(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9783, Requested 486. Please try again in 1.614s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 97, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9614, Requested 486. Please try again in 600ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 4.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9558, Requested 486. Please try again in 264ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "  5%|▍         | 98/2000 [03:18<1:43:26,  3.26s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 98, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  5%|▍         | 99/2000 [03:18<1:17:17,  2.44s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 99, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  5%|▌         | 100/2000 [03:19<1:00:19,  1.91s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 100, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  5%|▌         | 101/2000 [03:20<50:43,  1.60s/it]  INFO:backoff:Backing off get_labels_batch(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9793, Requested 312. Please try again in 630ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 101, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  5%|▌         | 102/2000 [03:21<48:55,  1.55s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9875, Requested 406. Please try again in 1.686s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 102, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  5%|▌         | 103/2000 [03:24<58:02,  1.84s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9855, Requested 461. Please try again in 1.896s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 103, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9562, Requested 461. Please try again in 138ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "  5%|▌         | 104/2000 [03:28<1:18:27,  2.48s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9626, Requested 417. Please try again in 258ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 104, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  5%|▌         | 105/2000 [03:29<1:10:51,  2.24s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9749, Requested 274. Please try again in 138ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 105, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  5%|▌         | 106/2000 [03:31<1:10:53,  2.25s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 106, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  5%|▌         | 107/2000 [03:32<58:22,  1.85s/it]  INFO:backoff:Backing off get_labels_batch(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9799, Requested 274. Please try again in 438ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 107, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  5%|▌         | 108/2000 [03:35<1:01:03,  1.94s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 108, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  5%|▌         | 109/2000 [03:35<49:11,  1.56s/it]  INFO:backoff:Backing off get_labels_batch(...) for 1.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9887, Requested 275. Please try again in 972ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 109, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  6%|▌         | 110/2000 [03:38<57:34,  1.83s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9757, Requested 284. Please try again in 246ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 110, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  6%|▌         | 111/2000 [03:39<51:55,  1.65s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9834, Requested 571. Please try again in 2.43s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 111, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9574, Requested 571. Please try again in 870ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "  6%|▌         | 112/2000 [03:42<1:09:29,  2.21s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9788, Requested 280. Please try again in 408ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 112, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9767, Requested 280. Please try again in 282ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "  6%|▌         | 113/2000 [03:45<1:16:47,  2.44s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 113, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  6%|▌         | 114/2000 [03:46<58:54,  1.87s/it]  INFO:backoff:Backing off get_labels_batch(...) for 1.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9818, Requested 343. Please try again in 966ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 114, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  6%|▌         | 115/2000 [03:48<1:03:41,  2.03s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9766, Requested 407. Please try again in 1.038s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 115, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9617, Requested 407. Please try again in 144ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "  6%|▌         | 116/2000 [03:52<1:22:06,  2.61s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 116, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  6%|▌         | 117/2000 [03:53<1:01:49,  1.97s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9735, Requested 322. Please try again in 342ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 117, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  6%|▌         | 118/2000 [03:55<1:03:49,  2.03s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9686, Requested 367. Please try again in 318ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 118, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  6%|▌         | 119/2000 [03:56<58:33,  1.87s/it]  INFO:backoff:Backing off get_labels_batch(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9787, Requested 302. Please try again in 534ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 119, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 4.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9710, Requested 302. Please try again in 72ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "  6%|▌         | 120/2000 [04:01<1:27:10,  2.78s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 120, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  6%|▌         | 121/2000 [04:02<1:06:48,  2.13s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 121, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  6%|▌         | 122/2000 [04:03<51:44,  1.65s/it]  "
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 122, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  6%|▌         | 123/2000 [04:03<42:07,  1.35s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9855, Requested 584. Please try again in 2.634s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 123, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9666, Requested 584. Please try again in 1.5s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "  6%|▌         | 124/2000 [04:07<1:02:53,  2.01s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9800, Requested 328. Please try again in 768ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 124, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  6%|▋         | 125/2000 [04:09<1:08:28,  2.19s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9682, Requested 490. Please try again in 1.032s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 125, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9639, Requested 490. Please try again in 774ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "  6%|▋         | 126/2000 [04:12<1:09:06,  2.21s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9758, Requested 419. Please try again in 1.062s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 126, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  6%|▋         | 127/2000 [04:14<1:10:57,  2.27s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9756, Requested 351. Please try again in 642ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 127, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  6%|▋         | 128/2000 [04:16<1:08:44,  2.20s/it]INFO:backoff:Backing off get_labels_batch(...) for 2.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9757, Requested 455. Please try again in 1.272s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 128, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  6%|▋         | 129/2000 [04:19<1:14:06,  2.38s/it]INFO:backoff:Backing off get_labels_batch(...) for 2.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9722, Requested 326. Please try again in 288ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 129, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  6%|▋         | 130/2000 [04:22<1:16:52,  2.47s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 130, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  7%|▋         | 131/2000 [04:22<58:41,  1.88s/it]  INFO:backoff:Backing off get_labels_batch(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9847, Requested 282. Please try again in 774ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 131, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9776, Requested 282. Please try again in 348ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "  7%|▋         | 132/2000 [04:25<1:12:31,  2.33s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 132, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  7%|▋         | 133/2000 [04:26<57:02,  1.83s/it]  INFO:backoff:Backing off get_labels_batch(...) for 1.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9832, Requested 316. Please try again in 888ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 133, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  7%|▋         | 134/2000 [04:28<57:22,  1.84s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9836, Requested 286. Please try again in 732ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 134, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  7%|▋         | 135/2000 [04:30<57:47,  1.86s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9813, Requested 360. Please try again in 1.038s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 135, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  7%|▋         | 136/2000 [04:32<57:44,  1.86s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9857, Requested 419. Please try again in 1.656s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 136, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9654, Requested 419. Please try again in 438ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "  7%|▋         | 137/2000 [04:35<1:07:21,  2.17s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9773, Requested 324. Please try again in 582ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 137, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  7%|▋         | 138/2000 [04:37<1:10:59,  2.29s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9667, Requested 450. Please try again in 702ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 138, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  7%|▋         | 139/2000 [04:39<1:08:36,  2.21s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9784, Requested 303. Please try again in 522ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 139, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  7%|▋         | 140/2000 [04:41<1:03:16,  2.04s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9820, Requested 308. Please try again in 768ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 140, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  7%|▋         | 141/2000 [04:42<59:13,  1.91s/it]  INFO:backoff:Backing off get_labels_batch(...) for 1.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9859, Requested 443. Please try again in 1.812s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 141, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9565, Requested 443. Please try again in 48ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "  7%|▋         | 142/2000 [04:49<1:37:47,  3.16s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 142, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  7%|▋         | 143/2000 [04:49<1:16:33,  2.47s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 143, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  7%|▋         | 144/2000 [04:50<1:01:26,  1.99s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9681, Requested 369. Please try again in 300ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 144, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  7%|▋         | 145/2000 [04:51<51:03,  1.65s/it]  INFO:backoff:Backing off get_labels_batch(...) for 1.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9903, Requested 306. Please try again in 1.254s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 145, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  7%|▋         | 146/2000 [04:54<58:04,  1.88s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9815, Requested 289. Please try again in 624ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 146, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  7%|▋         | 147/2000 [04:55<51:19,  1.66s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9914, Requested 717. Please try again in 3.786s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 147, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9729, Requested 717. Please try again in 2.676s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 1.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9706, Requested 717. Please try again in 2.538s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 5.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9497, Requested 717. Please try again in 1.284s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "  7%|▋         | 148/2000 [05:03<1:51:53,  3.63s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 148, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  7%|▋         | 149/2000 [05:04<1:24:03,  2.72s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9411, Requested 593. Please try again in 24ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 149, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  8%|▊         | 150/2000 [05:06<1:20:43,  2.62s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 150, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  8%|▊         | 151/2000 [05:07<1:04:32,  2.09s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 151, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  8%|▊         | 152/2000 [05:08<54:48,  1.78s/it]  INFO:backoff:Backing off get_labels_batch(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9778, Requested 1023. Please try again in 4.806s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 152, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9622, Requested 1023. Please try again in 3.87s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "  8%|▊         | 153/2000 [05:13<1:29:33,  2.91s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9741, Requested 393. Please try again in 804ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 153, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9640, Requested 393. Please try again in 198ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "  8%|▊         | 154/2000 [05:18<1:44:14,  3.39s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 154, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  8%|▊         | 155/2000 [05:18<1:17:11,  2.51s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9617, Requested 836. Please try again in 2.718s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 155, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9537, Requested 836. Please try again in 2.238s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 1.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9419, Requested 836. Please try again in 1.53s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "  8%|▊         | 156/2000 [05:22<1:26:46,  2.82s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9728, Requested 294. Please try again in 132ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 156, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  8%|▊         | 157/2000 [05:25<1:25:54,  2.80s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 157, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  8%|▊         | 158/2000 [05:25<1:06:09,  2.15s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9752, Requested 379. Please try again in 786ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 158, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  8%|▊         | 159/2000 [05:27<1:04:55,  2.12s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9777, Requested 303. Please try again in 480ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 159, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  8%|▊         | 160/2000 [05:29<56:42,  1.85s/it]  INFO:backoff:Backing off get_labels_batch(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9872, Requested 334. Please try again in 1.236s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 160, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9668, Requested 334. Please try again in 12ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "  8%|▊         | 161/2000 [05:33<1:17:20,  2.52s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 161, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  8%|▊         | 162/2000 [05:33<58:45,  1.92s/it]  INFO:backoff:Backing off get_labels_batch(...) for 1.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9748, Requested 412. Please try again in 960ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 162, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  8%|▊         | 163/2000 [05:35<59:38,  1.95s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9818, Requested 326. Please try again in 864ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 163, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  8%|▊         | 164/2000 [05:37<58:40,  1.92s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9836, Requested 319. Please try again in 930ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 164, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  8%|▊         | 165/2000 [05:39<1:03:54,  2.09s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9730, Requested 320. Please try again in 300ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 165, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  8%|▊         | 166/2000 [05:41<58:41,  1.92s/it]  INFO:backoff:Backing off get_labels_batch(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9794, Requested 599. Please try again in 2.358s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 166, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9523, Requested 599. Please try again in 732ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "  8%|▊         | 167/2000 [05:46<1:31:28,  2.99s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 167, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  8%|▊         | 168/2000 [05:47<1:08:36,  2.25s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 168, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  8%|▊         | 169/2000 [05:48<53:47,  1.76s/it]  INFO:backoff:Backing off get_labels_batch(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9824, Requested 284. Please try again in 648ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 169, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  8%|▊         | 170/2000 [05:49<51:30,  1.69s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9862, Requested 295. Please try again in 941ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 170, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9735, Requested 295. Please try again in 180ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "  9%|▊         | 171/2000 [05:52<1:04:29,  2.12s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9641, Requested 411. Please try again in 312ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 171, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  9%|▊         | 172/2000 [05:54<1:00:00,  1.97s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9763, Requested 304. Please try again in 402ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 172, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9708, Requested 304. Please try again in 72ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "  9%|▊         | 173/2000 [05:58<1:15:37,  2.48s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 173, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  9%|▊         | 174/2000 [05:58<56:39,  1.86s/it]  "
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 174, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  9%|▉         | 175/2000 [05:59<47:11,  1.55s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9839, Requested 742. Please try again in 3.486s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 175, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9567, Requested 742. Please try again in 1.854s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 1.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9353, Requested 742. Please try again in 570ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "  9%|▉         | 176/2000 [06:03<1:14:40,  2.46s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9781, Requested 299. Please try again in 480ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 176, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  9%|▉         | 177/2000 [06:06<1:13:36,  2.42s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 177, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  9%|▉         | 178/2000 [06:07<1:04:20,  2.12s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9736, Requested 400. Please try again in 816ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 178, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  9%|▉         | 179/2000 [06:09<1:01:31,  2.03s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9813, Requested 458. Please try again in 1.626s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 179, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9686, Requested 458. Please try again in 864ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "  9%|▉         | 180/2000 [06:14<1:32:39,  3.05s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 180, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  9%|▉         | 181/2000 [06:15<1:08:37,  2.26s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 181, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  9%|▉         | 182/2000 [06:15<51:39,  1.71s/it]  INFO:backoff:Backing off get_labels_batch(...) for 1.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9901, Requested 324. Please try again in 1.35s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 182, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  9%|▉         | 183/2000 [06:18<1:01:42,  2.04s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9746, Requested 302. Please try again in 288ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 183, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  9%|▉         | 184/2000 [06:20<1:04:32,  2.13s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 184, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  9%|▉         | 185/2000 [06:21<50:52,  1.68s/it]  INFO:backoff:Backing off get_labels_batch(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9854, Requested 601. Please try again in 2.73s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 185, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9766, Requested 601. Please try again in 2.202s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 3.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9616, Requested 601. Please try again in 1.302s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "  9%|▉         | 186/2000 [06:26<1:24:43,  2.80s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 186, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  9%|▉         | 187/2000 [06:27<1:05:13,  2.16s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 187, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  9%|▉         | 188/2000 [06:28<50:15,  1.66s/it]  INFO:backoff:Backing off get_labels_batch(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9884, Requested 329. Please try again in 1.278s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 188, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9736, Requested 329. Please try again in 390ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "  9%|▉         | 189/2000 [06:31<1:09:25,  2.30s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9581, Requested 432. Please try again in 78ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 189, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 10%|▉         | 190/2000 [06:33<1:05:59,  2.19s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9674, Requested 329. Please try again in 18ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 190, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 10%|▉         | 191/2000 [06:34<54:02,  1.79s/it]  INFO:backoff:Backing off get_labels_batch(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9851, Requested 365. Please try again in 1.296s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 191, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9815, Requested 365. Please try again in 1.08s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 10%|▉         | 192/2000 [06:37<1:06:50,  2.22s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9670, Requested 350. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 192, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 10%|▉         | 193/2000 [06:39<1:03:15,  2.10s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 193, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 10%|▉         | 194/2000 [06:40<51:21,  1.71s/it]  INFO:backoff:Backing off get_labels_batch(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9862, Requested 321. Please try again in 1.098s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 194, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9805, Requested 321. Please try again in 756ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 4.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9704, Requested 321. Please try again in 150ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 10%|▉         | 195/2000 [06:46<1:32:38,  3.08s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 195, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 10%|▉         | 196/2000 [06:47<1:08:47,  2.29s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9450, Requested 1450. Please try again in 5.4s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 196, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9318, Requested 1450. Please try again in 4.608s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 5.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 8949, Requested 1450. Please try again in 2.394s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 10%|▉         | 197/2000 [06:56<2:09:30,  4.31s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 197, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 10%|▉         | 198/2000 [06:56<1:34:54,  3.16s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 198, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 10%|▉         | 199/2000 [06:57<1:14:03,  2.47s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9792, Requested 365. Please try again in 941ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 3.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9776, Requested 365. Please try again in 846ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 199, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 10%|█         | 200/2000 [07:01<1:26:30,  2.88s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 200, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 10%|█         | 201/2000 [07:02<1:06:49,  2.23s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9718, Requested 325. Please try again in 258ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 201, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 10%|█         | 202/2000 [07:03<1:03:28,  2.12s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9736, Requested 303. Please try again in 234ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 202, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 10%|█         | 203/2000 [07:06<1:03:06,  2.11s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 203, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 10%|█         | 204/2000 [07:06<48:16,  1.61s/it]  INFO:backoff:Backing off get_labels_batch(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9919, Requested 299. Please try again in 1.308s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 204, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9717, Requested 299. Please try again in 96ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 10%|█         | 205/2000 [07:10<1:05:53,  2.20s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9627, Requested 387. Please try again in 84ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 205, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 10%|█         | 206/2000 [07:11<1:02:44,  2.10s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9697, Requested 308. Please try again in 30ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 206, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 10%|█         | 207/2000 [07:14<1:07:21,  2.25s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 207, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 10%|█         | 208/2000 [07:15<55:34,  1.86s/it]  INFO:backoff:Backing off get_labels_batch(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9760, Requested 389. Please try again in 894ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 208, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9633, Requested 389. Please try again in 132ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 10%|█         | 209/2000 [07:19<1:16:16,  2.56s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 209, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 10%|█         | 210/2000 [07:20<58:53,  1.97s/it]  "
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 210, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 11%|█         | 211/2000 [07:20<46:38,  1.56s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9843, Requested 321. Please try again in 984ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 211, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 11%|█         | 212/2000 [07:23<52:30,  1.76s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9789, Requested 311. Please try again in 600ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 212, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 11%|█         | 213/2000 [07:25<54:30,  1.83s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9774, Requested 277. Please try again in 306ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 213, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 11%|█         | 214/2000 [07:27<59:33,  2.00s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 214, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 11%|█         | 215/2000 [07:28<49:31,  1.66s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9806, Requested 326. Please try again in 792ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 215, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 11%|█         | 216/2000 [07:30<55:23,  1.86s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9738, Requested 345. Please try again in 498ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 216, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 11%|█         | 217/2000 [07:33<1:00:18,  2.03s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 217, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 11%|█         | 218/2000 [07:33<46:11,  1.56s/it]  INFO:backoff:Backing off get_labels_batch(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9913, Requested 308. Please try again in 1.326s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 218, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9805, Requested 308. Please try again in 678ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 11%|█         | 219/2000 [07:36<56:54,  1.92s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9765, Requested 398. Please try again in 977ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 219, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9733, Requested 398. Please try again in 786ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 11%|█         | 220/2000 [07:38<1:02:41,  2.11s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9721, Requested 288. Please try again in 54ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 220, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 11%|█         | 221/2000 [07:39<50:20,  1.70s/it]  INFO:backoff:Backing off get_labels_batch(...) for 0.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9890, Requested 353. Please try again in 1.458s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 221, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9869, Requested 353. Please try again in 1.332s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 11%|█         | 222/2000 [07:43<1:09:11,  2.33s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 222, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 11%|█         | 223/2000 [07:43<52:11,  1.76s/it]  INFO:backoff:Backing off get_labels_batch(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9823, Requested 493. Please try again in 1.896s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 223, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9719, Requested 493. Please try again in 1.272s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 11%|█         | 224/2000 [07:48<1:14:07,  2.50s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 224, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 11%|█▏        | 225/2000 [07:48<55:22,  1.87s/it]  INFO:backoff:Backing off get_labels_batch(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9797, Requested 462. Please try again in 1.554s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 225, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 11%|█▏        | 226/2000 [07:51<1:00:38,  2.05s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9816, Requested 339. Please try again in 930ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 226, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 11%|█▏        | 227/2000 [07:53<1:02:26,  2.11s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9769, Requested 352. Please try again in 726ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 227, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 11%|█▏        | 228/2000 [07:55<59:41,  2.02s/it]  INFO:backoff:Backing off get_labels_batch(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9811, Requested 378. Please try again in 1.134s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 228, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9788, Requested 378. Please try again in 996ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 2.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9762, Requested 378. Please try again in 840ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 11%|█▏        | 229/2000 [07:58<1:09:10,  2.34s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 229, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 12%|█▏        | 230/2000 [07:59<56:11,  1.90s/it]  INFO:backoff:Backing off get_labels_batch(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9838, Requested 398. Please try again in 1.416s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 230, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9780, Requested 398. Please try again in 1.068s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 12%|█▏        | 231/2000 [08:01<57:18,  1.94s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9886, Requested 336. Please try again in 1.332s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 1.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9865, Requested 336. Please try again in 1.206s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 231, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 12%|█▏        | 232/2000 [08:03<1:04:16,  2.18s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9764, Requested 278. Please try again in 251ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 232, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 12%|█▏        | 233/2000 [08:04<51:14,  1.74s/it]  INFO:backoff:Backing off get_labels_batch(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9928, Requested 391. Please try again in 1.913s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 233, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9899, Requested 391. Please try again in 1.74s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 5.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9846, Requested 391. Please try again in 1.422s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 12%|█▏        | 234/2000 [08:11<1:37:16,  3.31s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 234, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 12%|█▏        | 235/2000 [08:12<1:15:58,  2.58s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 235, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 12%|█▏        | 236/2000 [08:13<1:00:24,  2.05s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 236, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 12%|█▏        | 237/2000 [08:13<47:11,  1.61s/it]  INFO:backoff:Backing off get_labels_batch(...) for 1.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9764, Requested 725. Please try again in 2.934s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 237, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9424, Requested 725. Please try again in 894ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 5.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9318, Requested 725. Please try again in 258ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 12%|█▏        | 238/2000 [08:22<1:48:21,  3.69s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 238, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 12%|█▏        | 239/2000 [08:23<1:23:31,  2.85s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 239, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 12%|█▏        | 240/2000 [08:23<1:04:01,  2.18s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 240, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 12%|█▏        | 241/2000 [08:24<49:47,  1.70s/it]  "
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 241, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 12%|█▏        | 242/2000 [08:25<44:38,  1.52s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9745, Requested 451. Please try again in 1.176s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 242, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 12%|█▏        | 243/2000 [08:27<50:40,  1.73s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9815, Requested 977. Please try again in 4.752s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 243, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9692, Requested 977. Please try again in 4.014s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9227, Requested 977. Please try again in 1.224s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9087, Requested 977. Please try again in 384ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 12%|█▏        | 244/2000 [08:33<1:27:13,  2.98s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9711, Requested 327. Please try again in 228ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 244, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 12%|█▏        | 245/2000 [08:35<1:17:38,  2.65s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 245, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 12%|█▏        | 246/2000 [08:36<1:02:31,  2.14s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9842, Requested 326. Please try again in 1.007s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 246, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9791, Requested 326. Please try again in 702ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 12%|█▏        | 247/2000 [08:40<1:22:25,  2.82s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 247, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 12%|█▏        | 248/2000 [08:41<1:03:12,  2.16s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 248, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 12%|█▏        | 249/2000 [08:41<47:58,  1.64s/it]  INFO:backoff:Backing off get_labels_batch(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9864, Requested 399. Please try again in 1.578s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 249, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9759, Requested 399. Please try again in 948ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9743, Requested 399. Please try again in 852ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 12%|█▎        | 250/2000 [08:44<56:57,  1.95s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9797, Requested 282. Please try again in 474ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 250, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 13%|█▎        | 251/2000 [08:46<53:57,  1.85s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9817, Requested 432. Please try again in 1.494s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 251, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 13%|█▎        | 252/2000 [08:48<1:00:07,  2.06s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9803, Requested 322. Please try again in 750ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 252, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 13%|█▎        | 253/2000 [08:51<1:03:45,  2.19s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 253, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 13%|█▎        | 254/2000 [08:51<50:49,  1.75s/it]  INFO:backoff:Backing off get_labels_batch(...) for 1.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9876, Requested 484. Please try again in 2.16s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 254, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9626, Requested 484. Please try again in 660ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 13%|█▎        | 255/2000 [08:55<1:09:30,  2.39s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9678, Requested 347. Please try again in 150ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 255, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 13%|█▎        | 256/2000 [08:56<57:09,  1.97s/it]  INFO:backoff:Backing off get_labels_batch(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9855, Requested 459. Please try again in 1.883s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 256, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9634, Requested 459. Please try again in 558ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 13%|█▎        | 257/2000 [08:59<1:06:16,  2.28s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9788, Requested 375. Please try again in 977ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 257, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9749, Requested 375. Please try again in 744ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 13%|█▎        | 258/2000 [09:04<1:27:17,  3.01s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 258, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 13%|█▎        | 259/2000 [09:05<1:08:20,  2.36s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9571, Requested 456. Please try again in 162ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 259, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 13%|█▎        | 260/2000 [09:06<58:22,  2.01s/it]  INFO:backoff:Backing off get_labels_batch(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9793, Requested 350. Please try again in 858ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 260, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9728, Requested 350. Please try again in 468ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 13%|█▎        | 261/2000 [09:08<56:34,  1.95s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9838, Requested 571. Please try again in 2.454s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 261, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9580, Requested 571. Please try again in 906ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 3.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9540, Requested 571. Please try again in 666ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 13%|█▎        | 262/2000 [09:14<1:29:39,  3.09s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 262, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 13%|█▎        | 263/2000 [09:14<1:07:23,  2.33s/it]INFO:backoff:Backing off get_labels_batch(...) for 2.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9732, Requested 351. Please try again in 498ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 263, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 13%|█▎        | 264/2000 [09:17<1:13:28,  2.54s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 264, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 13%|█▎        | 265/2000 [09:18<56:19,  1.95s/it]  INFO:backoff:Backing off get_labels_batch(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9780, Requested 324. Please try again in 624ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 265, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9734, Requested 324. Please try again in 348ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 13%|█▎        | 266/2000 [09:21<1:05:50,  2.28s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 266, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 13%|█▎        | 267/2000 [09:22<52:19,  1.81s/it]  INFO:backoff:Backing off get_labels_batch(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9821, Requested 518. Please try again in 2.034s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 267, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9791, Requested 518. Please try again in 1.854s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 3.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9578, Requested 518. Please try again in 576ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 13%|█▎        | 268/2000 [09:28<1:31:52,  3.18s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 268, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 13%|█▎        | 269/2000 [09:29<1:10:49,  2.45s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 269, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 14%|█▎        | 270/2000 [09:29<54:06,  1.88s/it]  INFO:backoff:Backing off get_labels_batch(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9580, Requested 453. Please try again in 198ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 270, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 14%|█▎        | 271/2000 [09:31<53:23,  1.85s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9703, Requested 361. Please try again in 384ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 271, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 14%|█▎        | 272/2000 [09:33<52:54,  1.84s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9751, Requested 298. Please try again in 294ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 272, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 14%|█▎        | 273/2000 [09:34<44:17,  1.54s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9908, Requested 332. Please try again in 1.44s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 273, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9677, Requested 332. Please try again in 54ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 14%|█▎        | 274/2000 [09:37<1:01:04,  2.12s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 274, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 14%|█▍        | 275/2000 [09:38<45:57,  1.60s/it]  INFO:backoff:Backing off get_labels_batch(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9905, Requested 362. Please try again in 1.602s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 275, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9786, Requested 362. Please try again in 888ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 7.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9642, Requested 362. Please try again in 24ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 14%|█▍        | 276/2000 [09:48<2:02:18,  4.26s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 276, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 14%|█▍        | 277/2000 [09:49<1:32:44,  3.23s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 277, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 14%|█▍        | 278/2000 [09:49<1:09:45,  2.43s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 278, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 14%|█▍        | 279/2000 [09:50<54:16,  1.89s/it]  "
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 279, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 14%|█▍        | 280/2000 [09:51<47:52,  1.67s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 280, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 14%|█▍        | 281/2000 [09:52<40:24,  1.41s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9623, Requested 530. Please try again in 918ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 281, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 14%|█▍        | 282/2000 [09:54<42:37,  1.49s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9849, Requested 305. Please try again in 924ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 282, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 14%|█▍        | 283/2000 [09:56<51:30,  1.80s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9733, Requested 459. Please try again in 1.152s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 283, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 4.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9655, Requested 459. Please try again in 684ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 14%|█▍        | 284/2000 [10:02<1:22:42,  2.89s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 284, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 14%|█▍        | 285/2000 [10:02<1:02:54,  2.20s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 285, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 14%|█▍        | 286/2000 [10:03<49:18,  1.73s/it]  "
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 286, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 14%|█▍        | 287/2000 [10:03<39:17,  1.38s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9903, Requested 291. Please try again in 1.164s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 287, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 14%|█▍        | 288/2000 [10:05<44:25,  1.56s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9869, Requested 344. Please try again in 1.278s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 288, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9739, Requested 344. Please try again in 498ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 14%|█▍        | 289/2000 [10:08<52:18,  1.83s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9795, Requested 342. Please try again in 822ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 289, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 14%|█▍        | 290/2000 [10:10<55:04,  1.93s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9766, Requested 397. Please try again in 977ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 290, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9743, Requested 397. Please try again in 840ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 6.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9727, Requested 397. Please try again in 744ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 15%|█▍        | 291/2000 [10:17<1:40:35,  3.53s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 291, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 15%|█▍        | 292/2000 [10:18<1:17:48,  2.73s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 292, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 15%|█▍        | 293/2000 [10:19<1:02:03,  2.18s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 293, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 15%|█▍        | 294/2000 [10:20<48:30,  1.71s/it]  "
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 294, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 15%|█▍        | 295/2000 [10:20<39:22,  1.39s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9835, Requested 286. Please try again in 726ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 295, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 15%|█▍        | 296/2000 [10:22<39:55,  1.41s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9874, Requested 339. Please try again in 1.278s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 296, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9850, Requested 339. Please try again in 1.134s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 15%|█▍        | 297/2000 [10:25<59:41,  2.10s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 297, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 15%|█▍        | 298/2000 [10:26<45:01,  1.59s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9843, Requested 578. Please try again in 2.526s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 298, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9638, Requested 578. Please try again in 1.296s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 15%|█▍        | 299/2000 [10:30<1:03:19,  2.23s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9760, Requested 418. Please try again in 1.068s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 299, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 15%|█▌        | 300/2000 [10:32<1:02:22,  2.20s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9805, Requested 368. Please try again in 1.038s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 300, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9766, Requested 368. Please try again in 804ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 15%|█▌        | 301/2000 [10:36<1:16:54,  2.72s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 301, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 15%|█▌        | 302/2000 [10:36<57:25,  2.03s/it]  INFO:backoff:Backing off get_labels_batch(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9732, Requested 387. Please try again in 714ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 302, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 15%|█▌        | 303/2000 [10:38<54:34,  1.93s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9830, Requested 435. Please try again in 1.59s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 303, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 15%|█▌        | 304/2000 [10:40<57:14,  2.03s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9865, Requested 334. Please try again in 1.194s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 304, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9781, Requested 334. Please try again in 690ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 5.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9752, Requested 334. Please try again in 516ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 15%|█▌        | 305/2000 [10:46<1:34:36,  3.35s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 305, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 15%|█▌        | 306/2000 [10:47<1:10:54,  2.51s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 306, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 15%|█▌        | 307/2000 [10:48<55:45,  1.98s/it]  INFO:backoff:Backing off get_labels_batch(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9690, Requested 359. Please try again in 294ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 307, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 15%|█▌        | 308/2000 [10:50<54:30,  1.93s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9744, Requested 290. Please try again in 204ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 308, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 15%|█▌        | 309/2000 [10:52<57:06,  2.03s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 309, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 16%|█▌        | 310/2000 [10:53<45:57,  1.63s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9867, Requested 286. Please try again in 918ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 310, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 16%|█▌        | 311/2000 [10:55<53:01,  1.88s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9744, Requested 272. Please try again in 96ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 311, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 16%|█▌        | 312/2000 [10:57<51:31,  1.83s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9730, Requested 354. Please try again in 503ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 312, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 16%|█▌        | 313/2000 [10:59<51:10,  1.82s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9774, Requested 304. Please try again in 468ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 313, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9700, Requested 304. Please try again in 24ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 16%|█▌        | 314/2000 [11:04<1:18:54,  2.81s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 314, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 16%|█▌        | 315/2000 [11:04<1:00:23,  2.15s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 315, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 16%|█▌        | 316/2000 [11:05<46:28,  1.66s/it]  INFO:backoff:Backing off get_labels_batch(...) for 1.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9727, Requested 349. Please try again in 456ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 316, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 16%|█▌        | 317/2000 [11:07<48:59,  1.75s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9743, Requested 302. Please try again in 270ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 317, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 16%|█▌        | 318/2000 [11:08<46:45,  1.67s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9791, Requested 379. Please try again in 1.02s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 318, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 16%|█▌        | 319/2000 [11:11<52:14,  1.86s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9762, Requested 355. Please try again in 702ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 319, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9692, Requested 355. Please try again in 282ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 16%|█▌        | 320/2000 [11:15<1:12:24,  2.59s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 320, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 16%|█▌        | 321/2000 [11:15<55:50,  2.00s/it]  INFO:backoff:Backing off get_labels_batch(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9641, Requested 363. Please try again in 24ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 321, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 16%|█▌        | 322/2000 [11:17<50:01,  1.79s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9777, Requested 294. Please try again in 426ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 322, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 16%|█▌        | 323/2000 [11:19<51:27,  1.84s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9738, Requested 308. Please try again in 276ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 323, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9695, Requested 308. Please try again in 18ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 16%|█▌        | 324/2000 [11:22<1:00:25,  2.16s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 324, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 16%|█▋        | 325/2000 [11:22<46:44,  1.67s/it]  INFO:backoff:Backing off get_labels_batch(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9784, Requested 274. Please try again in 348ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 325, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 16%|█▋        | 326/2000 [11:24<44:43,  1.60s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9820, Requested 306. Please try again in 756ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 326, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9722, Requested 306. Please try again in 168ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 16%|█▋        | 327/2000 [11:26<53:22,  1.91s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9679, Requested 353. Please try again in 192ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 327, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 16%|█▋        | 328/2000 [11:27<45:08,  1.62s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9878, Requested 281. Please try again in 954ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 328, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9839, Requested 281. Please try again in 720ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 16%|█▋        | 329/2000 [11:31<1:01:31,  2.21s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 329, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 16%|█▋        | 330/2000 [11:32<50:49,  1.83s/it]  INFO:backoff:Backing off get_labels_batch(...) for 1.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9696, Requested 318. Please try again in 84ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 330, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 17%|█▋        | 331/2000 [11:34<51:35,  1.85s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9691, Requested 515. Please try again in 1.236s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 331, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 17%|█▋        | 332/2000 [11:36<1:00:15,  2.17s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9683, Requested 472. Please try again in 930ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 332, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 17%|█▋        | 333/2000 [11:39<1:00:07,  2.16s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9765, Requested 359. Please try again in 744ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 333, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 17%|█▋        | 334/2000 [11:40<56:11,  2.02s/it]  INFO:backoff:Backing off get_labels_batch(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9822, Requested 441. Please try again in 1.578s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 334, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9564, Requested 441. Please try again in 30ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 17%|█▋        | 335/2000 [11:46<1:27:20,  3.15s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 335, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 17%|█▋        | 336/2000 [11:47<1:05:29,  2.36s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 336, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 17%|█▋        | 337/2000 [11:47<50:35,  1.83s/it]  INFO:backoff:Backing off get_labels_batch(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9713, Requested 401. Please try again in 684ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 337, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9609, Requested 401. Please try again in 60ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 17%|█▋        | 338/2000 [11:53<1:21:26,  2.94s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 338, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 17%|█▋        | 339/2000 [11:53<1:00:26,  2.18s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 339, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 17%|█▋        | 340/2000 [11:54<46:53,  1.69s/it]  INFO:backoff:Backing off get_labels_batch(...) for 1.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9809, Requested 303. Please try again in 672ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 340, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 17%|█▋        | 341/2000 [11:56<53:40,  1.94s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9694, Requested 401. Please try again in 570ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 341, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9637, Requested 401. Please try again in 228ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 17%|█▋        | 342/2000 [11:59<1:04:02,  2.32s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 342, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 17%|█▋        | 343/2000 [12:00<51:38,  1.87s/it]  INFO:backoff:Backing off get_labels_batch(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9753, Requested 320. Please try again in 438ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 343, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 17%|█▋        | 344/2000 [12:02<54:42,  1.98s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 344, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 17%|█▋        | 345/2000 [12:03<43:40,  1.58s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9870, Requested 304. Please try again in 1.044s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 345, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9731, Requested 304. Please try again in 210ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 17%|█▋        | 346/2000 [12:06<54:47,  1.99s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9686, Requested 328. Please try again in 84ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 346, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 17%|█▋        | 347/2000 [12:07<47:39,  1.73s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9835, Requested 274. Please try again in 654ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 347, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 17%|█▋        | 348/2000 [12:09<52:07,  1.89s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9731, Requested 337. Please try again in 408ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 348, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 17%|█▋        | 349/2000 [12:12<54:49,  1.99s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9693, Requested 310. Please try again in 18ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 349, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 18%|█▊        | 350/2000 [12:14<53:44,  1.95s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9682, Requested 343. Please try again in 150ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 350, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 18%|█▊        | 351/2000 [12:15<47:34,  1.73s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9812, Requested 335. Please try again in 882ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 351, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 18%|█▊        | 352/2000 [12:17<49:01,  1.78s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9825, Requested 400. Please try again in 1.35s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 352, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9632, Requested 400. Please try again in 192ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 18%|█▊        | 353/2000 [12:22<1:15:38,  2.76s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 353, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 18%|█▊        | 354/2000 [12:23<1:00:41,  2.21s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 354, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 18%|█▊        | 355/2000 [12:23<47:18,  1.73s/it]  INFO:backoff:Backing off get_labels_batch(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9827, Requested 477. Please try again in 1.824s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 355, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9565, Requested 477. Please try again in 251ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 18%|█▊        | 356/2000 [12:27<1:07:11,  2.45s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9591, Requested 470. Please try again in 366ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 356, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 18%|█▊        | 357/2000 [12:30<1:04:48,  2.37s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9683, Requested 556. Please try again in 1.434s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 357, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9546, Requested 556. Please try again in 612ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 18%|█▊        | 358/2000 [12:34<1:19:04,  2.89s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 358, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 18%|█▊        | 359/2000 [12:34<1:01:54,  2.26s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9647, Requested 416. Please try again in 378ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 359, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 18%|█▊        | 360/2000 [12:36<54:30,  1.99s/it]  INFO:backoff:Backing off get_labels_batch(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9823, Requested 431. Please try again in 1.524s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 360, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9623, Requested 431. Please try again in 324ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9600, Requested 431. Please try again in 186ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 18%|█▊        | 361/2000 [12:39<1:06:24,  2.43s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 361, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 18%|█▊        | 362/2000 [12:40<51:26,  1.88s/it]  INFO:backoff:Backing off get_labels_batch(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9880, Requested 286. Please try again in 996ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 362, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9857, Requested 286. Please try again in 858ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 2.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9749, Requested 286. Please try again in 210ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 18%|█▊        | 363/2000 [12:44<1:10:31,  2.58s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 363, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 18%|█▊        | 364/2000 [12:45<52:46,  1.94s/it]  INFO:backoff:Backing off get_labels_batch(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9710, Requested 328. Please try again in 228ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 364, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 18%|█▊        | 365/2000 [12:46<47:17,  1.74s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9824, Requested 283. Please try again in 642ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 365, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9780, Requested 283. Please try again in 378ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 18%|█▊        | 366/2000 [12:50<1:07:35,  2.48s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 366, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 18%|█▊        | 367/2000 [12:51<51:30,  1.89s/it]  "
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 367, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 18%|█▊        | 368/2000 [12:51<40:36,  1.49s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9845, Requested 300. Please try again in 870ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 368, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9754, Requested 300. Please try again in 324ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 18%|█▊        | 369/2000 [12:55<1:02:48,  2.31s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 369, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 18%|█▊        | 370/2000 [12:56<50:24,  1.86s/it]  "
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 370, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 19%|█▊        | 371/2000 [12:57<42:22,  1.56s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9822, Requested 453. Please try again in 1.65s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 371, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9725, Requested 453. Please try again in 1.068s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 19%|█▊        | 372/2000 [13:01<1:02:21,  2.30s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 372, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 19%|█▊        | 373/2000 [13:02<48:06,  1.77s/it]  INFO:backoff:Backing off get_labels_batch(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9781, Requested 343. Please try again in 744ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 373, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 19%|█▊        | 374/2000 [13:03<46:34,  1.72s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9859, Requested 476. Please try again in 2.01s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 374, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9749, Requested 476. Please try again in 1.35s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 19%|█▉        | 375/2000 [13:08<1:15:25,  2.78s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 375, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 19%|█▉        | 376/2000 [13:09<57:21,  2.12s/it]  INFO:backoff:Backing off get_labels_batch(...) for 1.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9630, Requested 398. Please try again in 168ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 376, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 19%|█▉        | 377/2000 [13:12<1:01:41,  2.28s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9581, Requested 421. Please try again in 12ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 377, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 19%|█▉        | 378/2000 [13:13<51:22,  1.90s/it]  INFO:backoff:Backing off get_labels_batch(...) for 1.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9807, Requested 445. Please try again in 1.512s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 378, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9598, Requested 445. Please try again in 258ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 19%|█▉        | 379/2000 [13:17<1:07:10,  2.49s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9599, Requested 417. Please try again in 96ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 379, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 19%|█▉        | 380/2000 [13:18<55:14,  2.05s/it]  INFO:backoff:Backing off get_labels_batch(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9837, Requested 333. Please try again in 1.02s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 380, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9754, Requested 333. Please try again in 522ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 19%|█▉        | 381/2000 [13:21<1:02:59,  2.33s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9666, Requested 352. Please try again in 108ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 381, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 19%|█▉        | 382/2000 [13:23<1:03:39,  2.36s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9616, Requested 416. Please try again in 192ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 382, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 19%|█▉        | 383/2000 [13:25<1:04:41,  2.40s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 383, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 19%|█▉        | 384/2000 [13:26<49:42,  1.85s/it]  INFO:backoff:Backing off get_labels_batch(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9821, Requested 273. Please try again in 564ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 384, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 19%|█▉        | 385/2000 [13:28<48:27,  1.80s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9818, Requested 284. Please try again in 612ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 385, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 19%|█▉        | 386/2000 [13:30<51:42,  1.92s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9738, Requested 425. Please try again in 977ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 386, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 19%|█▉        | 387/2000 [13:32<53:34,  1.99s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9786, Requested 321. Please try again in 642ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 387, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 19%|█▉        | 388/2000 [13:35<59:07,  2.20s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9657, Requested 431. Please try again in 528ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 388, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 19%|█▉        | 389/2000 [13:37<58:51,  2.19s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9712, Requested 401. Please try again in 678ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 389, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 20%|█▉        | 390/2000 [13:39<54:53,  2.05s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9823, Requested 406. Please try again in 1.374s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 390, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 20%|█▉        | 391/2000 [13:41<58:11,  2.17s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9808, Requested 292. Please try again in 600ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 391, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 20%|█▉        | 392/2000 [13:43<58:00,  2.16s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9742, Requested 295. Please try again in 222ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 392, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 20%|█▉        | 393/2000 [13:45<51:43,  1.93s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9809, Requested 357. Please try again in 996ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 393, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9698, Requested 357. Please try again in 330ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 20%|█▉        | 394/2000 [13:49<1:10:11,  2.62s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 394, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 20%|█▉        | 395/2000 [13:50<59:31,  2.23s/it]  INFO:backoff:Backing off get_labels_batch(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9701, Requested 328. Please try again in 174ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 395, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 20%|█▉        | 396/2000 [13:52<55:07,  2.06s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9744, Requested 441. Please try again in 1.11s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 396, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 20%|█▉        | 397/2000 [13:54<55:45,  2.09s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9810, Requested 292. Please try again in 612ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 397, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 20%|█▉        | 398/2000 [13:56<57:25,  2.15s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9715, Requested 358. Please try again in 438ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 398, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 20%|█▉        | 399/2000 [13:58<51:18,  1.92s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9833, Requested 293. Please try again in 756ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 399, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 20%|██        | 400/2000 [13:59<50:19,  1.89s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9819, Requested 287. Please try again in 636ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 400, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 20%|██        | 401/2000 [14:02<54:16,  2.04s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 401, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 20%|██        | 402/2000 [14:03<46:30,  1.75s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9814, Requested 285. Please try again in 594ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 402, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9784, Requested 285. Please try again in 414ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 20%|██        | 403/2000 [14:07<1:05:12,  2.45s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 403, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 20%|██        | 404/2000 [14:07<48:41,  1.83s/it]  INFO:backoff:Backing off get_labels_batch(...) for 1.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9672, Requested 351. Please try again in 138ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 404, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 20%|██        | 405/2000 [14:10<57:41,  2.17s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 405, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 20%|██        | 406/2000 [14:11<45:33,  1.71s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9794, Requested 321. Please try again in 690ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 406, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 20%|██        | 407/2000 [14:12<42:59,  1.62s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9877, Requested 272. Please try again in 894ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 407, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 20%|██        | 408/2000 [14:15<49:27,  1.86s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9748, Requested 308. Please try again in 336ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 408, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9703, Requested 308. Please try again in 66ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 20%|██        | 409/2000 [14:19<1:04:33,  2.43s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 409, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 20%|██        | 410/2000 [14:19<51:49,  1.96s/it]  "
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 410, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 21%|██        | 411/2000 [14:20<40:52,  1.54s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9780, Requested 284. Please try again in 384ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 411, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9756, Requested 284. Please try again in 240ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 21%|██        | 412/2000 [14:21<36:59,  1.40s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9886, Requested 351. Please try again in 1.422s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 412, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9827, Requested 351. Please try again in 1.068s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 21%|██        | 413/2000 [14:25<57:33,  2.18s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 413, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 21%|██        | 414/2000 [14:26<44:56,  1.70s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9859, Requested 371. Please try again in 1.38s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 414, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9789, Requested 371. Please try again in 960ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 21%|██        | 415/2000 [14:30<1:07:36,  2.56s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 415, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 21%|██        | 416/2000 [14:31<50:39,  1.92s/it]  INFO:backoff:Backing off get_labels_batch(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9697, Requested 412. Please try again in 654ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 416, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9655, Requested 412. Please try again in 402ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 21%|██        | 417/2000 [14:35<1:05:57,  2.50s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 417, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 21%|██        | 418/2000 [14:35<50:23,  1.91s/it]  "
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 418, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 21%|██        | 419/2000 [14:36<42:12,  1.60s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9798, Requested 360. Please try again in 948ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 419, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9685, Requested 360. Please try again in 270ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 21%|██        | 420/2000 [14:39<54:32,  2.07s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 420, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 21%|██        | 421/2000 [14:40<42:35,  1.62s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9841, Requested 540. Please try again in 2.286s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 421, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9747, Requested 540. Please try again in 1.722s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 21%|██        | 422/2000 [14:43<55:27,  2.11s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9802, Requested 367. Please try again in 1.013s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 422, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9696, Requested 367. Please try again in 378ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 21%|██        | 423/2000 [14:46<1:02:00,  2.36s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9669, Requested 339. Please try again in 48ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 423, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 21%|██        | 424/2000 [14:48<1:03:33,  2.42s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 424, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 21%|██▏       | 425/2000 [14:49<49:04,  1.87s/it]  INFO:backoff:Backing off get_labels_batch(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9810, Requested 386. Please try again in 1.176s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 425, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 21%|██▏       | 426/2000 [14:51<50:25,  1.92s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9829, Requested 312. Please try again in 846ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 426, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 21%|██▏       | 427/2000 [14:53<47:45,  1.82s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9877, Requested 346. Please try again in 1.338s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 427, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9800, Requested 346. Please try again in 876ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 21%|██▏       | 428/2000 [14:56<1:02:38,  2.39s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 428, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 21%|██▏       | 429/2000 [14:57<49:29,  1.89s/it]  INFO:backoff:Backing off get_labels_batch(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9852, Requested 293. Please try again in 870ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 429, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9717, Requested 293. Please try again in 60ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 22%|██▏       | 430/2000 [15:00<55:56,  2.14s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9689, Requested 381. Please try again in 420ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 430, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9637, Requested 381. Please try again in 108ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 22%|██▏       | 431/2000 [15:03<1:00:59,  2.33s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 431, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 22%|██▏       | 432/2000 [15:03<47:25,  1.81s/it]  INFO:backoff:Backing off get_labels_batch(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9823, Requested 434. Please try again in 1.542s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 432, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9765, Requested 434. Please try again in 1.194s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9750, Requested 434. Please try again in 1.104s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 13.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9604, Requested 434. Please try again in 228ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 22%|██▏       | 433/2000 [15:18<2:31:13,  5.79s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 433, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 22%|██▏       | 434/2000 [15:19<1:50:50,  4.25s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 434, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 22%|██▏       | 435/2000 [15:19<1:20:56,  3.10s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 435, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 22%|██▏       | 436/2000 [15:20<1:00:11,  2.31s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 436, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 22%|██▏       | 437/2000 [15:20<47:06,  1.81s/it]  "
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 437, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 22%|██▏       | 438/2000 [15:21<37:03,  1.42s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 438, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 22%|██▏       | 439/2000 [15:22<30:46,  1.18s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 439, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 22%|██▏       | 440/2000 [15:22<24:07,  1.08it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 440, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 22%|██▏       | 441/2000 [15:23<22:23,  1.16it/s]INFO:backoff:Backing off get_labels_batch(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9650, Requested 1299. Please try again in 5.694s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 441, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9617, Requested 1299. Please try again in 5.496s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 7.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9600, Requested 1299. Please try again in 5.394s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 22%|██▏       | 442/2000 [15:31<1:18:43,  3.03s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9447, Requested 796. Please try again in 1.458s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 442, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9299, Requested 796. Please try again in 570ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 22%|██▏       | 443/2000 [15:33<1:15:32,  2.91s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9707, Requested 371. Please try again in 468ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 443, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 22%|██▏       | 444/2000 [15:36<1:10:19,  2.71s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9693, Requested 673. Please try again in 2.196s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 444, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9421, Requested 673. Please try again in 564ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 22%|██▏       | 445/2000 [15:42<1:35:15,  3.68s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 445, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 22%|██▏       | 446/2000 [15:42<1:13:07,  2.82s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 446, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 22%|██▏       | 447/2000 [15:43<55:56,  2.16s/it]  "
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 447, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 22%|██▏       | 448/2000 [15:44<43:52,  1.70s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9883, Requested 342. Please try again in 1.35s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 448, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9720, Requested 342. Please try again in 372ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 22%|██▏       | 449/2000 [15:46<48:23,  1.87s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9840, Requested 290. Please try again in 780ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 449, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9767, Requested 290. Please try again in 342ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 22%|██▎       | 450/2000 [15:47<46:07,  1.79s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9865, Requested 327. Please try again in 1.152s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 450, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9696, Requested 327. Please try again in 138ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 23%|██▎       | 451/2000 [15:53<1:12:33,  2.81s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 451, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 23%|██▎       | 452/2000 [15:53<57:13,  2.22s/it]  "
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 452, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 23%|██▎       | 453/2000 [15:54<46:54,  1.82s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 453, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 23%|██▎       | 454/2000 [15:55<37:59,  1.47s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9848, Requested 325. Please try again in 1.038s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 454, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9750, Requested 325. Please try again in 450ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 23%|██▎       | 455/2000 [15:58<48:21,  1.88s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9703, Requested 439. Please try again in 852ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 455, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 23%|██▎       | 456/2000 [16:00<48:55,  1.90s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9785, Requested 283. Please try again in 408ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 456, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9758, Requested 283. Please try again in 246ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 23%|██▎       | 457/2000 [16:04<1:02:58,  2.45s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 457, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 23%|██▎       | 458/2000 [16:04<48:46,  1.90s/it]  INFO:backoff:Backing off get_labels_batch(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9696, Requested 377. Please try again in 438ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 458, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 23%|██▎       | 459/2000 [16:05<40:57,  1.59s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9902, Requested 299. Please try again in 1.206s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 459, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9846, Requested 299. Please try again in 870ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 23%|██▎       | 460/2000 [16:09<56:23,  2.20s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9601, Requested 466. Please try again in 402ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 460, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 23%|██▎       | 461/2000 [16:10<51:03,  1.99s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9796, Requested 319. Please try again in 690ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 461, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 23%|██▎       | 462/2000 [16:12<53:03,  2.07s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9750, Requested 341. Please try again in 546ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 462, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 23%|██▎       | 463/2000 [16:15<54:50,  2.14s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 463, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 23%|██▎       | 464/2000 [16:16<45:22,  1.77s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9838, Requested 621. Please try again in 2.754s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 464, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9582, Requested 621. Please try again in 1.218s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 23%|██▎       | 465/2000 [16:20<1:08:06,  2.66s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 465, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 23%|██▎       | 466/2000 [16:21<53:37,  2.10s/it]  INFO:backoff:Backing off get_labels_batch(...) for 1.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9801, Requested 285. Please try again in 516ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 466, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 23%|██▎       | 467/2000 [16:24<56:17,  2.20s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 467, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 23%|██▎       | 468/2000 [16:24<44:37,  1.75s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9864, Requested 384. Please try again in 1.488s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 468, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9782, Requested 384. Please try again in 996ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 23%|██▎       | 469/2000 [16:27<49:40,  1.95s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9834, Requested 289. Please try again in 738ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 469, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 24%|██▎       | 470/2000 [16:28<44:52,  1.76s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9900, Requested 313. Please try again in 1.278s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 470, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9738, Requested 313. Please try again in 306ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 24%|██▎       | 471/2000 [16:32<1:00:17,  2.37s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 471, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 24%|██▎       | 472/2000 [16:32<46:20,  1.82s/it]  INFO:backoff:Backing off get_labels_batch(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9790, Requested 338. Please try again in 768ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 472, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 24%|██▎       | 473/2000 [16:35<49:26,  1.94s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9751, Requested 291. Please try again in 251ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 473, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 24%|██▎       | 474/2000 [16:36<41:57,  1.65s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9882, Requested 615. Please try again in 2.982s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 474, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9715, Requested 615. Please try again in 1.98s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 24%|██▍       | 475/2000 [16:40<1:04:35,  2.54s/it]INFO:backoff:Backing off get_labels_batch(...) for 2.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9695, Requested 315. Please try again in 60ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 475, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 24%|██▍       | 476/2000 [16:43<1:07:15,  2.65s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 476, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 24%|██▍       | 477/2000 [16:43<50:14,  1.98s/it]  INFO:backoff:Backing off get_labels_batch(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9747, Requested 378. Please try again in 750ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 477, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 24%|██▍       | 478/2000 [16:45<48:11,  1.90s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9846, Requested 321. Please try again in 1.002s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 478, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 24%|██▍       | 479/2000 [16:48<52:48,  2.08s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9738, Requested 278. Please try again in 96ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 479, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 24%|██▍       | 480/2000 [16:49<44:55,  1.77s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9845, Requested 304. Please try again in 894ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 480, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9739, Requested 304. Please try again in 258ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 24%|██▍       | 481/2000 [16:51<45:05,  1.78s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9849, Requested 451. Please try again in 1.8s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 481, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9744, Requested 451. Please try again in 1.17s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 2.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9617, Requested 451. Please try again in 408ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 24%|██▍       | 482/2000 [16:55<1:07:51,  2.68s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 482, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 24%|██▍       | 483/2000 [16:56<52:29,  2.08s/it]  INFO:backoff:Backing off get_labels_batch(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9738, Requested 290. Please try again in 168ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 483, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 24%|██▍       | 484/2000 [16:58<54:05,  2.14s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9647, Requested 388. Please try again in 210ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 484, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 24%|██▍       | 485/2000 [16:59<45:53,  1.82s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9847, Requested 289. Please try again in 816ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 485, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9718, Requested 289. Please try again in 42ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 24%|██▍       | 486/2000 [17:01<44:19,  1.76s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9867, Requested 273. Please try again in 840ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 486, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 24%|██▍       | 487/2000 [17:03<45:49,  1.82s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9820, Requested 366. Please try again in 1.116s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 487, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 24%|██▍       | 488/2000 [17:05<50:55,  2.02s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9770, Requested 347. Please try again in 702ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 488, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9708, Requested 347. Please try again in 330ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 24%|██▍       | 489/2000 [17:08<52:51,  2.10s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9730, Requested 340. Please try again in 420ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 489, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 24%|██▍       | 490/2000 [17:10<51:23,  2.04s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9750, Requested 300. Please try again in 300ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 490, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 25%|██▍       | 491/2000 [17:11<48:10,  1.92s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9783, Requested 276. Please try again in 354ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 491, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 25%|██▍       | 492/2000 [17:13<46:20,  1.84s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9779, Requested 275. Please try again in 324ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 492, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 25%|██▍       | 493/2000 [17:14<42:29,  1.69s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9837, Requested 297. Please try again in 804ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 493, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 25%|██▍       | 494/2000 [17:16<40:17,  1.61s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9905, Requested 296. Please try again in 1.206s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 494, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9780, Requested 296. Please try again in 456ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 25%|██▍       | 495/2000 [17:17<42:00,  1.67s/it]INFO:backoff:Backing off get_labels_batch(...) for 2.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9894, Requested 299. Please try again in 1.158s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 495, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 25%|██▍       | 496/2000 [17:20<49:46,  1.99s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9741, Requested 278. Please try again in 114ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 496, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 25%|██▍       | 497/2000 [17:22<48:45,  1.95s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9717, Requested 291. Please try again in 48ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 497, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 25%|██▍       | 498/2000 [17:23<42:54,  1.71s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9814, Requested 288. Please try again in 612ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 498, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 25%|██▍       | 499/2000 [17:25<40:27,  1.62s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9871, Requested 529. Please try again in 2.4s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 499, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9742, Requested 529. Please try again in 1.626s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 6.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9637, Requested 529. Please try again in 996ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 25%|██▌       | 500/2000 [17:33<1:34:13,  3.77s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 500, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 25%|██▌       | 501/2000 [17:34<1:09:16,  2.77s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 501, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 25%|██▌       | 502/2000 [17:35<55:22,  2.22s/it]  "
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 502, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 25%|██▌       | 503/2000 [17:36<44:18,  1.78s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9625, Requested 637. Please try again in 1.572s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 503, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 25%|██▌       | 504/2000 [17:38<50:30,  2.03s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9804, Requested 294. Please try again in 588ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 504, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 25%|██▌       | 505/2000 [17:40<51:11,  2.05s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9747, Requested 314. Please try again in 366ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 505, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9729, Requested 314. Please try again in 258ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 25%|██▌       | 506/2000 [17:44<1:05:34,  2.63s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 506, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 25%|██▌       | 507/2000 [17:45<50:30,  2.03s/it]  "
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 507, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 25%|██▌       | 508/2000 [17:45<39:49,  1.60s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9819, Requested 300. Please try again in 714ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 508, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 25%|██▌       | 509/2000 [17:48<43:59,  1.77s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9750, Requested 358. Please try again in 648ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 509, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 26%|██▌       | 510/2000 [17:49<44:22,  1.79s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9790, Requested 272. Please try again in 372ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 510, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 26%|██▌       | 511/2000 [17:52<49:10,  1.98s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9662, Requested 495. Please try again in 941ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 511, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 26%|██▌       | 512/2000 [17:54<47:35,  1.92s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9843, Requested 334. Please try again in 1.062s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 512, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 26%|██▌       | 513/2000 [17:56<49:40,  2.00s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9802, Requested 328. Please try again in 780ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 513, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 26%|██▌       | 514/2000 [17:58<53:16,  2.15s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9710, Requested 326. Please try again in 216ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 2.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9694, Requested 326. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 514, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.4s (openai.error.RateLimitError: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 8.3s (openai.error.RateLimitError: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 9.3s (openai.error.RateLimitError: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 48.2s (openai.error.RateLimitError: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 92.4s (openai.error.RateLimitError: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 91.2s (openai.error.RateLimitError: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 378.8s (openai.error.RateLimitError: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.)\n",
            " 26%|██▌       | 515/2000 [28:32<79:02:28, 191.62s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 515, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 26%|██▌       | 516/2000 [28:33<55:21:55, 134.31s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 516, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 26%|██▌       | 517/2000 [28:33<38:48:21, 94.20s/it] "
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 517, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 26%|██▌       | 518/2000 [28:34<27:15:20, 66.21s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 518, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 26%|██▌       | 519/2000 [28:35<19:07:43, 46.50s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 519, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 26%|██▌       | 520/2000 [28:35<13:25:49, 32.67s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 520, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 26%|██▌       | 521/2000 [28:36<9:28:28, 23.06s/it] "
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 521, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 26%|██▌       | 522/2000 [28:36<6:42:19, 16.33s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 522, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 26%|██▌       | 523/2000 [28:37<4:46:35, 11.64s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 523, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 26%|██▌       | 524/2000 [28:38<3:25:03,  8.34s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 524, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 26%|██▋       | 525/2000 [28:39<2:29:41,  6.09s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 525, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 26%|██▋       | 526/2000 [28:39<1:47:33,  4.38s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 526, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 26%|██▋       | 527/2000 [28:39<1:18:49,  3.21s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 527, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 26%|██▋       | 528/2000 [28:40<1:01:32,  2.51s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 528, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 26%|██▋       | 529/2000 [28:41<46:13,  1.89s/it]  "
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 529, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 26%|██▋       | 530/2000 [28:41<36:09,  1.48s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 530, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 27%|██▋       | 531/2000 [28:42<30:08,  1.23s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 531, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 27%|██▋       | 532/2000 [28:43<26:13,  1.07s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 532, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 27%|██▋       | 533/2000 [28:43<21:49,  1.12it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 533, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 27%|██▋       | 534/2000 [28:44<21:21,  1.14it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 534, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 27%|██▋       | 535/2000 [28:45<20:46,  1.18it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 535, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 27%|██▋       | 536/2000 [28:46<20:40,  1.18it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 536, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 27%|██▋       | 537/2000 [28:46<17:17,  1.41it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 537, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 27%|██▋       | 538/2000 [28:47<18:22,  1.33it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 538, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 27%|██▋       | 539/2000 [28:47<16:48,  1.45it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 539, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 27%|██▋       | 540/2000 [28:48<14:46,  1.65it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 540, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 27%|██▋       | 541/2000 [28:48<13:33,  1.79it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 541, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 27%|██▋       | 542/2000 [28:49<12:36,  1.93it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 542, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 27%|██▋       | 543/2000 [28:49<13:35,  1.79it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 543, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 27%|██▋       | 544/2000 [28:50<14:09,  1.71it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 544, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 27%|██▋       | 545/2000 [28:50<13:48,  1.76it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 545, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 27%|██▋       | 546/2000 [28:51<13:56,  1.74it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 546, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 27%|██▋       | 547/2000 [28:52<15:55,  1.52it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 547, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 27%|██▋       | 548/2000 [28:53<16:10,  1.50it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 548, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 27%|██▋       | 549/2000 [28:53<15:15,  1.58it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 549, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 28%|██▊       | 550/2000 [28:54<14:57,  1.62it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 550, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 28%|██▊       | 551/2000 [28:55<17:12,  1.40it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 551, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 28%|██▊       | 552/2000 [28:55<15:59,  1.51it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 552, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 28%|██▊       | 553/2000 [28:56<15:53,  1.52it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 553, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 28%|██▊       | 554/2000 [28:56<14:37,  1.65it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 554, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 28%|██▊       | 555/2000 [28:57<16:27,  1.46it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 555, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 28%|██▊       | 556/2000 [28:58<15:55,  1.51it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 556, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 28%|██▊       | 557/2000 [28:59<16:35,  1.45it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 557, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 28%|██▊       | 558/2000 [28:59<14:36,  1.65it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 558, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 28%|██▊       | 559/2000 [29:00<15:13,  1.58it/s]INFO:backoff:Backing off get_labels_batch(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9807, Requested 340. Please try again in 882ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 559, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 28%|██▊       | 560/2000 [29:01<23:25,  1.02it/s]INFO:backoff:Backing off get_labels_batch(...) for 1.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9847, Requested 513. Please try again in 2.16s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 560, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9556, Requested 513. Please try again in 414ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 28%|██▊       | 561/2000 [29:07<56:09,  2.34s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 561, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 28%|██▊       | 562/2000 [29:08<43:40,  1.82s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 562, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 28%|██▊       | 563/2000 [29:08<35:04,  1.46s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9873, Requested 376. Please try again in 1.494s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 563, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 28%|██▊       | 564/2000 [29:11<42:06,  1.76s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9835, Requested 574. Please try again in 2.454s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 564, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9573, Requested 574. Please try again in 882ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 28%|██▊       | 565/2000 [29:14<56:35,  2.37s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9750, Requested 300. Please try again in 300ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 565, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 28%|██▊       | 566/2000 [29:16<53:17,  2.23s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9731, Requested 397. Please try again in 768ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 566, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 28%|██▊       | 567/2000 [29:19<57:01,  2.39s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9657, Requested 365. Please try again in 132ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 567, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 28%|██▊       | 568/2000 [29:21<54:12,  2.27s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9682, Requested 489. Please try again in 1.026s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 568, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 28%|██▊       | 569/2000 [29:23<55:12,  2.32s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9730, Requested 283. Please try again in 78ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 569, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 28%|██▊       | 570/2000 [29:25<52:08,  2.19s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9698, Requested 316. Please try again in 84ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 570, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 29%|██▊       | 571/2000 [29:26<43:00,  1.81s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9863, Requested 361. Please try again in 1.344s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 571, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 29%|██▊       | 572/2000 [29:29<47:01,  1.98s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9825, Requested 285. Please try again in 660ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 572, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9771, Requested 285. Please try again in 336ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 29%|██▊       | 573/2000 [29:31<50:44,  2.13s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 573, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 29%|██▊       | 574/2000 [29:32<42:06,  1.77s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9821, Requested 295. Please try again in 696ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 574, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 29%|██▉       | 575/2000 [29:33<39:26,  1.66s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9882, Requested 294. Please try again in 1.056s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 575, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 29%|██▉       | 576/2000 [29:36<42:19,  1.78s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9833, Requested 421. Please try again in 1.524s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 576, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9648, Requested 421. Please try again in 414ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 29%|██▉       | 577/2000 [29:39<50:31,  2.13s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9750, Requested 334. Please try again in 503ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 577, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 29%|██▉       | 578/2000 [29:40<46:56,  1.98s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9806, Requested 494. Please try again in 1.8s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 578, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9674, Requested 494. Please try again in 1.007s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 29%|██▉       | 579/2000 [29:44<58:01,  2.45s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9703, Requested 313. Please try again in 96ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 579, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 29%|██▉       | 580/2000 [29:45<50:19,  2.13s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9784, Requested 319. Please try again in 618ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 580, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 29%|██▉       | 581/2000 [29:47<49:51,  2.11s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9753, Requested 324. Please try again in 462ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 581, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 29%|██▉       | 582/2000 [29:48<43:00,  1.82s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9883, Requested 272. Please try again in 930ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 582, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9784, Requested 272. Please try again in 336ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 29%|██▉       | 583/2000 [29:50<45:05,  1.91s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9804, Requested 285. Please try again in 534ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 583, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 29%|██▉       | 584/2000 [29:53<46:42,  1.98s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9734, Requested 269. Please try again in 18ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 584, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 29%|██▉       | 585/2000 [29:53<38:01,  1.61s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9880, Requested 285. Please try again in 990ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 585, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 29%|██▉       | 586/2000 [29:55<39:30,  1.68s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9870, Requested 413. Please try again in 1.698s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 586, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9636, Requested 413. Please try again in 294ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 29%|██▉       | 587/2000 [29:59<55:01,  2.34s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 587, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 29%|██▉       | 588/2000 [30:00<43:09,  1.83s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9866, Requested 267. Please try again in 798ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 588, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 29%|██▉       | 589/2000 [30:02<44:25,  1.89s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9803, Requested 401. Please try again in 1.224s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 589, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 30%|██▉       | 590/2000 [30:04<46:36,  1.98s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9830, Requested 412. Please try again in 1.452s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 590, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 4.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9784, Requested 412. Please try again in 1.176s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 30%|██▉       | 591/2000 [30:09<1:07:32,  2.88s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 591, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 30%|██▉       | 592/2000 [30:09<51:01,  2.17s/it]  "
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 592, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 30%|██▉       | 593/2000 [30:10<39:41,  1.69s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9836, Requested 276. Please try again in 672ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 593, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9749, Requested 276. Please try again in 150ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 30%|██▉       | 594/2000 [30:12<41:33,  1.77s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9794, Requested 368. Please try again in 972ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 594, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 30%|██▉       | 595/2000 [30:13<39:59,  1.71s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9886, Requested 356. Please try again in 1.452s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 595, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9646, Requested 356. Please try again in 12ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 30%|██▉       | 596/2000 [30:19<1:08:55,  2.95s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 596, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 30%|██▉       | 597/2000 [30:20<52:13,  2.23s/it]  "
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 597, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 30%|██▉       | 598/2000 [30:21<42:12,  1.81s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9637, Requested 426. Please try again in 378ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 598, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 30%|██▉       | 599/2000 [30:23<46:55,  2.01s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9635, Requested 527. Please try again in 972ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 599, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9601, Requested 527. Please try again in 768ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 30%|███       | 600/2000 [30:26<55:29,  2.38s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 600, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 30%|███       | 601/2000 [30:27<43:09,  1.85s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9827, Requested 397. Please try again in 1.344s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 601, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 30%|███       | 602/2000 [30:29<46:46,  2.01s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9810, Requested 294. Please try again in 624ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 2.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9795, Requested 294. Please try again in 534ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 602, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 30%|███       | 603/2000 [30:32<52:48,  2.27s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 603, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 30%|███       | 604/2000 [30:33<41:47,  1.80s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9835, Requested 286. Please try again in 726ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 604, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9783, Requested 286. Please try again in 414ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 30%|███       | 605/2000 [30:36<52:50,  2.27s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 605, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 30%|███       | 606/2000 [30:37<40:09,  1.73s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9764, Requested 313. Please try again in 462ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 606, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 30%|███       | 607/2000 [30:39<41:08,  1.77s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9760, Requested 339. Please try again in 594ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 607, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9701, Requested 339. Please try again in 240ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 30%|███       | 608/2000 [30:43<57:02,  2.46s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 608, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 30%|███       | 609/2000 [30:43<43:12,  1.86s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 609, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 30%|███       | 610/2000 [30:44<36:11,  1.56s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9804, Requested 443. Please try again in 1.482s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 610, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 31%|███       | 611/2000 [30:47<44:13,  1.91s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9776, Requested 325. Please try again in 606ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 611, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 31%|███       | 612/2000 [30:49<44:28,  1.92s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9776, Requested 323. Please try again in 594ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 612, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 31%|███       | 613/2000 [30:50<43:09,  1.87s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9807, Requested 333. Please try again in 840ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 613, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9756, Requested 333. Please try again in 534ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 31%|███       | 614/2000 [30:53<47:26,  2.05s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9722, Requested 310. Please try again in 192ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 614, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 31%|███       | 615/2000 [30:54<42:58,  1.86s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9788, Requested 616. Please try again in 2.424s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 615, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9692, Requested 616. Please try again in 1.848s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 31%|███       | 616/2000 [30:58<57:43,  2.50s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9676, Requested 402. Please try again in 468ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 616, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 31%|███       | 617/2000 [31:00<50:28,  2.19s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9808, Requested 287. Please try again in 570ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 617, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 31%|███       | 618/2000 [31:02<49:46,  2.16s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9741, Requested 360. Please try again in 606ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 618, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 31%|███       | 619/2000 [31:04<48:25,  2.10s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9765, Requested 338. Please try again in 618ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 619, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 31%|███       | 620/2000 [31:06<50:27,  2.19s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9701, Requested 329. Please try again in 180ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 620, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 31%|███       | 621/2000 [31:07<41:50,  1.82s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9858, Requested 320. Please try again in 1.068s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 621, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9718, Requested 320. Please try again in 228ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 31%|███       | 622/2000 [31:13<1:06:35,  2.90s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 622, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 31%|███       | 623/2000 [31:13<52:11,  2.27s/it]  "
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 623, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 31%|███       | 624/2000 [31:14<42:11,  1.84s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9643, Requested 836. Please try again in 2.874s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 624, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9374, Requested 836. Please try again in 1.26s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 2.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9189, Requested 836. Please try again in 150ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 31%|███▏      | 625/2000 [31:21<1:15:07,  3.28s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 625, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 31%|███▏      | 626/2000 [31:22<1:01:54,  2.70s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 626, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 31%|███▏      | 627/2000 [31:23<49:04,  2.14s/it]  INFO:backoff:Backing off get_labels_batch(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9733, Requested 294. Please try again in 162ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 627, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 31%|███▏      | 628/2000 [31:24<43:26,  1.90s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9800, Requested 315. Please try again in 690ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 628, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 31%|███▏      | 629/2000 [31:26<43:29,  1.90s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9795, Requested 336. Please try again in 786ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 629, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 32%|███▏      | 630/2000 [31:28<40:20,  1.77s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9888, Requested 367. Please try again in 1.53s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 630, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 32%|███▏      | 631/2000 [31:30<45:14,  1.98s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9842, Requested 311. Please try again in 918ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 631, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 32%|███▏      | 632/2000 [31:32<44:35,  1.96s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9839, Requested 295. Please try again in 804ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 632, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 32%|███▏      | 633/2000 [31:34<42:35,  1.87s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9850, Requested 401. Please try again in 1.506s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 633, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9768, Requested 401. Please try again in 1.013s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 32%|███▏      | 634/2000 [31:37<48:57,  2.15s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9759, Requested 314. Please try again in 438ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 634, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 32%|███▏      | 635/2000 [31:38<43:42,  1.92s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9846, Requested 316. Please try again in 972ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 635, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9743, Requested 316. Please try again in 354ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 32%|███▏      | 636/2000 [31:43<1:00:48,  2.68s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 636, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 32%|███▏      | 637/2000 [31:43<46:55,  2.07s/it]  INFO:backoff:Backing off get_labels_batch(...) for 1.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9647, Requested 414. Please try again in 366ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 637, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 32%|███▏      | 638/2000 [31:46<51:32,  2.27s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 638, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 32%|███▏      | 639/2000 [31:46<38:48,  1.71s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9901, Requested 269. Please try again in 1.02s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 639, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9732, Requested 269. Please try again in 6ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 32%|███▏      | 640/2000 [31:50<50:32,  2.23s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 640, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 32%|███▏      | 641/2000 [31:50<39:30,  1.74s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9809, Requested 365. Please try again in 1.044s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 641, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9747, Requested 365. Please try again in 672ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 32%|███▏      | 642/2000 [31:53<47:00,  2.08s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9694, Requested 355. Please try again in 294ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 642, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9656, Requested 355. Please try again in 66ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 32%|███▏      | 643/2000 [31:54<41:21,  1.83s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9842, Requested 305. Please try again in 882ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 643, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9778, Requested 305. Please try again in 498ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 32%|███▏      | 644/2000 [31:57<46:33,  2.06s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9711, Requested 324. Please try again in 210ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 644, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 32%|███▏      | 645/2000 [31:59<44:53,  1.99s/it]INFO:backoff:Backing off get_labels_batch(...) for 2.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9734, Requested 389. Please try again in 738ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 645, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 32%|███▏      | 646/2000 [32:02<51:13,  2.27s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 646, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 32%|███▏      | 647/2000 [32:02<38:45,  1.72s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9872, Requested 329. Please try again in 1.206s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 647, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9790, Requested 329. Please try again in 714ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 32%|███▏      | 648/2000 [32:07<1:01:30,  2.73s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 648, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 32%|███▏      | 649/2000 [32:08<47:41,  2.12s/it]  INFO:backoff:Backing off get_labels_batch(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9562, Requested 449. Please try again in 66ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 649, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 32%|███▎      | 650/2000 [32:09<43:13,  1.92s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9743, Requested 417. Please try again in 960ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 650, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9620, Requested 417. Please try again in 222ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 33%|███▎      | 651/2000 [32:13<56:56,  2.53s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 651, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 33%|███▎      | 652/2000 [32:14<44:19,  1.97s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9700, Requested 309. Please try again in 54ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 652, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 33%|███▎      | 653/2000 [32:16<45:48,  2.04s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 653, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 33%|███▎      | 654/2000 [32:17<35:53,  1.60s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9861, Requested 364. Please try again in 1.35s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 654, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9711, Requested 364. Please try again in 450ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 33%|███▎      | 655/2000 [32:19<39:31,  1.76s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9851, Requested 983. Please try again in 5.004s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 655, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9565, Requested 983. Please try again in 3.288s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 33%|███▎      | 656/2000 [32:25<1:06:57,  2.99s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9761, Requested 357. Please try again in 708ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 656, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 33%|███▎      | 657/2000 [32:28<1:05:22,  2.92s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9644, Requested 373. Please try again in 102ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 657, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 33%|███▎      | 658/2000 [32:30<1:03:40,  2.85s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 658, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 33%|███▎      | 659/2000 [32:31<48:16,  2.16s/it]  INFO:backoff:Backing off get_labels_batch(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9771, Requested 533. Please try again in 1.824s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 659, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9678, Requested 533. Please try again in 1.266s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 33%|███▎      | 660/2000 [32:33<49:06,  2.20s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9889, Requested 285. Please try again in 1.044s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 660, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 33%|███▎      | 661/2000 [32:35<47:33,  2.13s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9845, Requested 338. Please try again in 1.098s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 661, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9788, Requested 338. Please try again in 756ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 33%|███▎      | 662/2000 [32:38<54:32,  2.45s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9653, Requested 366. Please try again in 114ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 662, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 33%|███▎      | 663/2000 [32:40<50:11,  2.25s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 663, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 33%|███▎      | 664/2000 [32:41<37:56,  1.70s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9914, Requested 312. Please try again in 1.356s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 664, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9893, Requested 312. Please try again in 1.23s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 33%|███▎      | 665/2000 [32:45<56:08,  2.52s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 665, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 33%|███▎      | 666/2000 [32:47<52:00,  2.34s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 666, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 33%|███▎      | 667/2000 [32:48<41:33,  1.87s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9834, Requested 290. Please try again in 744ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 667, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 33%|███▎      | 668/2000 [32:50<44:35,  2.01s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9733, Requested 335. Please try again in 408ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 668, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 33%|███▎      | 669/2000 [32:52<41:20,  1.86s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9811, Requested 339. Please try again in 900ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 669, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 34%|███▎      | 670/2000 [32:54<43:18,  1.95s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9785, Requested 347. Please try again in 792ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 670, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 34%|███▎      | 671/2000 [32:55<42:19,  1.91s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9829, Requested 381. Please try again in 1.26s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 671, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9758, Requested 381. Please try again in 834ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 34%|███▎      | 672/2000 [32:58<43:45,  1.98s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9853, Requested 311. Please try again in 984ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 672, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 34%|███▎      | 673/2000 [32:59<40:28,  1.83s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9910, Requested 355. Please try again in 1.59s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 673, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9661, Requested 355. Please try again in 96ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 34%|███▎      | 674/2000 [33:02<48:04,  2.18s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9766, Requested 282. Please try again in 288ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 674, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 34%|███▍      | 675/2000 [33:03<40:36,  1.84s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9879, Requested 278. Please try again in 941ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 675, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 34%|███▍      | 676/2000 [33:05<40:08,  1.82s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9858, Requested 351. Please try again in 1.254s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 676, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9817, Requested 351. Please try again in 1.007s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 34%|███▍      | 677/2000 [33:08<46:28,  2.11s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9729, Requested 276. Please try again in 30ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 677, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 34%|███▍      | 678/2000 [33:09<44:20,  2.01s/it]INFO:backoff:Backing off get_labels_batch(...) for 2.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9709, Requested 293. Please try again in 12ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 678, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 34%|███▍      | 679/2000 [33:12<47:00,  2.14s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 679, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 34%|███▍      | 680/2000 [33:13<38:15,  1.74s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9737, Requested 278. Please try again in 90ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 680, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 34%|███▍      | 681/2000 [33:14<36:08,  1.64s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9784, Requested 317. Please try again in 606ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 681, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 34%|███▍      | 682/2000 [33:16<35:55,  1.64s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9822, Requested 282. Please try again in 624ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 682, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9753, Requested 282. Please try again in 210ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 34%|███▍      | 683/2000 [33:17<33:40,  1.53s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9896, Requested 299. Please try again in 1.17s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 683, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9726, Requested 299. Please try again in 150ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 34%|███▍      | 684/2000 [33:20<41:12,  1.88s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9749, Requested 327. Please try again in 456ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 684, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 34%|███▍      | 685/2000 [33:21<38:59,  1.78s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9820, Requested 360. Please try again in 1.08s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 685, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 34%|███▍      | 686/2000 [33:24<46:48,  2.14s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 686, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 34%|███▍      | 687/2000 [33:25<35:11,  1.61s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9904, Requested 559. Please try again in 2.778s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 687, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9867, Requested 559. Please try again in 2.556s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 2.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9492, Requested 559. Please try again in 306ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 34%|███▍      | 688/2000 [33:31<1:04:37,  2.96s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 688, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 34%|███▍      | 689/2000 [33:32<50:47,  2.32s/it]  "
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 689, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 34%|███▍      | 690/2000 [33:33<41:33,  1.90s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9825, Requested 309. Please try again in 804ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 690, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9789, Requested 309. Please try again in 588ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 35%|███▍      | 691/2000 [33:34<41:10,  1.89s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9827, Requested 599. Please try again in 2.556s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 691, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9791, Requested 599. Please try again in 2.34s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 35%|███▍      | 692/2000 [33:38<54:40,  2.51s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9749, Requested 336. Please try again in 510ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 3.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9732, Requested 336. Please try again in 408ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 692, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 35%|███▍      | 693/2000 [33:42<1:03:45,  2.93s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 693, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 35%|███▍      | 694/2000 [33:43<49:47,  2.29s/it]  "
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 694, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 35%|███▍      | 695/2000 [33:44<38:27,  1.77s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9806, Requested 316. Please try again in 732ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 695, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 35%|███▍      | 696/2000 [33:45<36:11,  1.67s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9879, Requested 303. Please try again in 1.092s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 696, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 35%|███▍      | 697/2000 [33:47<41:37,  1.92s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9762, Requested 304. Please try again in 396ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 697, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 35%|███▍      | 698/2000 [33:50<43:52,  2.02s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9685, Requested 319. Please try again in 24ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 698, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 35%|███▍      | 699/2000 [33:51<39:19,  1.81s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9779, Requested 308. Please try again in 522ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 699, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 35%|███▌      | 700/2000 [33:53<41:01,  1.89s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9734, Requested 279. Please try again in 78ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 700, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 35%|███▌      | 701/2000 [33:55<39:34,  1.83s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9740, Requested 322. Please try again in 372ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 701, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 35%|███▌      | 702/2000 [33:57<40:16,  1.86s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9737, Requested 284. Please try again in 125ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 702, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 35%|███▌      | 703/2000 [33:58<38:35,  1.79s/it]INFO:backoff:Backing off get_labels_batch(...) for 2.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9756, Requested 299. Please try again in 330ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 703, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 35%|███▌      | 704/2000 [34:01<43:41,  2.02s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 704, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 35%|███▌      | 705/2000 [34:02<35:39,  1.65s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9778, Requested 298. Please try again in 456ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 705, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 35%|███▌      | 706/2000 [34:04<41:40,  1.93s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 706, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 35%|███▌      | 707/2000 [34:05<33:20,  1.55s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9838, Requested 275. Please try again in 678ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 707, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9768, Requested 275. Please try again in 258ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 35%|███▌      | 708/2000 [34:09<52:17,  2.43s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 708, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 35%|███▌      | 709/2000 [34:10<42:44,  1.99s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 709, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 36%|███▌      | 710/2000 [34:11<34:30,  1.61s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9814, Requested 348. Please try again in 972ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 710, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9708, Requested 348. Please try again in 336ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 36%|███▌      | 711/2000 [34:13<38:23,  1.79s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9776, Requested 338. Please try again in 684ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 711, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9744, Requested 338. Please try again in 492ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 36%|███▌      | 712/2000 [34:15<37:41,  1.76s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9826, Requested 362. Please try again in 1.128s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 712, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 36%|███▌      | 713/2000 [34:17<40:27,  1.89s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9810, Requested 371. Please try again in 1.086s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 713, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9744, Requested 371. Please try again in 690ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 36%|███▌      | 714/2000 [34:22<1:01:05,  2.85s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 714, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 36%|███▌      | 715/2000 [34:23<48:06,  2.25s/it]  "
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 715, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 36%|███▌      | 716/2000 [34:24<37:11,  1.74s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9717, Requested 403. Please try again in 720ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 716, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 36%|███▌      | 717/2000 [34:26<41:26,  1.94s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9715, Requested 375. Please try again in 540ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 717, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 36%|███▌      | 718/2000 [34:28<38:25,  1.80s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9825, Requested 293. Please try again in 708ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 718, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 36%|███▌      | 719/2000 [34:29<38:50,  1.82s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9802, Requested 275. Please try again in 462ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 719, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 36%|███▌      | 720/2000 [34:31<37:18,  1.75s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9816, Requested 418. Please try again in 1.404s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 720, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9602, Requested 418. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 36%|███▌      | 721/2000 [34:36<1:00:54,  2.86s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 721, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 36%|███▌      | 722/2000 [34:37<47:57,  2.25s/it]  INFO:backoff:Backing off get_labels_batch(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9631, Requested 455. Please try again in 516ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 722, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 36%|███▌      | 723/2000 [34:39<43:03,  2.02s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9812, Requested 295. Please try again in 642ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 723, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 36%|███▌      | 724/2000 [34:40<39:06,  1.84s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9871, Requested 530. Please try again in 2.406s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 724, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9839, Requested 530. Please try again in 2.214s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 36%|███▋      | 725/2000 [34:44<53:50,  2.53s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9661, Requested 782. Please try again in 2.658s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 725, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9538, Requested 782. Please try again in 1.92s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 36%|███▋      | 726/2000 [34:48<1:03:15,  2.98s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 726, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 36%|███▋      | 727/2000 [34:49<49:19,  2.32s/it]  INFO:backoff:Backing off get_labels_batch(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9814, Requested 315. Please try again in 774ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 727, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 36%|███▋      | 728/2000 [34:51<44:54,  2.12s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9857, Requested 272. Please try again in 774ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 728, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 36%|███▋      | 729/2000 [34:53<42:40,  2.01s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9838, Requested 373. Please try again in 1.266s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 729, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9730, Requested 373. Please try again in 618ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 36%|███▋      | 730/2000 [34:56<48:20,  2.28s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 730, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 37%|███▋      | 731/2000 [34:56<39:04,  1.85s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9861, Requested 273. Please try again in 804ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 731, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9746, Requested 273. Please try again in 114ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 37%|███▋      | 732/2000 [34:58<39:50,  1.89s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9806, Requested 288. Please try again in 564ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 732, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 37%|███▋      | 733/2000 [35:00<37:27,  1.77s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9844, Requested 313. Please try again in 941ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 733, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 37%|███▋      | 734/2000 [35:02<41:59,  1.99s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9750, Requested 642. Please try again in 2.352s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 734, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9423, Requested 642. Please try again in 390ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 37%|███▋      | 735/2000 [35:07<58:03,  2.75s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 735, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 37%|███▋      | 736/2000 [35:07<44:33,  2.12s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9792, Requested 292. Please try again in 503ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 736, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 37%|███▋      | 737/2000 [35:10<44:19,  2.11s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9731, Requested 355. Please try again in 516ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 737, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9660, Requested 355. Please try again in 90ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 37%|███▋      | 738/2000 [35:12<47:57,  2.28s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 738, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 37%|███▋      | 739/2000 [35:13<37:02,  1.76s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9826, Requested 315. Please try again in 846ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 739, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 37%|███▋      | 740/2000 [35:15<42:05,  2.00s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9712, Requested 326. Please try again in 228ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 740, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 37%|███▋      | 741/2000 [35:17<41:40,  1.99s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9710, Requested 333. Please try again in 258ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 741, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9673, Requested 333. Please try again in 36ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 37%|███▋      | 742/2000 [35:22<58:28,  2.79s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 742, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 37%|███▋      | 743/2000 [35:23<45:07,  2.15s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 743, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 37%|███▋      | 744/2000 [35:23<35:21,  1.69s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9762, Requested 384. Please try again in 876ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 744, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 37%|███▋      | 745/2000 [35:25<35:00,  1.67s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9856, Requested 333. Please try again in 1.134s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 745, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9718, Requested 333. Please try again in 306ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 37%|███▋      | 746/2000 [35:27<40:26,  1.93s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9763, Requested 330. Please try again in 558ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 746, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 37%|███▋      | 747/2000 [35:28<34:39,  1.66s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9920, Requested 392. Please try again in 1.872s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 2.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9903, Requested 392. Please try again in 1.77s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 747, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 37%|███▋      | 748/2000 [35:32<47:07,  2.26s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 748, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 37%|███▋      | 749/2000 [35:33<36:34,  1.75s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9894, Requested 402. Please try again in 1.776s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 749, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9657, Requested 402. Please try again in 354ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 38%|███▊      | 750/2000 [35:38<1:00:29,  2.90s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 750, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 38%|███▊      | 751/2000 [35:39<46:30,  2.23s/it]  "
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 751, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 38%|███▊      | 752/2000 [35:39<35:07,  1.69s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9818, Requested 382. Please try again in 1.2s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 752, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 38%|███▊      | 753/2000 [35:41<36:22,  1.75s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9876, Requested 408. Please try again in 1.704s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 753, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9617, Requested 408. Please try again in 150ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 38%|███▊      | 754/2000 [35:46<55:54,  2.69s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 754, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 38%|███▊      | 755/2000 [35:47<42:28,  2.05s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9724, Requested 303. Please try again in 162ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 755, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 38%|███▊      | 756/2000 [35:48<35:55,  1.73s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9867, Requested 302. Please try again in 1.013s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 756, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 38%|███▊      | 757/2000 [35:50<42:20,  2.04s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9714, Requested 379. Please try again in 558ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 757, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9668, Requested 379. Please try again in 282ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 38%|███▊      | 758/2000 [35:55<54:48,  2.65s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 758, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 38%|███▊      | 759/2000 [35:55<41:54,  2.03s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9722, Requested 294. Please try again in 96ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 759, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 38%|███▊      | 760/2000 [35:56<36:14,  1.75s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9832, Requested 340. Please try again in 1.032s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 760, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9751, Requested 340. Please try again in 546ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 38%|███▊      | 761/2000 [36:00<49:05,  2.38s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 761, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 38%|███▊      | 762/2000 [36:00<36:45,  1.78s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9755, Requested 274. Please try again in 174ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 762, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 38%|███▊      | 763/2000 [36:02<35:52,  1.74s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9757, Requested 300. Please try again in 342ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 763, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 38%|███▊      | 764/2000 [36:04<37:34,  1.82s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9720, Requested 341. Please try again in 366ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 764, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 38%|███▊      | 765/2000 [36:05<33:57,  1.65s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9841, Requested 321. Please try again in 972ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 765, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 38%|███▊      | 766/2000 [36:08<37:12,  1.81s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9795, Requested 324. Please try again in 714ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 766, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9774, Requested 324. Please try again in 588ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 6.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9731, Requested 324. Please try again in 330ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 38%|███▊      | 767/2000 [36:15<1:13:22,  3.57s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 767, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 38%|███▊      | 768/2000 [36:16<54:25,  2.65s/it]  "
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 768, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 38%|███▊      | 769/2000 [36:16<40:38,  1.98s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 769, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 38%|███▊      | 770/2000 [36:17<31:06,  1.52s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9615, Requested 570. Please try again in 1.11s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 770, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9558, Requested 570. Please try again in 768ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 39%|███▊      | 771/2000 [36:19<37:03,  1.81s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9737, Requested 469. Please try again in 1.236s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 771, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9664, Requested 469. Please try again in 798ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 8.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9615, Requested 469. Please try again in 503ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 39%|███▊      | 772/2000 [36:29<1:25:15,  4.17s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 772, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 39%|███▊      | 773/2000 [36:29<1:03:49,  3.12s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 773, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 39%|███▊      | 774/2000 [36:30<48:24,  2.37s/it]  "
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 774, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 39%|███▉      | 775/2000 [36:31<39:40,  1.94s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 775, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 39%|███▉      | 776/2000 [36:32<32:01,  1.57s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 776, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 39%|███▉      | 777/2000 [36:32<26:20,  1.29s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 777, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 39%|███▉      | 778/2000 [36:33<22:42,  1.11s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9764, Requested 368. Please try again in 792ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 778, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 39%|███▉      | 779/2000 [36:35<26:25,  1.30s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9842, Requested 320. Please try again in 972ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 779, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9764, Requested 320. Please try again in 503ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 4.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9732, Requested 320. Please try again in 312ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 39%|███▉      | 780/2000 [36:40<53:29,  2.63s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 780, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 39%|███▉      | 781/2000 [36:41<40:49,  2.01s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9769, Requested 440. Please try again in 1.254s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 781, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9680, Requested 440. Please try again in 720ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 39%|███▉      | 782/2000 [36:44<44:05,  2.17s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9769, Requested 351. Please try again in 720ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 782, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 39%|███▉      | 783/2000 [36:45<39:00,  1.92s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9890, Requested 349. Please try again in 1.434s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 783, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9779, Requested 349. Please try again in 768ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 39%|███▉      | 784/2000 [36:50<55:03,  2.72s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 784, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 39%|███▉      | 785/2000 [36:50<42:26,  2.10s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 785, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 39%|███▉      | 786/2000 [36:51<32:08,  1.59s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9923, Requested 286. Please try again in 1.254s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 786, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9786, Requested 286. Please try again in 432ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 39%|███▉      | 787/2000 [36:53<38:23,  1.90s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9771, Requested 327. Please try again in 588ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 787, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9715, Requested 327. Please try again in 251ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 39%|███▉      | 788/2000 [36:55<36:00,  1.78s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9847, Requested 368. Please try again in 1.29s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 788, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9651, Requested 368. Please try again in 114ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 39%|███▉      | 789/2000 [37:00<58:28,  2.90s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 789, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 40%|███▉      | 790/2000 [37:01<44:26,  2.20s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 790, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 40%|███▉      | 791/2000 [37:01<34:41,  1.72s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9731, Requested 296. Please try again in 162ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 791, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 40%|███▉      | 792/2000 [37:03<31:07,  1.55s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9839, Requested 282. Please try again in 726ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 792, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 40%|███▉      | 793/2000 [37:04<32:32,  1.62s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9824, Requested 335. Please try again in 954ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 793, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 40%|███▉      | 794/2000 [37:06<34:58,  1.74s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9799, Requested 394. Please try again in 1.158s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 794, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 40%|███▉      | 795/2000 [37:08<37:10,  1.85s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9839, Requested 280. Please try again in 714ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 795, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 40%|███▉      | 796/2000 [37:11<41:05,  2.05s/it]INFO:backoff:Backing off get_labels_batch(...) for 2.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9706, Requested 876. Please try again in 3.492s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 796, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9362, Requested 876. Please try again in 1.428s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9303, Requested 876. Please try again in 1.074s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 40%|███▉      | 797/2000 [37:16<56:41,  2.83s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9708, Requested 423. Please try again in 786ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 797, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 40%|███▉      | 798/2000 [37:17<50:43,  2.53s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9812, Requested 608. Please try again in 2.52s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 798, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9769, Requested 608. Please try again in 2.262s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 40%|███▉      | 799/2000 [37:22<1:04:09,  3.21s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 799, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 40%|████      | 800/2000 [37:23<47:56,  2.40s/it]  INFO:backoff:Backing off get_labels_batch(...) for 1.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9882, Requested 616. Please try again in 2.988s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 800, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9570, Requested 616. Please try again in 1.116s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 2.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9432, Requested 616. Please try again in 288ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 40%|████      | 801/2000 [37:28<1:05:25,  3.27s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 801, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 40%|████      | 802/2000 [37:29<48:47,  2.44s/it]  INFO:backoff:Backing off get_labels_batch(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9763, Requested 315. Please try again in 468ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 802, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 40%|████      | 803/2000 [37:30<45:17,  2.27s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9764, Requested 328. Please try again in 552ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 803, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 40%|████      | 804/2000 [37:32<41:03,  2.06s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9825, Requested 313. Please try again in 828ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 804, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9782, Requested 313. Please try again in 570ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 6.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9745, Requested 313. Please try again in 348ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 40%|████      | 805/2000 [37:40<1:16:47,  3.86s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 805, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 40%|████      | 806/2000 [37:41<58:10,  2.92s/it]  "
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 806, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 40%|████      | 807/2000 [37:41<43:50,  2.20s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 807, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 40%|████      | 808/2000 [37:42<33:23,  1.68s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9501, Requested 514. Please try again in 90ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 808, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 40%|████      | 809/2000 [37:44<34:19,  1.73s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9661, Requested 493. Please try again in 924ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 809, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9519, Requested 493. Please try again in 72ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 40%|████      | 810/2000 [37:48<49:27,  2.49s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 810, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 41%|████      | 811/2000 [37:48<37:44,  1.90s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9626, Requested 377. Please try again in 18ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 811, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 41%|████      | 812/2000 [37:51<39:44,  2.01s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 812, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 41%|████      | 813/2000 [37:51<30:41,  1.55s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9839, Requested 362. Please try again in 1.206s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 813, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9716, Requested 362. Please try again in 468ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 41%|████      | 814/2000 [37:54<41:15,  2.09s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 814, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 41%|████      | 815/2000 [37:55<32:01,  1.62s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9881, Requested 272. Please try again in 918ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 815, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 41%|████      | 816/2000 [37:57<35:47,  1.81s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9779, Requested 340. Please try again in 714ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 816, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 41%|████      | 817/2000 [37:59<33:26,  1.70s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9880, Requested 374. Please try again in 1.524s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 817, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9851, Requested 374. Please try again in 1.35s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 41%|████      | 818/2000 [38:03<51:10,  2.60s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 818, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 41%|████      | 819/2000 [38:04<38:36,  1.96s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9784, Requested 298. Please try again in 492ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 819, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 41%|████      | 820/2000 [38:07<43:30,  2.21s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 820, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 41%|████      | 821/2000 [38:08<35:33,  1.81s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9811, Requested 303. Please try again in 684ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 821, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 41%|████      | 822/2000 [38:10<40:24,  2.06s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9670, Requested 436. Please try again in 636ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 822, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9610, Requested 436. Please try again in 276ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 41%|████      | 823/2000 [38:13<45:00,  2.29s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 823, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 41%|████      | 824/2000 [38:14<36:38,  1.87s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9779, Requested 318. Please try again in 582ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 824, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 41%|████▏     | 825/2000 [38:15<34:49,  1.78s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9828, Requested 384. Please try again in 1.272s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 825, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9625, Requested 384. Please try again in 54ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 41%|████▏     | 826/2000 [38:18<38:06,  1.95s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9816, Requested 286. Please try again in 612ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 826, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 41%|████▏     | 827/2000 [38:20<37:22,  1.91s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9801, Requested 402. Please try again in 1.218s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 827, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9726, Requested 402. Please try again in 768ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 6.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9702, Requested 402. Please try again in 624ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 41%|████▏     | 828/2000 [38:27<1:10:41,  3.62s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 828, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 41%|████▏     | 829/2000 [38:28<55:12,  2.83s/it]  "
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 829, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 42%|████▏     | 830/2000 [38:29<41:57,  2.15s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 830, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 42%|████▏     | 831/2000 [38:29<32:39,  1.68s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9660, Requested 347. Please try again in 42ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 831, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 42%|████▏     | 832/2000 [38:30<27:11,  1.40s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9886, Requested 276. Please try again in 972ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 832, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 42%|████▏     | 833/2000 [38:32<32:24,  1.67s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9782, Requested 476. Please try again in 1.548s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 833, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9749, Requested 476. Please try again in 1.35s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9619, Requested 476. Please try again in 570ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 42%|████▏     | 834/2000 [38:35<38:59,  2.01s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9764, Requested 340. Please try again in 624ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 834, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9690, Requested 340. Please try again in 180ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 42%|████▏     | 835/2000 [38:39<46:39,  2.40s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 835, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 42%|████▏     | 836/2000 [38:39<36:32,  1.88s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9719, Requested 294. Please try again in 78ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 836, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 42%|████▏     | 837/2000 [38:41<34:12,  1.76s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9764, Requested 280. Please try again in 264ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 837, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 42%|████▏     | 838/2000 [38:43<35:51,  1.85s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 838, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 42%|████▏     | 839/2000 [38:43<28:05,  1.45s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9918, Requested 293. Please try again in 1.266s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 839, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9834, Requested 293. Please try again in 762ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 42%|████▏     | 840/2000 [38:46<33:49,  1.75s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9810, Requested 301. Please try again in 666ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 840, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9774, Requested 301. Please try again in 450ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 42%|████▏     | 841/2000 [38:48<35:42,  1.85s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9760, Requested 306. Please try again in 396ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 841, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 42%|████▏     | 842/2000 [38:50<37:55,  1.97s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9698, Requested 345. Please try again in 258ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 842, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 42%|████▏     | 843/2000 [38:52<38:25,  1.99s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9703, Requested 324. Please try again in 162ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 843, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 42%|████▏     | 844/2000 [38:54<40:47,  2.12s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9622, Requested 590. Please try again in 1.272s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 844, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 42%|████▏     | 845/2000 [38:57<42:26,  2.20s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9770, Requested 323. Please try again in 558ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 845, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 42%|████▏     | 846/2000 [38:59<39:49,  2.07s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9803, Requested 284. Please try again in 522ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 846, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 42%|████▏     | 847/2000 [39:01<42:16,  2.20s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9675, Requested 363. Please try again in 228ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 847, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 42%|████▏     | 848/2000 [39:02<34:34,  1.80s/it]INFO:backoff:Backing off get_labels_batch(...) for 2.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9883, Requested 296. Please try again in 1.074s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 848, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 42%|████▏     | 849/2000 [39:05<40:48,  2.13s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9688, Requested 359. Please try again in 282ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 849, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 42%|████▎     | 850/2000 [39:06<36:15,  1.89s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9811, Requested 303. Please try again in 684ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 850, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 43%|████▎     | 851/2000 [39:08<32:38,  1.70s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 851, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9914, Requested 309. Please try again in 1.338s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 43%|████▎     | 852/2000 [39:10<36:24,  1.90s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9833, Requested 463. Please try again in 1.776s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 852, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9801, Requested 463. Please try again in 1.584s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 3.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9546, Requested 463. Please try again in 54ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 43%|████▎     | 853/2000 [39:16<59:11,  3.10s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 853, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 43%|████▎     | 854/2000 [39:17<45:44,  2.39s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9499, Requested 530. Please try again in 174ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 854, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 43%|████▎     | 855/2000 [39:18<39:41,  2.08s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9774, Requested 358. Please try again in 792ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 855, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 43%|████▎     | 856/2000 [39:20<38:25,  2.02s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9815, Requested 358. Please try again in 1.038s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 856, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9671, Requested 358. Please try again in 174ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 43%|████▎     | 857/2000 [39:22<38:52,  2.04s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9800, Requested 282. Please try again in 492ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 857, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 43%|████▎     | 858/2000 [39:24<41:46,  2.20s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 858, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 43%|████▎     | 859/2000 [39:25<34:47,  1.83s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9822, Requested 381. Please try again in 1.218s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 859, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9750, Requested 381. Please try again in 786ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 4.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9635, Requested 381. Please try again in 96ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 43%|████▎     | 860/2000 [39:31<58:43,  3.09s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 860, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 43%|████▎     | 861/2000 [39:32<43:40,  2.30s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 861, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 43%|████▎     | 862/2000 [39:32<33:40,  1.78s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9737, Requested 293. Please try again in 180ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 862, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 43%|████▎     | 863/2000 [39:34<31:00,  1.64s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9813, Requested 282. Please try again in 570ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 863, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9770, Requested 282. Please try again in 312ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 43%|████▎     | 864/2000 [39:38<45:54,  2.42s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 864, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 43%|████▎     | 865/2000 [39:38<34:24,  1.82s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9679, Requested 492. Please try again in 1.026s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 865, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 43%|████▎     | 866/2000 [39:40<33:54,  1.79s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9834, Requested 482. Please try again in 1.896s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 866, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9564, Requested 482. Please try again in 276ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 43%|████▎     | 867/2000 [39:46<57:53,  3.07s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 867, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 43%|████▎     | 868/2000 [39:47<44:15,  2.35s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 868, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 43%|████▎     | 869/2000 [39:48<35:58,  1.91s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9819, Requested 518. Please try again in 2.022s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 869, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9564, Requested 518. Please try again in 492ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 44%|████▎     | 870/2000 [39:51<41:12,  2.19s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9824, Requested 389. Please try again in 1.278s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 870, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9719, Requested 389. Please try again in 648ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 44%|████▎     | 871/2000 [39:56<58:50,  3.13s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 871, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 44%|████▎     | 872/2000 [39:56<44:21,  2.36s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 872, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 44%|████▎     | 873/2000 [39:57<34:24,  1.83s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9807, Requested 332. Please try again in 834ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 873, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 44%|████▎     | 874/2000 [39:59<36:09,  1.93s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9766, Requested 327. Please try again in 558ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 874, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9712, Requested 327. Please try again in 234ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 44%|████▍     | 875/2000 [40:04<52:41,  2.81s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 875, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 44%|████▍     | 876/2000 [40:05<40:58,  2.19s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 876, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 44%|████▍     | 877/2000 [40:06<32:39,  1.74s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9748, Requested 288. Please try again in 216ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 877, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 44%|████▍     | 878/2000 [40:08<33:58,  1.82s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9711, Requested 525. Please try again in 1.416s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 878, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 44%|████▍     | 879/2000 [40:10<37:30,  2.01s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9783, Requested 286. Please try again in 414ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 879, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9746, Requested 286. Please try again in 192ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 44%|████▍     | 880/2000 [40:11<32:44,  1.75s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9884, Requested 383. Please try again in 1.602s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 880, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9729, Requested 383. Please try again in 672ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 44%|████▍     | 881/2000 [40:14<38:59,  2.09s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9776, Requested 323. Please try again in 594ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 881, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 44%|████▍     | 882/2000 [40:16<36:27,  1.96s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9817, Requested 290. Please try again in 642ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 882, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9726, Requested 290. Please try again in 96ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 44%|████▍     | 883/2000 [40:21<54:18,  2.92s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 883, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 44%|████▍     | 884/2000 [40:21<40:32,  2.18s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 884, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 44%|████▍     | 885/2000 [40:22<30:27,  1.64s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9754, Requested 312. Please try again in 396ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 885, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9711, Requested 312. Please try again in 138ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 44%|████▍     | 886/2000 [40:24<36:55,  1.99s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 886, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 44%|████▍     | 887/2000 [40:25<27:55,  1.51s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9832, Requested 323. Please try again in 930ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 887, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 44%|████▍     | 888/2000 [40:27<33:51,  1.83s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9730, Requested 397. Please try again in 762ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 888, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 44%|████▍     | 889/2000 [40:29<33:30,  1.81s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9825, Requested 362. Please try again in 1.122s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 889, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 44%|████▍     | 890/2000 [40:32<37:29,  2.03s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9756, Requested 350. Please try again in 636ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 890, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 45%|████▍     | 891/2000 [40:33<34:40,  1.88s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9842, Requested 330. Please try again in 1.032s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 891, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9804, Requested 330. Please try again in 804ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 5.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9678, Requested 330. Please try again in 48ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 45%|████▍     | 892/2000 [40:41<1:06:20,  3.59s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 892, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 45%|████▍     | 893/2000 [40:41<48:35,  2.63s/it]  "
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 893, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 45%|████▍     | 894/2000 [40:42<36:09,  1.96s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 894, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 45%|████▍     | 895/2000 [40:42<29:05,  1.58s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 895, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 45%|████▍     | 896/2000 [40:43<23:37,  1.28s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9880, Requested 483. Please try again in 2.178s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 896, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9862, Requested 483. Please try again in 2.07s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 45%|████▍     | 897/2000 [40:48<41:57,  2.28s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 897, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 45%|████▍     | 898/2000 [40:48<32:46,  1.78s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9813, Requested 308. Please try again in 726ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 898, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9703, Requested 308. Please try again in 66ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 45%|████▍     | 899/2000 [40:51<37:00,  2.02s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9704, Requested 841. Please try again in 3.27s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 899, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9368, Requested 841. Please try again in 1.254s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 45%|████▌     | 900/2000 [40:57<1:01:36,  3.36s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 900, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 45%|████▌     | 901/2000 [40:58<45:43,  2.50s/it]  INFO:backoff:Backing off get_labels_batch(...) for 1.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9627, Requested 428. Please try again in 330ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 901, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 45%|████▌     | 902/2000 [41:00<44:53,  2.45s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 902, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 45%|████▌     | 903/2000 [41:01<35:08,  1.92s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9858, Requested 309. Please try again in 1.002s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 903, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 45%|████▌     | 904/2000 [41:03<36:40,  2.01s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9802, Requested 435. Please try again in 1.422s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 904, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 45%|████▌     | 905/2000 [41:05<37:03,  2.03s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9867, Requested 356. Please try again in 1.338s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 905, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9663, Requested 356. Please try again in 114ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 45%|████▌     | 906/2000 [41:10<50:59,  2.80s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 906, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 45%|████▌     | 907/2000 [41:10<39:23,  2.16s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9640, Requested 363. Please try again in 18ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 907, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 45%|████▌     | 908/2000 [41:12<37:49,  2.08s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9667, Requested 372. Please try again in 234ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 908, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 45%|████▌     | 909/2000 [41:13<30:05,  1.65s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9920, Requested 422. Please try again in 2.052s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 909, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9652, Requested 422. Please try again in 444ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 46%|████▌     | 910/2000 [41:17<42:56,  2.36s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 910, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 46%|████▌     | 911/2000 [41:18<33:51,  1.87s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9811, Requested 411. Please try again in 1.332s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 911, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 46%|████▌     | 912/2000 [41:20<35:28,  1.96s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9848, Requested 355. Please try again in 1.218s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 912, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9692, Requested 355. Please try again in 282ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 46%|████▌     | 913/2000 [41:23<41:19,  2.28s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 913, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 46%|████▌     | 914/2000 [41:23<31:17,  1.73s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9891, Requested 307. Please try again in 1.188s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 914, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 46%|████▌     | 915/2000 [41:25<34:18,  1.90s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9823, Requested 342. Please try again in 990ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 915, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 46%|████▌     | 916/2000 [41:28<37:56,  2.10s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 916, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 46%|████▌     | 917/2000 [41:29<29:17,  1.62s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9920, Requested 372. Please try again in 1.752s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 917, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9887, Requested 372. Please try again in 1.554s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 5.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9796, Requested 372. Please try again in 1.007s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 46%|████▌     | 918/2000 [41:35<57:06,  3.17s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 918, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 46%|████▌     | 919/2000 [41:36<42:51,  2.38s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 919, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 46%|████▌     | 920/2000 [41:36<32:09,  1.79s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 920, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 46%|████▌     | 921/2000 [41:37<25:29,  1.42s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9872, Requested 451. Please try again in 1.938s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 921, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9758, Requested 451. Please try again in 1.254s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 46%|████▌     | 922/2000 [41:40<36:12,  2.02s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9734, Requested 520. Please try again in 1.524s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 922, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 46%|████▌     | 923/2000 [41:43<37:53,  2.11s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9838, Requested 292. Please try again in 780ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 923, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 46%|████▌     | 924/2000 [41:45<38:52,  2.17s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9749, Requested 313. Please try again in 372ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 924, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 46%|████▋     | 925/2000 [41:46<34:06,  1.90s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9840, Requested 316. Please try again in 936ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 925, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 46%|████▋     | 926/2000 [41:48<33:06,  1.85s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9869, Requested 412. Please try again in 1.686s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 926, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9614, Requested 412. Please try again in 156ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 46%|████▋     | 927/2000 [41:54<54:35,  3.05s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 927, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 46%|████▋     | 928/2000 [41:54<41:42,  2.33s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 928, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 46%|████▋     | 929/2000 [41:55<32:27,  1.82s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9652, Requested 368. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 929, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 46%|████▋     | 930/2000 [41:57<31:06,  1.74s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9753, Requested 364. Please try again in 702ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 930, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 47%|████▋     | 931/2000 [41:59<33:05,  1.86s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9759, Requested 280. Please try again in 234ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 931, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 47%|████▋     | 932/2000 [42:01<33:58,  1.91s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9705, Requested 312. Please try again in 102ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 932, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 47%|████▋     | 933/2000 [42:03<36:44,  2.07s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 933, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 47%|████▋     | 934/2000 [42:04<27:46,  1.56s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9872, Requested 401. Please try again in 1.638s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 934, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9774, Requested 401. Please try again in 1.05s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 47%|████▋     | 935/2000 [42:07<38:34,  2.17s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 935, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 47%|████▋     | 936/2000 [42:08<31:30,  1.78s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9836, Requested 342. Please try again in 1.068s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 936, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9668, Requested 342. Please try again in 60ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 47%|████▋     | 937/2000 [42:11<36:07,  2.04s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9740, Requested 315. Please try again in 330ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 937, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 47%|████▋     | 938/2000 [42:12<32:04,  1.81s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9836, Requested 336. Please try again in 1.032s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 938, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 47%|████▋     | 939/2000 [42:15<36:38,  2.07s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9726, Requested 305. Please try again in 186ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 939, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 47%|████▋     | 940/2000 [42:17<40:10,  2.27s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 940, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 47%|████▋     | 941/2000 [42:18<30:23,  1.72s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9847, Requested 326. Please try again in 1.038s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 941, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 47%|████▋     | 942/2000 [42:20<32:49,  1.86s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9794, Requested 528. Please try again in 1.932s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 942, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9746, Requested 528. Please try again in 1.644s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 47%|████▋     | 943/2000 [42:24<46:27,  2.64s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9553, Requested 459. Please try again in 72ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 943, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 47%|████▋     | 944/2000 [42:26<41:07,  2.34s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 944, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 47%|████▋     | 945/2000 [42:26<30:55,  1.76s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9932, Requested 439. Please try again in 2.226s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 945, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9681, Requested 439. Please try again in 720ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 47%|████▋     | 946/2000 [42:31<47:17,  2.69s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 946, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 47%|████▋     | 947/2000 [42:32<36:04,  2.06s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9833, Requested 571. Please try again in 2.424s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 947, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9548, Requested 571. Please try again in 714ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9488, Requested 571. Please try again in 354ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 47%|████▋     | 948/2000 [42:36<45:29,  2.59s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9713, Requested 308. Please try again in 125ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 948, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 47%|████▋     | 949/2000 [42:38<43:28,  2.48s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 949, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 48%|████▊     | 950/2000 [42:39<34:13,  1.96s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9864, Requested 289. Please try again in 918ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 950, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 48%|████▊     | 951/2000 [42:40<31:49,  1.82s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9904, Requested 605. Please try again in 3.054s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 951, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9599, Requested 605. Please try again in 1.224s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 48%|████▊     | 952/2000 [42:46<54:11,  3.10s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 952, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 48%|████▊     | 953/2000 [42:47<40:46,  2.34s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9737, Requested 312. Please try again in 294ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 953, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 48%|████▊     | 954/2000 [42:48<32:13,  1.85s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9931, Requested 337. Please try again in 1.608s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 954, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 48%|████▊     | 955/2000 [42:50<35:19,  2.03s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9851, Requested 340. Please try again in 1.146s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 955, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9707, Requested 340. Please try again in 282ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 48%|████▊     | 956/2000 [42:54<45:53,  2.64s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 956, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 48%|████▊     | 957/2000 [42:55<34:26,  1.98s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9746, Requested 372. Please try again in 708ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 957, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 48%|████▊     | 958/2000 [42:57<35:06,  2.02s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9755, Requested 374. Please try again in 774ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 958, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 48%|████▊     | 959/2000 [42:58<33:31,  1.93s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9837, Requested 313. Please try again in 900ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 959, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9809, Requested 313. Please try again in 732ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 48%|████▊     | 960/2000 [43:03<45:44,  2.64s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 960, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 48%|████▊     | 961/2000 [43:03<34:09,  1.97s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 961, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 48%|████▊     | 962/2000 [43:04<28:10,  1.63s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9818, Requested 336. Please try again in 924ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 962, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 48%|████▊     | 963/2000 [43:06<30:03,  1.74s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9829, Requested 269. Please try again in 588ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 963, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 48%|████▊     | 964/2000 [43:07<27:49,  1.61s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9884, Requested 403. Please try again in 1.722s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 964, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 48%|████▊     | 965/2000 [43:10<33:28,  1.94s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9836, Requested 540. Please try again in 2.256s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 965, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9639, Requested 540. Please try again in 1.074s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 48%|████▊     | 966/2000 [43:14<44:13,  2.57s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 966, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 48%|████▊     | 967/2000 [43:14<33:02,  1.92s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9928, Requested 496. Please try again in 2.544s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 967, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9600, Requested 496. Please try again in 576ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 48%|████▊     | 968/2000 [43:19<48:37,  2.83s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 968, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 48%|████▊     | 969/2000 [43:20<37:14,  2.17s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9736, Requested 285. Please try again in 125ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 969, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 48%|████▊     | 970/2000 [43:22<35:32,  2.07s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9714, Requested 296. Please try again in 60ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 970, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 49%|████▊     | 971/2000 [43:23<32:21,  1.89s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9769, Requested 631. Please try again in 2.4s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 971, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9569, Requested 631. Please try again in 1.2s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 49%|████▊     | 972/2000 [43:27<40:07,  2.34s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9740, Requested 386. Please try again in 756ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 972, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9621, Requested 386. Please try again in 42ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 49%|████▊     | 973/2000 [43:32<53:54,  3.15s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 973, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 49%|████▊     | 974/2000 [43:32<40:44,  2.38s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 974, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 49%|████▉     | 975/2000 [43:33<33:03,  1.94s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9753, Requested 337. Please try again in 540ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 975, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9737, Requested 337. Please try again in 444ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 49%|████▉     | 976/2000 [43:37<43:52,  2.57s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 976, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 49%|████▉     | 977/2000 [43:38<33:01,  1.94s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9785, Requested 274. Please try again in 354ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 977, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 49%|████▉     | 978/2000 [43:39<30:37,  1.80s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9818, Requested 304. Please try again in 732ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 978, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 49%|████▉     | 979/2000 [43:41<30:51,  1.81s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9821, Requested 406. Please try again in 1.362s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 979, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 49%|████▉     | 980/2000 [43:44<37:17,  2.19s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 980, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 49%|████▉     | 981/2000 [43:46<35:40,  2.10s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 981, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 49%|████▉     | 982/2000 [43:46<27:39,  1.63s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9870, Requested 288. Please try again in 948ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 982, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9839, Requested 288. Please try again in 762ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 49%|████▉     | 983/2000 [43:51<39:58,  2.36s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 983, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 49%|████▉     | 984/2000 [43:51<31:14,  1.85s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9769, Requested 318. Please try again in 522ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 984, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 49%|████▉     | 985/2000 [43:54<33:43,  1.99s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9696, Requested 426. Please try again in 732ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 985, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 49%|████▉     | 986/2000 [43:55<31:33,  1.87s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9845, Requested 324. Please try again in 1.013s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 986, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9810, Requested 324. Please try again in 804ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 49%|████▉     | 987/2000 [43:57<32:53,  1.95s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9800, Requested 414. Please try again in 1.284s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 987, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9677, Requested 414. Please try again in 546ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 49%|████▉     | 988/2000 [44:01<40:06,  2.38s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9630, Requested 445. Please try again in 450ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 988, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 49%|████▉     | 989/2000 [44:02<35:20,  2.10s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9810, Requested 515. Please try again in 1.95s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 989, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9772, Requested 515. Please try again in 1.722s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9562, Requested 515. Please try again in 462ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 50%|████▉     | 990/2000 [44:05<39:25,  2.34s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9808, Requested 533. Please try again in 2.046s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 990, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9762, Requested 533. Please try again in 1.77s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 5.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9562, Requested 533. Please try again in 570ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 50%|████▉     | 991/2000 [44:13<1:06:51,  3.98s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 991, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 50%|████▉     | 992/2000 [44:13<49:32,  2.95s/it]  "
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 992, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 50%|████▉     | 993/2000 [44:14<37:25,  2.23s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 993, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 50%|████▉     | 994/2000 [44:14<28:48,  1.72s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9754, Requested 406. Please try again in 960ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 994, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 50%|████▉     | 995/2000 [44:16<30:27,  1.82s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9804, Requested 276. Please try again in 480ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 995, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 50%|████▉     | 996/2000 [44:18<31:04,  1.86s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9758, Requested 356. Please try again in 684ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 996, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9662, Requested 356. Please try again in 108ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 50%|████▉     | 997/2000 [44:23<46:52,  2.80s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 997, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 50%|████▉     | 998/2000 [44:24<37:38,  2.25s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 998, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 50%|████▉     | 999/2000 [44:25<29:28,  1.77s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9788, Requested 350. Please try again in 828ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 999, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 50%|█████     | 1000/2000 [44:27<29:25,  1.77s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9838, Requested 297. Please try again in 810ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1000, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 50%|█████     | 1001/2000 [44:29<32:40,  1.96s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9733, Requested 329. Please try again in 372ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1001, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 50%|█████     | 1002/2000 [44:30<28:44,  1.73s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9867, Requested 382. Please try again in 1.494s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1002, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9694, Requested 382. Please try again in 456ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 50%|█████     | 1003/2000 [44:35<44:25,  2.67s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1003, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 50%|█████     | 1004/2000 [44:36<34:12,  2.06s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9651, Requested 450. Please try again in 606ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1004, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 50%|█████     | 1005/2000 [44:38<36:48,  2.22s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9649, Requested 433. Please try again in 492ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1005, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9598, Requested 433. Please try again in 186ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 50%|█████     | 1006/2000 [44:42<44:29,  2.69s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1006, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 50%|█████     | 1007/2000 [44:43<35:53,  2.17s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9637, Requested 642. Please try again in 1.674s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1007, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9537, Requested 642. Please try again in 1.074s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 50%|█████     | 1008/2000 [44:47<44:58,  2.72s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1008, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 50%|█████     | 1009/2000 [44:48<34:58,  2.12s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9739, Requested 427. Please try again in 996ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1009, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9681, Requested 427. Please try again in 648ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 50%|█████     | 1010/2000 [44:50<34:52,  2.11s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9791, Requested 363. Please try again in 924ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1010, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 51%|█████     | 1011/2000 [44:52<34:41,  2.10s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9792, Requested 334. Please try again in 756ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1011, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 51%|█████     | 1012/2000 [44:55<36:56,  2.24s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9701, Requested 317. Please try again in 108ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1012, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 51%|█████     | 1013/2000 [44:56<32:06,  1.95s/it]INFO:backoff:Backing off get_labels_batch(...) for 2.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9811, Requested 572. Please try again in 2.298s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1013, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9465, Requested 572. Please try again in 222ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 51%|█████     | 1014/2000 [45:00<44:11,  2.69s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9599, Requested 487. Please try again in 516ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1014, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 51%|█████     | 1015/2000 [45:02<38:45,  2.36s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9797, Requested 619. Please try again in 2.496s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1015, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9587, Requested 619. Please try again in 1.236s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 51%|█████     | 1016/2000 [45:07<52:51,  3.22s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1016, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 51%|█████     | 1017/2000 [45:08<39:42,  2.42s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9705, Requested 316. Please try again in 125ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1017, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 51%|█████     | 1018/2000 [45:09<34:02,  2.08s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9797, Requested 315. Please try again in 672ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1018, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9719, Requested 315. Please try again in 204ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 51%|█████     | 1019/2000 [45:13<45:20,  2.77s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1019, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 51%|█████     | 1020/2000 [45:14<34:58,  2.14s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1020, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 51%|█████     | 1021/2000 [45:15<27:39,  1.70s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9820, Requested 427. Please try again in 1.482s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1021, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 51%|█████     | 1022/2000 [45:17<30:12,  1.85s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9861, Requested 436. Please try again in 1.782s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1022, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9784, Requested 436. Please try again in 1.32s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 6.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9608, Requested 436. Please try again in 264ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 51%|█████     | 1023/2000 [45:25<1:00:15,  3.70s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1023, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 51%|█████     | 1024/2000 [45:26<44:57,  2.76s/it]  "
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1024, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 51%|█████▏    | 1025/2000 [45:26<34:54,  2.15s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9627, Requested 410. Please try again in 222ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1025, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 51%|█████▏    | 1026/2000 [45:28<30:32,  1.88s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9813, Requested 332. Please try again in 870ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1026, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 51%|█████▏    | 1027/2000 [45:30<31:17,  1.93s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9801, Requested 332. Please try again in 798ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1027, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9692, Requested 332. Please try again in 144ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 51%|█████▏    | 1028/2000 [45:32<35:22,  2.18s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9670, Requested 425. Please try again in 570ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1028, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 51%|█████▏    | 1029/2000 [45:34<35:12,  2.18s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9720, Requested 366. Please try again in 516ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1029, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 52%|█████▏    | 1030/2000 [45:37<35:30,  2.20s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9701, Requested 377. Please try again in 468ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1030, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 52%|█████▏    | 1031/2000 [45:38<32:54,  2.04s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9789, Requested 341. Please try again in 780ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1031, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 52%|█████▏    | 1032/2000 [45:40<30:47,  1.91s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9856, Requested 312. Please try again in 1.007s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1032, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 52%|█████▏    | 1033/2000 [45:42<31:14,  1.94s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9834, Requested 306. Please try again in 840ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1033, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 52%|█████▏    | 1034/2000 [45:44<30:30,  1.90s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9842, Requested 345. Please try again in 1.122s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1034, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9810, Requested 345. Please try again in 930ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 52%|█████▏    | 1035/2000 [45:46<31:41,  1.97s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9810, Requested 340. Please try again in 900ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1035, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 52%|█████▏    | 1036/2000 [45:48<30:47,  1.92s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9840, Requested 428. Please try again in 1.608s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1036, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9575, Requested 428. Please try again in 18ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 52%|█████▏    | 1037/2000 [45:54<51:30,  3.21s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1037, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 52%|█████▏    | 1038/2000 [45:55<40:01,  2.50s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1038, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 52%|█████▏    | 1039/2000 [45:56<31:33,  1.97s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9835, Requested 496. Please try again in 1.985s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1039, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9697, Requested 496. Please try again in 1.158s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 2.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9644, Requested 496. Please try again in 840ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 52%|█████▏    | 1040/2000 [46:00<43:32,  2.72s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1040, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 52%|█████▏    | 1041/2000 [46:01<33:10,  2.08s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9860, Requested 467. Please try again in 1.962s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1041, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9732, Requested 467. Please try again in 1.194s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 52%|█████▏    | 1042/2000 [46:04<40:06,  2.51s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9700, Requested 430. Please try again in 780ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1042, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 52%|█████▏    | 1043/2000 [46:06<37:40,  2.36s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9776, Requested 341. Please try again in 702ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1043, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 52%|█████▏    | 1044/2000 [46:08<36:28,  2.29s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9765, Requested 500. Please try again in 1.59s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1044, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9510, Requested 500. Please try again in 60ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 52%|█████▏    | 1045/2000 [46:11<38:39,  2.43s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9782, Requested 335. Please try again in 702ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1045, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9736, Requested 335. Please try again in 426ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 52%|█████▏    | 1046/2000 [46:15<45:51,  2.88s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1046, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 52%|█████▏    | 1047/2000 [46:16<35:10,  2.21s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9682, Requested 433. Please try again in 690ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1047, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 52%|█████▏    | 1048/2000 [46:18<34:23,  2.17s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9756, Requested 367. Please try again in 738ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1048, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 52%|█████▏    | 1049/2000 [46:20<36:49,  2.32s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1049, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 52%|█████▎    | 1050/2000 [46:21<28:56,  1.83s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9871, Requested 548. Please try again in 2.514s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1050, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9778, Requested 548. Please try again in 1.955s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 6.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9501, Requested 548. Please try again in 294ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 53%|█████▎    | 1051/2000 [46:31<1:06:12,  4.19s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1051, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 53%|█████▎    | 1052/2000 [46:31<48:08,  3.05s/it]  "
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1052, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 53%|█████▎    | 1053/2000 [46:32<38:38,  2.45s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1053, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 53%|█████▎    | 1054/2000 [46:33<29:57,  1.90s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1054, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 53%|█████▎    | 1055/2000 [46:34<25:12,  1.60s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9521, Requested 493. Please try again in 84ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1055, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 53%|█████▎    | 1056/2000 [46:35<25:07,  1.60s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9732, Requested 330. Please try again in 372ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1056, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 53%|█████▎    | 1057/2000 [46:38<28:16,  1.80s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9679, Requested 398. Please try again in 462ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1057, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 53%|█████▎    | 1058/2000 [46:39<25:21,  1.62s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9869, Requested 341. Please try again in 1.26s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1058, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 53%|█████▎    | 1059/2000 [46:41<27:05,  1.73s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9873, Requested 328. Please try again in 1.206s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1059, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9722, Requested 328. Please try again in 300ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 53%|█████▎    | 1060/2000 [46:43<28:59,  1.85s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9838, Requested 285. Please try again in 738ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1060, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 53%|█████▎    | 1061/2000 [46:45<29:28,  1.88s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9794, Requested 306. Please try again in 600ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1061, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 53%|█████▎    | 1062/2000 [46:46<28:06,  1.80s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9839, Requested 280. Please try again in 714ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1062, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 53%|█████▎    | 1063/2000 [46:48<28:59,  1.86s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9786, Requested 320. Please try again in 636ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1063, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 53%|█████▎    | 1064/2000 [46:51<31:10,  2.00s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9724, Requested 340. Please try again in 384ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1064, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9699, Requested 340. Please try again in 234ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 53%|█████▎    | 1065/2000 [46:53<33:37,  2.16s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1065, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 53%|█████▎    | 1066/2000 [46:54<28:29,  1.83s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9766, Requested 301. Please try again in 402ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1066, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 53%|█████▎    | 1067/2000 [46:57<30:28,  1.96s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9690, Requested 332. Please try again in 132ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1067, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 53%|█████▎    | 1068/2000 [46:59<32:46,  2.11s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1068, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 53%|█████▎    | 1069/2000 [47:00<26:54,  1.73s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9828, Requested 342. Please try again in 1.02s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1069, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9669, Requested 342. Please try again in 66ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 54%|█████▎    | 1070/2000 [47:02<30:34,  1.97s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9742, Requested 363. Please try again in 630ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1070, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 54%|█████▎    | 1071/2000 [47:04<30:27,  1.97s/it]INFO:backoff:Backing off get_labels_batch(...) for 2.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9780, Requested 398. Please try again in 1.068s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1071, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 54%|█████▎    | 1072/2000 [47:07<33:43,  2.18s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9727, Requested 424. Please try again in 906ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1072, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9607, Requested 424. Please try again in 186ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 54%|█████▎    | 1073/2000 [47:10<39:05,  2.53s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1073, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 54%|█████▎    | 1074/2000 [47:11<31:17,  2.03s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9735, Requested 364. Please try again in 594ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1074, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 54%|█████▍    | 1075/2000 [47:13<30:05,  1.95s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9807, Requested 320. Please try again in 762ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1075, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 54%|█████▍    | 1076/2000 [47:14<26:57,  1.75s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9916, Requested 356. Please try again in 1.632s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1076, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 54%|█████▍    | 1077/2000 [47:17<31:35,  2.05s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9808, Requested 438. Please try again in 1.476s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1077, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9716, Requested 438. Please try again in 924ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 54%|█████▍    | 1078/2000 [47:22<44:48,  2.92s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1078, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 54%|█████▍    | 1079/2000 [47:22<33:04,  2.15s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9725, Requested 327. Please try again in 312ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1079, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 54%|█████▍    | 1080/2000 [47:24<29:31,  1.93s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9816, Requested 404. Please try again in 1.32s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1080, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 54%|█████▍    | 1081/2000 [47:26<30:33,  2.00s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9839, Requested 342. Please try again in 1.086s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1081, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 54%|█████▍    | 1082/2000 [47:29<33:20,  2.18s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9743, Requested 479. Please try again in 1.332s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1082, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 54%|█████▍    | 1083/2000 [47:31<33:34,  2.20s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9794, Requested 368. Please try again in 972ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1083, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 54%|█████▍    | 1084/2000 [47:33<32:44,  2.14s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9837, Requested 299. Please try again in 816ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1084, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9783, Requested 299. Please try again in 492ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 54%|█████▍    | 1085/2000 [47:36<37:15,  2.44s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1085, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 54%|█████▍    | 1086/2000 [47:37<29:41,  1.95s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9772, Requested 330. Please try again in 612ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1086, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 54%|█████▍    | 1087/2000 [47:39<30:01,  1.97s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9760, Requested 280. Please try again in 240ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1087, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 54%|█████▍    | 1088/2000 [47:41<31:36,  2.08s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1088, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 54%|█████▍    | 1089/2000 [47:42<26:17,  1.73s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9824, Requested 282. Please try again in 636ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1089, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 55%|█████▍    | 1090/2000 [47:44<28:34,  1.88s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9737, Requested 299. Please try again in 216ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1090, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 55%|█████▍    | 1091/2000 [47:47<31:03,  2.05s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1091, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 55%|█████▍    | 1092/2000 [47:47<24:30,  1.62s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9859, Requested 281. Please try again in 840ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1092, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 55%|█████▍    | 1093/2000 [47:49<25:49,  1.71s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9825, Requested 323. Please try again in 888ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1093, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 55%|█████▍    | 1094/2000 [47:51<25:40,  1.70s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9864, Requested 311. Please try again in 1.05s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1094, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9809, Requested 311. Please try again in 720ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 55%|█████▍    | 1095/2000 [47:56<41:13,  2.73s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1095, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 55%|█████▍    | 1096/2000 [47:56<30:52,  2.05s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1096, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 55%|█████▍    | 1097/2000 [47:57<25:01,  1.66s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9834, Requested 288. Please try again in 732ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 3.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9813, Requested 288. Please try again in 606ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1097, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 55%|█████▍    | 1098/2000 [48:02<37:06,  2.47s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1098, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 55%|█████▍    | 1099/2000 [48:03<31:39,  2.11s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1099, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 55%|█████▌    | 1100/2000 [48:04<25:54,  1.73s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9688, Requested 315. Please try again in 18ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1100, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 55%|█████▌    | 1101/2000 [48:06<28:13,  1.88s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1101, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 55%|█████▌    | 1102/2000 [48:07<22:39,  1.51s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9810, Requested 292. Please try again in 612ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1102, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 55%|█████▌    | 1103/2000 [48:08<24:07,  1.61s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9791, Requested 448. Please try again in 1.434s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1103, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9755, Requested 448. Please try again in 1.218s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 1.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9666, Requested 448. Please try again in 684ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 55%|█████▌    | 1104/2000 [48:11<29:50,  2.00s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1104, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 55%|█████▌    | 1105/2000 [48:12<23:49,  1.60s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9890, Requested 359. Please try again in 1.494s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1105, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 55%|█████▌    | 1106/2000 [48:14<26:58,  1.81s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9856, Requested 277. Please try again in 798ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1106, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9796, Requested 277. Please try again in 438ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 55%|█████▌    | 1107/2000 [48:18<35:02,  2.35s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1107, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 55%|█████▌    | 1108/2000 [48:19<27:15,  1.83s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9718, Requested 340. Please try again in 348ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1108, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 55%|█████▌    | 1109/2000 [48:21<29:55,  2.01s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1109, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 56%|█████▌    | 1110/2000 [48:22<23:46,  1.60s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9827, Requested 298. Please try again in 750ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1110, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9771, Requested 298. Please try again in 414ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 56%|█████▌    | 1111/2000 [48:25<32:48,  2.21s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1111, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 56%|█████▌    | 1112/2000 [48:26<26:46,  1.81s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9689, Requested 659. Please try again in 2.088s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1112, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9562, Requested 659. Please try again in 1.326s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9452, Requested 659. Please try again in 666ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 56%|█████▌    | 1113/2000 [48:29<31:41,  2.14s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9807, Requested 359. Please try again in 996ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1113, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9738, Requested 359. Please try again in 582ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 56%|█████▌    | 1114/2000 [48:33<39:24,  2.67s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1114, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 56%|█████▌    | 1115/2000 [48:34<31:16,  2.12s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9692, Requested 310. Please try again in 12ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1115, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 56%|█████▌    | 1116/2000 [48:36<31:49,  2.16s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1116, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 56%|█████▌    | 1117/2000 [48:37<26:52,  1.83s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9777, Requested 321. Please try again in 588ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1117, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 56%|█████▌    | 1118/2000 [48:39<25:42,  1.75s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9835, Requested 327. Please try again in 972ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1118, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 56%|█████▌    | 1119/2000 [48:41<30:03,  2.05s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1119, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 56%|█████▌    | 1120/2000 [48:43<26:20,  1.80s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9777, Requested 300. Please try again in 462ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1120, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 56%|█████▌    | 1121/2000 [48:45<27:12,  1.86s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9747, Requested 340. Please try again in 522ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1121, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9695, Requested 340. Please try again in 210ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 56%|█████▌    | 1122/2000 [48:46<27:12,  1.86s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9766, Requested 482. Please try again in 1.488s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1122, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 56%|█████▌    | 1123/2000 [48:48<27:42,  1.90s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9895, Requested 439. Please try again in 2.004s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1123, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9754, Requested 439. Please try again in 1.158s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 56%|█████▌    | 1124/2000 [48:53<39:00,  2.67s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1124, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 56%|█████▋    | 1125/2000 [48:53<28:57,  1.99s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9785, Requested 334. Please try again in 714ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1125, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 56%|█████▋    | 1126/2000 [48:55<29:03,  2.00s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9777, Requested 278. Please try again in 330ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1126, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 56%|█████▋    | 1127/2000 [48:58<31:39,  2.18s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1127, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 56%|█████▋    | 1128/2000 [48:59<25:24,  1.75s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9845, Requested 311. Please try again in 936ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1128, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 56%|█████▋    | 1129/2000 [49:01<29:53,  2.06s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1129, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 56%|█████▋    | 1130/2000 [49:02<23:56,  1.65s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9879, Requested 318. Please try again in 1.182s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1130, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9815, Requested 318. Please try again in 798ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 3.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9759, Requested 318. Please try again in 462ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 57%|█████▋    | 1131/2000 [49:07<37:17,  2.57s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1131, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 57%|█████▋    | 1132/2000 [49:07<28:34,  1.98s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1132, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 57%|█████▋    | 1133/2000 [49:08<21:49,  1.51s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9865, Requested 400. Please try again in 1.59s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1133, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 57%|█████▋    | 1134/2000 [49:10<24:45,  1.72s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9877, Requested 309. Please try again in 1.116s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1134, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 57%|█████▋    | 1135/2000 [49:13<29:25,  2.04s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9716, Requested 387. Please try again in 618ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1135, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 57%|█████▋    | 1136/2000 [49:15<28:57,  2.01s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9771, Requested 454. Please try again in 1.35s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1136, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9631, Requested 454. Please try again in 510ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 57%|█████▋    | 1137/2000 [49:18<31:40,  2.20s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9760, Requested 341. Please try again in 606ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1137, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9673, Requested 341. Please try again in 84ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 57%|█████▋    | 1138/2000 [49:21<38:59,  2.71s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1138, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 57%|█████▋    | 1139/2000 [49:22<30:03,  2.10s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9669, Requested 364. Please try again in 198ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1139, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 57%|█████▋    | 1140/2000 [49:24<28:59,  2.02s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1140, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 57%|█████▋    | 1141/2000 [49:25<23:56,  1.67s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9851, Requested 283. Please try again in 804ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1141, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 57%|█████▋    | 1142/2000 [49:27<24:26,  1.71s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9841, Requested 279. Please try again in 720ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1142, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 57%|█████▋    | 1143/2000 [49:28<24:53,  1.74s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9821, Requested 296. Please try again in 702ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1143, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 57%|█████▋    | 1144/2000 [49:30<25:14,  1.77s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9814, Requested 284. Please try again in 588ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9796, Requested 284. Please try again in 480ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1144, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 57%|█████▋    | 1145/2000 [49:31<22:51,  1.60s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9900, Requested 283. Please try again in 1.098s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1145, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9780, Requested 283. Please try again in 378ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 57%|█████▋    | 1146/2000 [49:35<33:06,  2.33s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1146, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 57%|█████▋    | 1147/2000 [49:36<26:33,  1.87s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9663, Requested 430. Please try again in 558ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1147, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 57%|█████▋    | 1148/2000 [49:38<26:05,  1.84s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9783, Requested 302. Please try again in 510ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1148, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9731, Requested 302. Please try again in 198ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 57%|█████▋    | 1149/2000 [49:40<26:58,  1.90s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9740, Requested 315. Please try again in 330ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1149, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 57%|█████▊    | 1150/2000 [49:41<24:38,  1.74s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9825, Requested 301. Please try again in 756ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1150, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 58%|█████▊    | 1151/2000 [49:44<26:58,  1.91s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9744, Requested 287. Please try again in 186ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1151, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 58%|█████▊    | 1152/2000 [49:46<29:27,  2.08s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1152, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 58%|█████▊    | 1153/2000 [49:47<22:45,  1.61s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9830, Requested 436. Please try again in 1.596s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1153, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 58%|█████▊    | 1154/2000 [49:49<26:00,  1.84s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9845, Requested 371. Please try again in 1.296s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1154, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9657, Requested 371. Please try again in 168ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 58%|█████▊    | 1155/2000 [49:51<28:00,  1.99s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9822, Requested 351. Please try again in 1.038s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1155, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9694, Requested 351. Please try again in 270ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 58%|█████▊    | 1156/2000 [49:55<33:24,  2.37s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1156, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 58%|█████▊    | 1157/2000 [49:55<26:13,  1.87s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9811, Requested 286. Please try again in 582ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1157, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 58%|█████▊    | 1158/2000 [49:57<24:06,  1.72s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9865, Requested 387. Please try again in 1.512s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1158, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9788, Requested 387. Please try again in 1.05s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 58%|█████▊    | 1159/2000 [49:59<28:13,  2.01s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9796, Requested 274. Please try again in 420ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1159, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 58%|█████▊    | 1160/2000 [50:02<30:37,  2.19s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9648, Requested 447. Please try again in 570ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1160, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 58%|█████▊    | 1161/2000 [50:04<28:25,  2.03s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9795, Requested 981. Please try again in 4.656s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1161, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9651, Requested 981. Please try again in 3.792s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 3.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9176, Requested 981. Please try again in 941ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 58%|█████▊    | 1162/2000 [50:11<52:03,  3.73s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1162, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 58%|█████▊    | 1163/2000 [50:12<39:34,  2.84s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1163, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 58%|█████▊    | 1164/2000 [50:13<30:13,  2.17s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9756, Requested 314. Please try again in 420ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1164, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 58%|█████▊    | 1165/2000 [50:14<27:37,  1.99s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9815, Requested 280. Please try again in 570ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1165, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 58%|█████▊    | 1166/2000 [50:16<27:05,  1.95s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9790, Requested 375. Please try again in 990ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1166, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9687, Requested 375. Please try again in 372ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 58%|█████▊    | 1167/2000 [50:19<28:28,  2.05s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9774, Requested 288. Please try again in 372ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1167, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9747, Requested 288. Please try again in 210ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 58%|█████▊    | 1168/2000 [50:22<36:26,  2.63s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1168, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 58%|█████▊    | 1169/2000 [50:23<27:16,  1.97s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9650, Requested 473. Please try again in 738ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1169, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 58%|█████▊    | 1170/2000 [50:25<28:40,  2.07s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1170, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 59%|█████▊    | 1171/2000 [50:26<22:50,  1.65s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9873, Requested 263. Please try again in 816ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1171, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 59%|█████▊    | 1172/2000 [50:28<26:30,  1.92s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9718, Requested 291. Please try again in 54ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1172, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 59%|█████▊    | 1173/2000 [50:31<28:43,  2.08s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9598, Requested 411. Please try again in 54ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1173, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 59%|█████▊    | 1174/2000 [50:32<25:49,  1.88s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9758, Requested 284. Please try again in 251ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1174, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 59%|█████▉    | 1175/2000 [50:35<27:55,  2.03s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1175, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 59%|█████▉    | 1176/2000 [50:35<21:41,  1.58s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9869, Requested 290. Please try again in 954ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1176, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9791, Requested 290. Please try again in 486ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 59%|█████▉    | 1177/2000 [50:38<26:12,  1.91s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9711, Requested 343. Please try again in 324ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1177, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 59%|█████▉    | 1178/2000 [50:40<27:26,  2.00s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1178, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 59%|█████▉    | 1179/2000 [50:41<20:58,  1.53s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9891, Requested 404. Please try again in 1.77s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1179, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 59%|█████▉    | 1180/2000 [50:43<24:21,  1.78s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9878, Requested 492. Please try again in 2.22s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1180, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9762, Requested 492. Please try again in 1.524s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 6.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9683, Requested 492. Please try again in 1.05s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 59%|█████▉    | 1181/2000 [50:51<50:02,  3.67s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1181, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 59%|█████▉    | 1182/2000 [50:52<37:13,  2.73s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1182, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 59%|█████▉    | 1183/2000 [50:52<28:40,  2.11s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1183, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 59%|█████▉    | 1184/2000 [50:53<22:19,  1.64s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9716, Requested 388. Please try again in 624ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1184, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 59%|█████▉    | 1185/2000 [50:55<23:29,  1.73s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9765, Requested 303. Please try again in 408ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1185, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 59%|█████▉    | 1186/2000 [50:57<26:43,  1.97s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1186, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 59%|█████▉    | 1187/2000 [50:58<21:03,  1.55s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9887, Requested 354. Please try again in 1.446s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1187, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 59%|█████▉    | 1188/2000 [51:00<25:25,  1.88s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9796, Requested 323. Please try again in 714ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1188, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 59%|█████▉    | 1189/2000 [51:02<25:34,  1.89s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9794, Requested 404. Please try again in 1.188s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1189, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 60%|█████▉    | 1190/2000 [51:05<27:41,  2.05s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9778, Requested 326. Please try again in 624ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1190, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 60%|█████▉    | 1191/2000 [51:06<25:21,  1.88s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9849, Requested 308. Please try again in 941ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1191, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9758, Requested 308. Please try again in 396ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 60%|█████▉    | 1192/2000 [51:08<25:31,  1.89s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9837, Requested 355. Please try again in 1.152s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1192, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 60%|█████▉    | 1193/2000 [51:10<25:08,  1.87s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9898, Requested 293. Please try again in 1.146s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1193, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 60%|█████▉    | 1194/2000 [51:12<25:29,  1.90s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9867, Requested 548. Please try again in 2.49s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1194, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9843, Requested 548. Please try again in 2.346s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 60%|█████▉    | 1195/2000 [51:16<32:57,  2.46s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9755, Requested 369. Please try again in 744ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1195, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 60%|█████▉    | 1196/2000 [51:18<32:37,  2.43s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9719, Requested 1499. Please try again in 7.308s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1196, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9626, Requested 1499. Please try again in 6.75s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 4.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9357, Requested 1499. Please try again in 5.136s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 4.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 8549, Requested 1499. Please try again in 288ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 60%|█████▉    | 1197/2000 [51:30<1:12:02,  5.38s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1197, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 60%|█████▉    | 1198/2000 [51:31<53:37,  4.01s/it]  "
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1198, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 60%|█████▉    | 1199/2000 [51:32<40:51,  3.06s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1199, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 60%|██████    | 1200/2000 [51:33<30:37,  2.30s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9615, Requested 412. Please try again in 162ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1200, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 60%|██████    | 1201/2000 [51:35<30:03,  2.26s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9649, Requested 357. Please try again in 36ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1201, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 60%|██████    | 1202/2000 [51:37<28:33,  2.15s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9680, Requested 357. Please try again in 222ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1202, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 60%|██████    | 1203/2000 [51:38<24:42,  1.86s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9824, Requested 343. Please try again in 1.002s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1203, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9797, Requested 343. Please try again in 840ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 60%|██████    | 1204/2000 [51:41<28:26,  2.14s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9695, Requested 460. Please try again in 930ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1204, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 60%|██████    | 1205/2000 [51:42<27:30,  2.08s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9807, Requested 465. Please try again in 1.632s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1205, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9611, Requested 465. Please try again in 456ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9590, Requested 465. Please try again in 330ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 60%|██████    | 1206/2000 [51:45<30:58,  2.34s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9760, Requested 430. Please try again in 1.14s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1206, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 60%|██████    | 1207/2000 [51:48<30:59,  2.35s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9778, Requested 415. Please try again in 1.158s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1207, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 60%|██████    | 1208/2000 [51:50<29:24,  2.23s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9851, Requested 403. Please try again in 1.524s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1208, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9683, Requested 403. Please try again in 516ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 60%|██████    | 1209/2000 [51:53<34:44,  2.63s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1209, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 60%|██████    | 1210/2000 [51:54<26:49,  2.04s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9852, Requested 370. Please try again in 1.332s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1210, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9682, Requested 370. Please try again in 312ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 61%|██████    | 1211/2000 [51:58<35:10,  2.68s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1211, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 61%|██████    | 1212/2000 [51:59<27:07,  2.06s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9718, Requested 542. Please try again in 1.56s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1212, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9620, Requested 542. Please try again in 972ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 2.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9521, Requested 542. Please try again in 378ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 61%|██████    | 1213/2000 [52:03<36:56,  2.82s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1213, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 61%|██████    | 1214/2000 [52:04<27:22,  2.09s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1214, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 61%|██████    | 1215/2000 [52:04<20:40,  1.58s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9900, Requested 388. Please try again in 1.728s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1215, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9717, Requested 388. Please try again in 630ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 61%|██████    | 1216/2000 [52:07<24:39,  1.89s/it]INFO:backoff:Backing off get_labels_batch(...) for 2.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9839, Requested 302. Please try again in 846ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1216, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 61%|██████    | 1217/2000 [52:10<31:03,  2.38s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1217, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 61%|██████    | 1218/2000 [52:11<24:55,  1.91s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9702, Requested 346. Please try again in 288ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1218, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 61%|██████    | 1219/2000 [52:13<25:46,  1.98s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1219, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 61%|██████    | 1220/2000 [52:14<19:43,  1.52s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9918, Requested 324. Please try again in 1.452s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1220, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9870, Requested 324. Please try again in 1.164s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 61%|██████    | 1221/2000 [52:16<23:39,  1.82s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9817, Requested 458. Please try again in 1.65s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1221, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9562, Requested 458. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 61%|██████    | 1222/2000 [52:19<26:14,  2.02s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9832, Requested 451. Please try again in 1.698s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1222, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9724, Requested 451. Please try again in 1.05s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 61%|██████    | 1223/2000 [52:22<29:19,  2.26s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9793, Requested 386. Please try again in 1.074s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1223, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 61%|██████    | 1224/2000 [52:24<29:48,  2.30s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9773, Requested 373. Please try again in 876ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1224, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9648, Requested 373. Please try again in 125ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 61%|██████▏   | 1225/2000 [52:28<35:39,  2.76s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1225, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 61%|██████▏   | 1226/2000 [52:28<27:00,  2.09s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9714, Requested 320. Please try again in 204ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1226, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 61%|██████▏   | 1227/2000 [52:30<27:18,  2.12s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9673, Requested 347. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1227, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 61%|██████▏   | 1228/2000 [52:33<28:54,  2.25s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1228, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 61%|██████▏   | 1229/2000 [52:35<26:05,  2.03s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9695, Requested 575. Please try again in 1.62s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1229, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.8s (openai.error.RateLimitError: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.)\n",
            " 62%|██████▏   | 1230/2000 [52:39<35:51,  2.79s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1230, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 62%|██████▏   | 1231/2000 [52:40<26:34,  2.07s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9697, Requested 306. Please try again in 18ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1231, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 62%|██████▏   | 1232/2000 [52:40<21:36,  1.69s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9876, Requested 300. Please try again in 1.056s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1232, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 62%|██████▏   | 1233/2000 [52:43<24:28,  1.91s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9773, Requested 275. Please try again in 288ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1233, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 62%|██████▏   | 1234/2000 [52:45<26:52,  2.11s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1234, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 62%|██████▏   | 1235/2000 [52:46<22:07,  1.74s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9783, Requested 346. Please try again in 774ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1235, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 62%|██████▏   | 1236/2000 [52:49<24:48,  1.95s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9721, Requested 302. Please try again in 138ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1236, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 62%|██████▏   | 1237/2000 [52:50<22:48,  1.79s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9778, Requested 279. Please try again in 342ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1237, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 62%|██████▏   | 1238/2000 [52:52<23:13,  1.83s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9742, Requested 382. Please try again in 744ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1238, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 62%|██████▏   | 1239/2000 [52:53<21:14,  1.67s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9897, Requested 294. Please try again in 1.146s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1239, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9827, Requested 294. Please try again in 726ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 62%|██████▏   | 1240/2000 [52:58<32:29,  2.57s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1240, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 62%|██████▏   | 1241/2000 [52:59<25:18,  2.00s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1241, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 62%|██████▏   | 1242/2000 [52:59<19:48,  1.57s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9844, Requested 337. Please try again in 1.086s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1242, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9749, Requested 337. Please try again in 516ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 62%|██████▏   | 1243/2000 [53:03<28:20,  2.25s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1243, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 62%|██████▏   | 1244/2000 [53:04<22:04,  1.75s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9719, Requested 443. Please try again in 972ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1244, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 62%|██████▏   | 1245/2000 [53:06<22:49,  1.81s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9825, Requested 329. Please try again in 924ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1245, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9778, Requested 329. Please try again in 642ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 62%|██████▏   | 1246/2000 [53:09<29:00,  2.31s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1246, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 62%|██████▏   | 1247/2000 [53:10<22:12,  1.77s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9770, Requested 313. Please try again in 498ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1247, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 62%|██████▏   | 1248/2000 [53:11<21:36,  1.72s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9811, Requested 306. Please try again in 702ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1248, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 62%|██████▏   | 1249/2000 [53:14<25:00,  2.00s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1249, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 62%|██████▎   | 1250/2000 [53:14<19:58,  1.60s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9871, Requested 310. Please try again in 1.086s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1250, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 63%|██████▎   | 1251/2000 [53:16<21:20,  1.71s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9852, Requested 322. Please try again in 1.044s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1251, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 63%|██████▎   | 1252/2000 [53:19<25:07,  2.01s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9717, Requested 326. Please try again in 258ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1252, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 63%|██████▎   | 1253/2000 [53:21<24:22,  1.96s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9749, Requested 360. Please try again in 654ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1253, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 63%|██████▎   | 1254/2000 [53:23<24:51,  2.00s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9751, Requested 280. Please try again in 186ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1254, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 63%|██████▎   | 1255/2000 [53:25<24:37,  1.98s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9712, Requested 467. Please try again in 1.074s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1255, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 63%|██████▎   | 1256/2000 [53:27<25:36,  2.07s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9772, Requested 277. Please try again in 294ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1256, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 63%|██████▎   | 1257/2000 [53:30<28:18,  2.29s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1257, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 63%|██████▎   | 1258/2000 [53:31<22:25,  1.81s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9788, Requested 282. Please try again in 420ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1258, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9739, Requested 282. Please try again in 125ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 63%|██████▎   | 1259/2000 [53:34<25:56,  2.10s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1259, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 63%|██████▎   | 1260/2000 [53:34<20:41,  1.68s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9784, Requested 276. Please try again in 360ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1260, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 63%|██████▎   | 1261/2000 [53:36<19:28,  1.58s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9838, Requested 288. Please try again in 756ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1261, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9714, Requested 288. Please try again in 12ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 63%|██████▎   | 1262/2000 [53:40<31:29,  2.56s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1262, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 63%|██████▎   | 1263/2000 [53:41<23:49,  1.94s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1263, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 63%|██████▎   | 1264/2000 [53:42<19:50,  1.62s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9739, Requested 278. Please try again in 102ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1264, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 63%|██████▎   | 1265/2000 [53:43<18:03,  1.47s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9832, Requested 422. Please try again in 1.524s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1265, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9717, Requested 422. Please try again in 834ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 8.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9616, Requested 422. Please try again in 228ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 63%|██████▎   | 1266/2000 [53:53<49:01,  4.01s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1266, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 63%|██████▎   | 1267/2000 [53:53<35:39,  2.92s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1267, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 63%|██████▎   | 1268/2000 [53:54<26:50,  2.20s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1268, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 63%|██████▎   | 1269/2000 [53:54<21:04,  1.73s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1269, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 64%|██████▎   | 1270/2000 [53:55<17:26,  1.43s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1270, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 64%|██████▎   | 1271/2000 [53:56<14:31,  1.20s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9661, Requested 361. Please try again in 132ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1271, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 64%|██████▎   | 1272/2000 [53:58<18:43,  1.54s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1272, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 64%|██████▎   | 1273/2000 [53:59<16:00,  1.32s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9812, Requested 312. Please try again in 744ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1273, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 64%|██████▎   | 1274/2000 [54:00<16:43,  1.38s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9861, Requested 313. Please try again in 1.044s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1274, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9749, Requested 313. Please try again in 372ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 64%|██████▍   | 1275/2000 [54:03<21:09,  1.75s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9738, Requested 328. Please try again in 396ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1275, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 64%|██████▍   | 1276/2000 [54:06<23:38,  1.96s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1276, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 64%|██████▍   | 1277/2000 [54:06<18:46,  1.56s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9887, Requested 332. Please try again in 1.314s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1277, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 64%|██████▍   | 1278/2000 [54:09<23:26,  1.95s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9740, Requested 329. Please try again in 414ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1278, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 64%|██████▍   | 1279/2000 [54:12<25:33,  2.13s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1279, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 64%|██████▍   | 1280/2000 [54:12<20:09,  1.68s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9829, Requested 290. Please try again in 714ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1280, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 64%|██████▍   | 1281/2000 [54:14<19:49,  1.65s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9855, Requested 278. Please try again in 798ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1281, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 64%|██████▍   | 1282/2000 [54:16<20:26,  1.71s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9834, Requested 471. Please try again in 1.83s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1282, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9779, Requested 471. Please try again in 1.5s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 64%|██████▍   | 1283/2000 [54:20<30:24,  2.54s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1283, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 64%|██████▍   | 1284/2000 [54:21<23:36,  1.98s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9802, Requested 368. Please try again in 1.02s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1284, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9633, Requested 368. Please try again in 6ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 64%|██████▍   | 1285/2000 [54:24<28:51,  2.42s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1285, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 64%|██████▍   | 1286/2000 [54:25<22:43,  1.91s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9742, Requested 345. Please try again in 522ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1286, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 64%|██████▍   | 1287/2000 [54:26<21:02,  1.77s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9838, Requested 317. Please try again in 930ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1287, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9739, Requested 317. Please try again in 336ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 64%|██████▍   | 1288/2000 [54:29<23:11,  1.95s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9758, Requested 431. Please try again in 1.134s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1288, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 64%|██████▍   | 1289/2000 [54:31<23:25,  1.98s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9827, Requested 405. Please try again in 1.392s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1289, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 64%|██████▍   | 1290/2000 [54:33<25:22,  2.14s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9800, Requested 315. Please try again in 690ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1290, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9743, Requested 315. Please try again in 348ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 65%|██████▍   | 1291/2000 [54:36<28:19,  2.40s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1291, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 65%|██████▍   | 1292/2000 [54:37<21:48,  1.85s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9847, Requested 289. Please try again in 816ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1292, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 65%|██████▍   | 1293/2000 [54:40<25:26,  2.16s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1293, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 65%|██████▍   | 1294/2000 [54:40<19:40,  1.67s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9903, Requested 311. Please try again in 1.284s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1294, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9794, Requested 311. Please try again in 630ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 65%|██████▍   | 1295/2000 [54:44<28:17,  2.41s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1295, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 65%|██████▍   | 1296/2000 [54:45<21:38,  1.85s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9844, Requested 280. Please try again in 744ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1296, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9805, Requested 280. Please try again in 510ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 65%|██████▍   | 1297/2000 [54:47<21:18,  1.82s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9833, Requested 315. Please try again in 888ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1297, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 65%|██████▍   | 1298/2000 [54:49<21:24,  1.83s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9839, Requested 286. Please try again in 750ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1298, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 65%|██████▍   | 1299/2000 [54:51<23:41,  2.03s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9716, Requested 455. Please try again in 1.026s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1299, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 65%|██████▌   | 1300/2000 [54:54<25:27,  2.18s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9739, Requested 661. Please try again in 2.4s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1300, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9711, Requested 661. Please try again in 2.232s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 2.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9413, Requested 661. Please try again in 444ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 65%|██████▌   | 1301/2000 [54:59<38:00,  3.26s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1301, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 65%|██████▌   | 1302/2000 [55:00<28:34,  2.46s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1302, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 65%|██████▌   | 1303/2000 [55:01<22:50,  1.97s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9777, Requested 328. Please try again in 630ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1303, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9698, Requested 328. Please try again in 156ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 65%|██████▌   | 1304/2000 [55:05<29:59,  2.59s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1304, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 65%|██████▌   | 1305/2000 [55:05<23:15,  2.01s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9838, Requested 272. Please try again in 660ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1305, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 65%|██████▌   | 1306/2000 [55:08<24:31,  2.12s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9721, Requested 383. Please try again in 624ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1306, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 65%|██████▌   | 1307/2000 [55:10<23:04,  2.00s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9812, Requested 275. Please try again in 522ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1307, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 65%|██████▌   | 1308/2000 [55:12<23:30,  2.04s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9738, Requested 283. Please try again in 125ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1308, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 65%|██████▌   | 1309/2000 [55:13<20:26,  1.77s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9832, Requested 276. Please try again in 648ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1309, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 66%|██████▌   | 1310/2000 [55:14<18:21,  1.60s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9913, Requested 393. Please try again in 1.836s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1310, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9767, Requested 393. Please try again in 960ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 66%|██████▌   | 1311/2000 [55:20<32:22,  2.82s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1311, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 66%|██████▌   | 1312/2000 [55:20<24:48,  2.16s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1312, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 66%|██████▌   | 1313/2000 [55:21<19:35,  1.71s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9712, Requested 339. Please try again in 306ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1313, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 66%|██████▌   | 1314/2000 [55:23<19:40,  1.72s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9745, Requested 277. Please try again in 132ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1314, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 66%|██████▌   | 1315/2000 [55:24<17:28,  1.53s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9842, Requested 321. Please try again in 977ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1315, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 66%|██████▌   | 1316/2000 [55:26<18:34,  1.63s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9855, Requested 276. Please try again in 786ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1316, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9782, Requested 276. Please try again in 348ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 66%|██████▌   | 1317/2000 [55:28<19:34,  1.72s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9814, Requested 276. Please try again in 540ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1317, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 66%|██████▌   | 1318/2000 [55:30<21:31,  1.89s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9698, Requested 412. Please try again in 660ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1318, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 66%|██████▌   | 1319/2000 [55:32<21:24,  1.89s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9780, Requested 278. Please try again in 348ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1319, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9740, Requested 278. Please try again in 108ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 66%|██████▌   | 1320/2000 [55:37<32:38,  2.88s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1320, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 66%|██████▌   | 1321/2000 [55:38<25:36,  2.26s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1321, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 66%|██████▌   | 1322/2000 [55:38<19:25,  1.72s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1322, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 66%|██████▌   | 1323/2000 [55:39<15:41,  1.39s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9888, Requested 277. Please try again in 990ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1323, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9751, Requested 277. Please try again in 168ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 66%|██████▌   | 1324/2000 [55:42<22:26,  1.99s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1324, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 66%|██████▋   | 1325/2000 [55:43<18:38,  1.66s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9778, Requested 339. Please try again in 702ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1325, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 66%|██████▋   | 1326/2000 [55:46<21:18,  1.90s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9705, Requested 312. Please try again in 102ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1326, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 66%|██████▋   | 1327/2000 [55:48<22:40,  2.02s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9625, Requested 436. Please try again in 366ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1327, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 66%|██████▋   | 1328/2000 [55:50<23:11,  2.07s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1328, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 66%|██████▋   | 1329/2000 [55:51<18:10,  1.63s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9890, Requested 392. Please try again in 1.692s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1329, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 66%|██████▋   | 1330/2000 [55:53<21:23,  1.92s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9839, Requested 378. Please try again in 1.302s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1330, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9744, Requested 378. Please try again in 732ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 67%|██████▋   | 1331/2000 [55:55<21:03,  1.89s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9906, Requested 346. Please try again in 1.512s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1331, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9687, Requested 346. Please try again in 198ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 67%|██████▋   | 1332/2000 [56:00<31:42,  2.85s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1332, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 67%|██████▋   | 1333/2000 [56:01<24:48,  2.23s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9663, Requested 378. Please try again in 246ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1333, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 67%|██████▋   | 1334/2000 [56:03<23:59,  2.16s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9707, Requested 298. Please try again in 30ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1334, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 67%|██████▋   | 1335/2000 [56:04<21:44,  1.96s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9756, Requested 344. Please try again in 600ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1335, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9729, Requested 344. Please try again in 438ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 67%|██████▋   | 1336/2000 [56:08<27:44,  2.51s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1336, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 67%|██████▋   | 1337/2000 [56:09<21:20,  1.93s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9796, Requested 302. Please try again in 588ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1337, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9747, Requested 302. Please try again in 294ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 67%|██████▋   | 1338/2000 [56:13<29:16,  2.65s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1338, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 67%|██████▋   | 1339/2000 [56:14<23:58,  2.18s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1339, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 67%|██████▋   | 1340/2000 [56:15<18:34,  1.69s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9698, Requested 331. Please try again in 174ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1340, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 67%|██████▋   | 1341/2000 [56:17<19:28,  1.77s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9692, Requested 313. Please try again in 30ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1341, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 67%|██████▋   | 1342/2000 [56:18<19:08,  1.75s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1342, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 67%|██████▋   | 1343/2000 [56:19<15:33,  1.42s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9899, Requested 301. Please try again in 1.2s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1343, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 67%|██████▋   | 1344/2000 [56:22<18:51,  1.73s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9790, Requested 280. Please try again in 420ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1344, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 67%|██████▋   | 1345/2000 [56:23<17:21,  1.59s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9860, Requested 434. Please try again in 1.764s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1345, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9682, Requested 434. Please try again in 696ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 67%|██████▋   | 1346/2000 [56:26<24:05,  2.21s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1346, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 67%|██████▋   | 1347/2000 [56:27<18:58,  1.74s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9841, Requested 290. Please try again in 786ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1347, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 67%|██████▋   | 1348/2000 [56:29<19:22,  1.78s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9814, Requested 287. Please try again in 606ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1348, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 67%|██████▋   | 1349/2000 [56:30<18:12,  1.68s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9862, Requested 286. Please try again in 888ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1349, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 68%|██████▊   | 1350/2000 [56:33<20:07,  1.86s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9770, Requested 381. Please try again in 906ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1350, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 68%|██████▊   | 1351/2000 [56:34<19:38,  1.82s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9855, Requested 283. Please try again in 828ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1351, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 68%|██████▊   | 1352/2000 [56:37<20:28,  1.90s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9793, Requested 301. Please try again in 564ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1352, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9707, Requested 301. Please try again in 48ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 68%|██████▊   | 1353/2000 [56:38<19:37,  1.82s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9822, Requested 310. Please try again in 792ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1353, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 68%|██████▊   | 1354/2000 [56:40<20:10,  1.87s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9800, Requested 277. Please try again in 462ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1354, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 68%|██████▊   | 1355/2000 [56:43<21:50,  2.03s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1355, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 68%|██████▊   | 1356/2000 [56:43<17:15,  1.61s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9859, Requested 317. Please try again in 1.056s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1356, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9731, Requested 317. Please try again in 288ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 68%|██████▊   | 1357/2000 [56:48<28:53,  2.70s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1357, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 68%|██████▊   | 1358/2000 [56:49<22:03,  2.06s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9491, Requested 530. Please try again in 125ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1358, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 68%|██████▊   | 1359/2000 [56:51<21:17,  1.99s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9692, Requested 434. Please try again in 756ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1359, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 68%|██████▊   | 1360/2000 [56:53<20:26,  1.92s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9823, Requested 445. Please try again in 1.608s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1360, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9675, Requested 445. Please try again in 720ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 68%|██████▊   | 1361/2000 [56:58<30:32,  2.87s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1361, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 68%|██████▊   | 1362/2000 [56:58<22:59,  2.16s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1362, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 68%|██████▊   | 1363/2000 [56:59<17:47,  1.68s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9901, Requested 399. Please try again in 1.8s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1363, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9642, Requested 399. Please try again in 246ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 68%|██████▊   | 1364/2000 [57:02<23:21,  2.20s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9716, Requested 475. Please try again in 1.146s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1364, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 68%|██████▊   | 1365/2000 [57:04<22:03,  2.08s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9874, Requested 482. Please try again in 2.136s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1365, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9670, Requested 482. Please try again in 912ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 68%|██████▊   | 1366/2000 [57:07<25:09,  2.38s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9818, Requested 420. Please try again in 1.428s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1366, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9678, Requested 420. Please try again in 588ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 68%|██████▊   | 1367/2000 [57:10<26:17,  2.49s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9761, Requested 373. Please try again in 804ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9747, Requested 373. Please try again in 720ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1367, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 5.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9653, Requested 373. Please try again in 156ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 68%|██████▊   | 1368/2000 [57:16<39:38,  3.76s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1368, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 68%|██████▊   | 1369/2000 [57:17<30:28,  2.90s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1369, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 68%|██████▊   | 1370/2000 [57:18<22:58,  2.19s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1370, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 69%|██████▊   | 1371/2000 [57:18<17:21,  1.66s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9694, Requested 353. Please try again in 282ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1371, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 4.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9660, Requested 353. Please try again in 78ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 69%|██████▊   | 1372/2000 [57:23<26:55,  2.57s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1372, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 69%|██████▊   | 1373/2000 [57:24<20:39,  1.98s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1373, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 69%|██████▊   | 1374/2000 [57:24<16:11,  1.55s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9662, Requested 380. Please try again in 251ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1374, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 69%|██████▉   | 1375/2000 [57:27<19:13,  1.84s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9610, Requested 399. Please try again in 54ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1375, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 69%|██████▉   | 1376/2000 [57:29<19:25,  1.87s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1376, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 69%|██████▉   | 1377/2000 [57:29<15:22,  1.48s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9856, Requested 279. Please try again in 810ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1377, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 69%|██████▉   | 1378/2000 [57:31<15:56,  1.54s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9861, Requested 306. Please try again in 1.002s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1378, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9708, Requested 306. Please try again in 84ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 69%|██████▉   | 1379/2000 [57:33<18:50,  1.82s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9760, Requested 380. Please try again in 840ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1379, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9655, Requested 380. Please try again in 210ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 69%|██████▉   | 1380/2000 [57:36<21:52,  2.12s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1380, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 69%|██████▉   | 1381/2000 [57:37<16:53,  1.64s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9887, Requested 508. Please try again in 2.37s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1381, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9856, Requested 508. Please try again in 2.184s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 7.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9543, Requested 508. Please try again in 306ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 69%|██████▉   | 1382/2000 [57:47<42:16,  4.10s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1382, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 69%|██████▉   | 1383/2000 [57:47<31:51,  3.10s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1383, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 69%|██████▉   | 1384/2000 [57:48<24:03,  2.34s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1384, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 69%|██████▉   | 1385/2000 [57:49<18:56,  1.85s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1385, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 69%|██████▉   | 1386/2000 [57:49<14:57,  1.46s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9682, Requested 428. Please try again in 660ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1386, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 69%|██████▉   | 1387/2000 [57:51<15:49,  1.55s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9793, Requested 302. Please try again in 570ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1387, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9735, Requested 302. Please try again in 222ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 69%|██████▉   | 1388/2000 [57:54<19:10,  1.88s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9657, Requested 356. Please try again in 78ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1388, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 69%|██████▉   | 1389/2000 [57:54<15:56,  1.56s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9854, Requested 363. Please try again in 1.302s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1389, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9654, Requested 363. Please try again in 102ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 70%|██████▉   | 1390/2000 [57:58<21:45,  2.14s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1390, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 70%|██████▉   | 1391/2000 [57:58<16:45,  1.65s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9841, Requested 284. Please try again in 750ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1391, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 70%|██████▉   | 1392/2000 [58:01<18:55,  1.87s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9733, Requested 330. Please try again in 378ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1392, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 70%|██████▉   | 1393/2000 [58:02<17:52,  1.77s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9806, Requested 469. Please try again in 1.65s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1393, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9537, Requested 469. Please try again in 36ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 70%|██████▉   | 1394/2000 [58:08<30:26,  3.01s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1394, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 70%|██████▉   | 1395/2000 [58:09<23:19,  2.31s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1395, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 70%|██████▉   | 1396/2000 [58:10<18:18,  1.82s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9685, Requested 363. Please try again in 288ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1396, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 70%|██████▉   | 1397/2000 [58:11<17:25,  1.73s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9776, Requested 587. Please try again in 2.178s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1397, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9575, Requested 587. Please try again in 972ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 6.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9479, Requested 587. Please try again in 396ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 70%|██████▉   | 1398/2000 [58:20<38:53,  3.88s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1398, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 70%|██████▉   | 1399/2000 [58:20<28:27,  2.84s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1399, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 70%|███████   | 1400/2000 [58:21<21:45,  2.18s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1400, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 70%|███████   | 1401/2000 [58:22<17:29,  1.75s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9793, Requested 341. Please try again in 804ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1401, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9670, Requested 341. Please try again in 66ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 70%|███████   | 1402/2000 [58:27<27:06,  2.72s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1402, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 70%|███████   | 1403/2000 [58:27<20:41,  2.08s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1403, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 70%|███████   | 1404/2000 [58:28<15:50,  1.60s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9822, Requested 343. Please try again in 990ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1404, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9731, Requested 343. Please try again in 444ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 70%|███████   | 1405/2000 [58:34<28:06,  2.83s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1405, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 70%|███████   | 1406/2000 [58:34<21:35,  2.18s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1406, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 70%|███████   | 1407/2000 [58:35<16:26,  1.66s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9898, Requested 295. Please try again in 1.158s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1407, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9849, Requested 295. Please try again in 864ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 70%|███████   | 1408/2000 [58:39<25:25,  2.58s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1408, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 70%|███████   | 1409/2000 [58:40<20:08,  2.04s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9779, Requested 391. Please try again in 1.02s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1409, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9739, Requested 391. Please try again in 780ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 70%|███████   | 1410/2000 [58:42<18:55,  1.92s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9877, Requested 308. Please try again in 1.11s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1410, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9758, Requested 308. Please try again in 396ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 71%|███████   | 1411/2000 [58:43<17:59,  1.83s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9911, Requested 310. Please try again in 1.326s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1411, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9761, Requested 310. Please try again in 426ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 71%|███████   | 1412/2000 [58:46<19:46,  2.02s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9807, Requested 292. Please try again in 594ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1412, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 71%|███████   | 1413/2000 [58:47<18:01,  1.84s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9864, Requested 598. Please try again in 2.772s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1413, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9705, Requested 598. Please try again in 1.818s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 7.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9479, Requested 598. Please try again in 462ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 71%|███████   | 1414/2000 [58:58<43:36,  4.47s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1414, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 71%|███████   | 1415/2000 [58:59<32:37,  3.35s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1415, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 71%|███████   | 1416/2000 [58:59<24:44,  2.54s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1416, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 71%|███████   | 1417/2000 [59:00<18:52,  1.94s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1417, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 71%|███████   | 1418/2000 [59:00<14:50,  1.53s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1418, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 71%|███████   | 1419/2000 [59:01<12:24,  1.28s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9732, Requested 306. Please try again in 228ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1419, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 71%|███████   | 1420/2000 [59:02<12:43,  1.32s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9804, Requested 307. Please try again in 666ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1420, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 71%|███████   | 1421/2000 [59:04<14:11,  1.47s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9810, Requested 421. Please try again in 1.386s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1421, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9712, Requested 421. Please try again in 798ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 71%|███████   | 1422/2000 [59:09<23:07,  2.40s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1422, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 71%|███████   | 1423/2000 [59:10<17:59,  1.87s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9674, Requested 334. Please try again in 48ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1423, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 71%|███████   | 1424/2000 [59:11<17:43,  1.85s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9704, Requested 467. Please try again in 1.026s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1424, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9677, Requested 467. Please try again in 864ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 71%|███████▏  | 1425/2000 [59:16<26:00,  2.71s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1425, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 71%|███████▏  | 1426/2000 [59:17<20:34,  2.15s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1426, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 71%|███████▏  | 1427/2000 [59:17<16:09,  1.69s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9751, Requested 336. Please try again in 522ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1427, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 71%|███████▏  | 1428/2000 [59:20<17:11,  1.80s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9734, Requested 424. Please try again in 948ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1428, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 71%|███████▏  | 1429/2000 [59:22<17:44,  1.86s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9795, Requested 512. Please try again in 1.842s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1429, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9770, Requested 512. Please try again in 1.692s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 6.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9577, Requested 512. Please try again in 534ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 72%|███████▏  | 1430/2000 [59:30<37:21,  3.93s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1430, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 72%|███████▏  | 1431/2000 [59:31<27:58,  2.95s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9029, Requested 1003. Please try again in 192ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1431, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 72%|███████▏  | 1432/2000 [59:33<24:20,  2.57s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1432, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 72%|███████▏  | 1433/2000 [59:33<18:50,  1.99s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9866, Requested 376. Please try again in 1.452s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1433, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9665, Requested 376. Please try again in 246ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 72%|███████▏  | 1434/2000 [59:39<27:56,  2.96s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9360, Requested 2618. Please try again in 11.868s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1434, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9337, Requested 2618. Please try again in 11.73s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 4.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 8824, Requested 2618. Please try again in 8.652s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 11.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 8035, Requested 2618. Please try again in 3.918s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 72%|███████▏  | 1435/2000 [59:59<1:16:31,  8.13s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1435, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 72%|███████▏  | 1436/2000 [1:00:00<56:01,  5.96s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1436, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 72%|███████▏  | 1437/2000 [1:00:00<40:30,  4.32s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1437, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 72%|███████▏  | 1438/2000 [1:00:01<30:14,  3.23s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1438, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 72%|███████▏  | 1439/2000 [1:00:01<23:03,  2.47s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1439, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 72%|███████▏  | 1440/2000 [1:00:02<18:34,  1.99s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1440, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 72%|███████▏  | 1441/2000 [1:00:03<15:14,  1.64s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1441, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 72%|███████▏  | 1442/2000 [1:00:04<12:17,  1.32s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9634, Requested 453. Please try again in 522ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1442, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9581, Requested 453. Please try again in 204ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 72%|███████▏  | 1443/2000 [1:00:05<13:06,  1.41s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9794, Requested 264. Please try again in 348ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1443, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 72%|███████▏  | 1444/2000 [1:00:08<15:03,  1.63s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9711, Requested 339. Please try again in 300ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1444, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 72%|███████▏  | 1445/2000 [1:00:10<17:26,  1.89s/it]INFO:backoff:Backing off get_labels_batch(...) for 2.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9628, Requested 411. Please try again in 234ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1445, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 72%|███████▏  | 1446/2000 [1:00:13<19:08,  2.07s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1446, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 72%|███████▏  | 1447/2000 [1:00:13<15:12,  1.65s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9876, Requested 298. Please try again in 1.044s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1447, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 72%|███████▏  | 1448/2000 [1:00:15<17:02,  1.85s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9789, Requested 277. Please try again in 396ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1448, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 72%|███████▏  | 1449/2000 [1:00:17<16:56,  1.84s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9773, Requested 377. Please try again in 900ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1449, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 72%|███████▎  | 1450/2000 [1:00:19<17:45,  1.94s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9784, Requested 415. Please try again in 1.194s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1450, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9741, Requested 415. Please try again in 936ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 73%|███████▎  | 1451/2000 [1:00:24<24:16,  2.65s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1451, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 73%|███████▎  | 1452/2000 [1:00:24<18:32,  2.03s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9712, Requested 344. Please try again in 336ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1452, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9664, Requested 344. Please try again in 48ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 73%|███████▎  | 1453/2000 [1:00:29<25:44,  2.82s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1453, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 73%|███████▎  | 1454/2000 [1:00:30<19:42,  2.17s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1454, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 73%|███████▎  | 1455/2000 [1:00:30<15:35,  1.72s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1455, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 73%|███████▎  | 1456/2000 [1:00:31<12:47,  1.41s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9853, Requested 281. Please try again in 804ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1456, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9832, Requested 281. Please try again in 678ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 73%|███████▎  | 1457/2000 [1:00:34<17:42,  1.96s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1457, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 73%|███████▎  | 1458/2000 [1:00:35<14:02,  1.55s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9833, Requested 345. Please try again in 1.068s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1458, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9710, Requested 345. Please try again in 330ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 73%|███████▎  | 1459/2000 [1:00:37<16:37,  1.84s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9751, Requested 359. Please try again in 660ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1459, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 73%|███████▎  | 1460/2000 [1:00:39<16:43,  1.86s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9786, Requested 427. Please try again in 1.278s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1460, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9706, Requested 427. Please try again in 798ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 73%|███████▎  | 1461/2000 [1:00:43<22:10,  2.47s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1461, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 73%|███████▎  | 1462/2000 [1:00:44<17:08,  1.91s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9773, Requested 319. Please try again in 552ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1462, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9734, Requested 319. Please try again in 318ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 73%|███████▎  | 1463/2000 [1:00:46<17:37,  1.97s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9731, Requested 294. Please try again in 150ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1463, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 73%|███████▎  | 1464/2000 [1:00:47<14:04,  1.58s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9923, Requested 324. Please try again in 1.482s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1464, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9839, Requested 324. Please try again in 977ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 3.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9812, Requested 324. Please try again in 816ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 73%|███████▎  | 1465/2000 [1:00:52<23:28,  2.63s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1465, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 73%|███████▎  | 1466/2000 [1:00:52<18:10,  2.04s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1466, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 73%|███████▎  | 1467/2000 [1:00:53<13:58,  1.57s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9758, Requested 267. Please try again in 150ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1467, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 73%|███████▎  | 1468/2000 [1:00:54<12:05,  1.36s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9884, Requested 288. Please try again in 1.032s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1468, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9856, Requested 288. Please try again in 864ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 2.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9802, Requested 288. Please try again in 540ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 73%|███████▎  | 1469/2000 [1:00:57<18:32,  2.09s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1469, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 74%|███████▎  | 1470/2000 [1:00:58<14:32,  1.65s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9723, Requested 555. Please try again in 1.668s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1470, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9633, Requested 555. Please try again in 1.128s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 74%|███████▎  | 1471/2000 [1:01:03<23:34,  2.67s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1471, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 74%|███████▎  | 1472/2000 [1:01:04<17:58,  2.04s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1472, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 74%|███████▎  | 1473/2000 [1:01:04<13:44,  1.56s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9804, Requested 316. Please try again in 720ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1473, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 74%|███████▎  | 1474/2000 [1:01:06<14:31,  1.66s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9805, Requested 333. Please try again in 828ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1474, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 74%|███████▍  | 1475/2000 [1:01:08<15:07,  1.73s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9820, Requested 375. Please try again in 1.17s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1475, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 74%|███████▍  | 1476/2000 [1:01:10<16:37,  1.90s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9798, Requested 347. Please try again in 870ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1476, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 74%|███████▍  | 1477/2000 [1:01:12<16:12,  1.86s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9851, Requested 412. Please try again in 1.578s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1477, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9769, Requested 412. Please try again in 1.086s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9589, Requested 412. Please try again in 6ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 74%|███████▍  | 1478/2000 [1:01:15<19:23,  2.23s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1478, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 74%|███████▍  | 1479/2000 [1:01:16<15:35,  1.79s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9873, Requested 305. Please try again in 1.068s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1479, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9802, Requested 305. Please try again in 642ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 74%|███████▍  | 1480/2000 [1:01:20<21:20,  2.46s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1480, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 74%|███████▍  | 1481/2000 [1:01:21<16:30,  1.91s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9732, Requested 307. Please try again in 234ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1481, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 74%|███████▍  | 1482/2000 [1:01:22<15:35,  1.81s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9781, Requested 287. Please try again in 408ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1482, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9730, Requested 287. Please try again in 102ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 74%|███████▍  | 1483/2000 [1:01:25<18:15,  2.12s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1483, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 74%|███████▍  | 1484/2000 [1:01:25<14:10,  1.65s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9819, Requested 305. Please try again in 744ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1484, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9777, Requested 305. Please try again in 492ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 74%|███████▍  | 1485/2000 [1:01:29<19:18,  2.25s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9511, Requested 536. Please try again in 282ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1485, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 74%|███████▍  | 1486/2000 [1:01:32<19:39,  2.30s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1486, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 74%|███████▍  | 1487/2000 [1:01:32<14:58,  1.75s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9831, Requested 268. Please try again in 594ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1487, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 74%|███████▍  | 1488/2000 [1:01:34<15:44,  1.85s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9765, Requested 324. Please try again in 534ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1488, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 74%|███████▍  | 1489/2000 [1:01:36<15:30,  1.82s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9787, Requested 285. Please try again in 432ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1489, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 74%|███████▍  | 1490/2000 [1:01:39<17:50,  2.10s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1490, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 75%|███████▍  | 1491/2000 [1:01:40<15:06,  1.78s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9809, Requested 312. Please try again in 726ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1491, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 75%|███████▍  | 1492/2000 [1:01:41<14:07,  1.67s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9878, Requested 316. Please try again in 1.164s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1492, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9775, Requested 316. Please try again in 546ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 75%|███████▍  | 1493/2000 [1:01:44<18:28,  2.19s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1493, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 75%|███████▍  | 1494/2000 [1:01:45<14:13,  1.69s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9816, Requested 335. Please try again in 906ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1494, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 75%|███████▍  | 1495/2000 [1:01:47<16:13,  1.93s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9727, Requested 332. Please try again in 354ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1495, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9680, Requested 332. Please try again in 72ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 75%|███████▍  | 1496/2000 [1:01:50<18:17,  2.18s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1496, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 75%|███████▍  | 1497/2000 [1:01:51<13:48,  1.65s/it]INFO:backoff:Backing off get_labels_batch(...) for 2.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9876, Requested 328. Please try again in 1.224s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1497, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 75%|███████▍  | 1498/2000 [1:01:53<16:03,  1.92s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9778, Requested 286. Please try again in 384ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1498, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 75%|███████▍  | 1499/2000 [1:01:56<17:42,  2.12s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1499, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 75%|███████▌  | 1500/2000 [1:01:56<13:55,  1.67s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9859, Requested 285. Please try again in 864ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1500, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9830, Requested 285. Please try again in 690ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 75%|███████▌  | 1501/2000 [1:02:00<19:12,  2.31s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1501, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 75%|███████▌  | 1502/2000 [1:02:01<15:11,  1.83s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9763, Requested 285. Please try again in 288ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1502, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 75%|███████▌  | 1503/2000 [1:02:03<16:50,  2.03s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1503, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 75%|███████▌  | 1504/2000 [1:02:05<15:02,  1.82s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9736, Requested 335. Please try again in 426ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1504, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 75%|███████▌  | 1505/2000 [1:02:07<16:02,  1.94s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9702, Requested 364. Please try again in 396ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1505, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 75%|███████▌  | 1506/2000 [1:02:09<15:37,  1.90s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9758, Requested 275. Please try again in 198ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1506, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 75%|███████▌  | 1507/2000 [1:02:10<13:29,  1.64s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9865, Requested 472. Please try again in 2.022s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1507, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9690, Requested 472. Please try again in 972ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 75%|███████▌  | 1508/2000 [1:02:14<19:04,  2.33s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1508, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 75%|███████▌  | 1509/2000 [1:02:14<14:51,  1.82s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9863, Requested 328. Please try again in 1.146s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1509, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9761, Requested 328. Please try again in 534ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 2.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9710, Requested 328. Please try again in 228ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 76%|███████▌  | 1510/2000 [1:02:19<21:00,  2.57s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1510, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 76%|███████▌  | 1511/2000 [1:02:19<16:04,  1.97s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9747, Requested 345. Please try again in 552ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1511, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 76%|███████▌  | 1512/2000 [1:02:21<15:55,  1.96s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9766, Requested 367. Please try again in 798ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1512, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 76%|███████▌  | 1513/2000 [1:02:23<16:07,  1.99s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9775, Requested 291. Please try again in 396ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1513, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 76%|███████▌  | 1514/2000 [1:02:25<14:31,  1.79s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9843, Requested 598. Please try again in 2.646s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1514, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9649, Requested 598. Please try again in 1.482s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 76%|███████▌  | 1515/2000 [1:02:29<21:47,  2.70s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9596, Requested 472. Please try again in 408ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1515, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 76%|███████▌  | 1516/2000 [1:02:31<19:47,  2.45s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9746, Requested 300. Please try again in 276ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1516, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 76%|███████▌  | 1517/2000 [1:02:33<18:44,  2.33s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9706, Requested 385. Please try again in 546ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1517, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 76%|███████▌  | 1518/2000 [1:02:35<18:02,  2.24s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9748, Requested 276. Please try again in 144ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1518, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 76%|███████▌  | 1519/2000 [1:02:37<17:41,  2.21s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9673, Requested 592. Please try again in 1.59s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1519, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9453, Requested 592. Please try again in 270ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 76%|███████▌  | 1520/2000 [1:02:42<22:39,  2.83s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1520, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 76%|███████▌  | 1521/2000 [1:02:42<17:19,  2.17s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9828, Requested 459. Please try again in 1.722s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 3.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9810, Requested 459. Please try again in 1.614s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1521, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 76%|███████▌  | 1522/2000 [1:02:46<21:44,  2.73s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1522, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 76%|███████▌  | 1523/2000 [1:02:47<16:46,  2.11s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9801, Requested 291. Please try again in 552ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1523, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9765, Requested 291. Please try again in 336ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 76%|███████▌  | 1524/2000 [1:02:48<15:03,  1.90s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9860, Requested 413. Please try again in 1.638s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1524, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9662, Requested 413. Please try again in 450ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 76%|███████▋  | 1525/2000 [1:02:53<21:38,  2.73s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1525, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 76%|███████▋  | 1526/2000 [1:02:54<16:01,  2.03s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1526, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 76%|███████▋  | 1527/2000 [1:02:54<12:32,  1.59s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9897, Requested 355. Please try again in 1.512s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1527, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 76%|███████▋  | 1528/2000 [1:02:57<14:25,  1.83s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9840, Requested 345. Please try again in 1.11s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1528, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9807, Requested 345. Please try again in 912ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 76%|███████▋  | 1529/2000 [1:03:00<18:36,  2.37s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1529, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 76%|███████▋  | 1530/2000 [1:03:01<13:56,  1.78s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9853, Requested 397. Please try again in 1.5s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1530, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 77%|███████▋  | 1531/2000 [1:03:03<15:35,  1.99s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9819, Requested 292. Please try again in 666ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1531, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 77%|███████▋  | 1532/2000 [1:03:05<15:43,  2.02s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9770, Requested 352. Please try again in 732ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1532, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 77%|███████▋  | 1533/2000 [1:03:08<16:45,  2.15s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1533, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 77%|███████▋  | 1534/2000 [1:03:08<13:41,  1.76s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9848, Requested 291. Please try again in 834ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1534, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 77%|███████▋  | 1535/2000 [1:03:10<13:27,  1.74s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9856, Requested 282. Please try again in 828ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1535, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 77%|███████▋  | 1536/2000 [1:03:12<13:29,  1.74s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9848, Requested 284. Please try again in 792ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1536, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 77%|███████▋  | 1537/2000 [1:03:14<13:24,  1.74s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9848, Requested 312. Please try again in 960ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1537, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9742, Requested 312. Please try again in 324ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 77%|███████▋  | 1538/2000 [1:03:18<19:13,  2.50s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1538, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 77%|███████▋  | 1539/2000 [1:03:19<15:22,  2.00s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9732, Requested 363. Please try again in 570ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1539, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 77%|███████▋  | 1540/2000 [1:03:21<15:30,  2.02s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9742, Requested 303. Please try again in 270ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1540, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 77%|███████▋  | 1541/2000 [1:03:24<17:16,  2.26s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1541, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 77%|███████▋  | 1542/2000 [1:03:24<13:26,  1.76s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9848, Requested 309. Please try again in 941ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1542, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9820, Requested 309. Please try again in 774ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 5.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9770, Requested 309. Please try again in 474ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 77%|███████▋  | 1543/2000 [1:03:31<24:59,  3.28s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1543, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 77%|███████▋  | 1544/2000 [1:03:32<18:47,  2.47s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1544, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 77%|███████▋  | 1545/2000 [1:03:32<14:29,  1.91s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1545, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 77%|███████▋  | 1546/2000 [1:03:33<11:31,  1.52s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1546, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 77%|███████▋  | 1547/2000 [1:03:33<09:31,  1.26s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9750, Requested 288. Please try again in 228ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1547, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 77%|███████▋  | 1548/2000 [1:03:36<12:28,  1.66s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1548, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 77%|███████▋  | 1549/2000 [1:03:37<10:05,  1.34s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9796, Requested 314. Please try again in 660ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1549, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 78%|███████▊  | 1550/2000 [1:03:39<11:18,  1.51s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9796, Requested 318. Please try again in 684ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1550, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9734, Requested 318. Please try again in 312ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 78%|███████▊  | 1551/2000 [1:03:43<16:59,  2.27s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1551, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 78%|███████▊  | 1552/2000 [1:03:43<13:19,  1.78s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9799, Requested 276. Please try again in 450ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1552, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 78%|███████▊  | 1553/2000 [1:03:46<14:39,  1.97s/it]INFO:backoff:Backing off get_labels_batch(...) for 2.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9677, Requested 345. Please try again in 132ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1553, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 78%|███████▊  | 1554/2000 [1:03:48<16:15,  2.19s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1554, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 78%|███████▊  | 1555/2000 [1:03:49<13:47,  1.86s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1555, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 78%|███████▊  | 1556/2000 [1:03:50<11:00,  1.49s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9860, Requested 341. Please try again in 1.206s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1556, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9712, Requested 341. Please try again in 318ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 78%|███████▊  | 1557/2000 [1:03:54<15:55,  2.16s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1557, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 78%|███████▊  | 1558/2000 [1:03:54<12:36,  1.71s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9845, Requested 278. Please try again in 738ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1558, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 78%|███████▊  | 1559/2000 [1:03:57<14:34,  1.98s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1559, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 78%|███████▊  | 1560/2000 [1:03:58<11:20,  1.55s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9889, Requested 279. Please try again in 1.007s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1560, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 78%|███████▊  | 1561/2000 [1:04:00<12:21,  1.69s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9842, Requested 400. Please try again in 1.452s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1561, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 78%|███████▊  | 1562/2000 [1:04:02<13:33,  1.86s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9852, Requested 284. Please try again in 816ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1562, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 78%|███████▊  | 1563/2000 [1:04:05<15:26,  2.12s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9681, Requested 335. Please try again in 96ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1563, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 78%|███████▊  | 1564/2000 [1:04:06<14:53,  2.05s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9701, Requested 329. Please try again in 180ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1564, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 78%|███████▊  | 1565/2000 [1:04:08<14:24,  1.99s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9714, Requested 410. Please try again in 744ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1565, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 78%|███████▊  | 1566/2000 [1:04:11<15:17,  2.11s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9726, Requested 315. Please try again in 246ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1566, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 78%|███████▊  | 1567/2000 [1:04:12<12:33,  1.74s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9894, Requested 273. Please try again in 1.002s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1567, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 78%|███████▊  | 1568/2000 [1:04:14<14:11,  1.97s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9752, Requested 295. Please try again in 282ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1568, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9707, Requested 295. Please try again in 12ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 78%|███████▊  | 1569/2000 [1:04:17<16:18,  2.27s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1569, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 78%|███████▊  | 1570/2000 [1:04:18<12:46,  1.78s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9808, Requested 349. Please try again in 941ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1570, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9765, Requested 349. Please try again in 684ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 79%|███████▊  | 1571/2000 [1:04:19<12:20,  1.73s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9881, Requested 318. Please try again in 1.194s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1571, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9853, Requested 318. Please try again in 1.026s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 79%|███████▊  | 1572/2000 [1:04:24<18:53,  2.65s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1572, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 79%|███████▊  | 1573/2000 [1:04:25<14:31,  2.04s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1573, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 79%|███████▊  | 1574/2000 [1:04:26<11:59,  1.69s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9785, Requested 314. Please try again in 594ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1574, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9714, Requested 314. Please try again in 168ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 79%|███████▉  | 1575/2000 [1:04:30<18:28,  2.61s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1575, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 79%|███████▉  | 1576/2000 [1:04:31<14:13,  2.01s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9535, Requested 654. Please try again in 1.134s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1576, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 79%|███████▉  | 1577/2000 [1:04:33<14:55,  2.12s/it]INFO:backoff:Backing off get_labels_batch(...) for 2.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9729, Requested 377. Please try again in 636ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1577, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 79%|███████▉  | 1578/2000 [1:04:36<16:05,  2.29s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1578, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 79%|███████▉  | 1579/2000 [1:04:37<12:43,  1.81s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9826, Requested 282. Please try again in 648ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1579, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 79%|███████▉  | 1580/2000 [1:04:39<13:09,  1.88s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9754, Requested 313. Please try again in 402ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1580, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 79%|███████▉  | 1581/2000 [1:04:41<14:21,  2.06s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9671, Requested 346. Please try again in 102ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1581, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 79%|███████▉  | 1582/2000 [1:04:42<11:52,  1.71s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9869, Requested 298. Please try again in 1.002s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1582, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 79%|███████▉  | 1583/2000 [1:04:44<12:07,  1.75s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9858, Requested 306. Please try again in 984ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1583, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9803, Requested 306. Please try again in 654ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 79%|███████▉  | 1584/2000 [1:04:48<17:50,  2.57s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1584, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 79%|███████▉  | 1585/2000 [1:04:49<13:30,  1.95s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9730, Requested 294. Please try again in 144ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 3.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9715, Requested 294. Please try again in 54ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1585, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 79%|███████▉  | 1586/2000 [1:04:53<17:59,  2.61s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1586, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 79%|███████▉  | 1587/2000 [1:04:54<13:50,  2.01s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9583, Requested 596. Please try again in 1.074s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1587, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9499, Requested 596. Please try again in 570ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 79%|███████▉  | 1588/2000 [1:04:56<14:15,  2.08s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9766, Requested 420. Please try again in 1.116s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1588, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 79%|███████▉  | 1589/2000 [1:04:58<13:44,  2.01s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9878, Requested 290. Please try again in 1.007s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1589, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9778, Requested 290. Please try again in 408ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 80%|███████▉  | 1590/2000 [1:04:59<12:55,  1.89s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9900, Requested 461. Please try again in 2.166s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1590, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9658, Requested 461. Please try again in 714ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 80%|███████▉  | 1591/2000 [1:05:04<19:00,  2.79s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1591, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 80%|███████▉  | 1592/2000 [1:05:05<14:08,  2.08s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9733, Requested 291. Please try again in 144ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1592, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 80%|███████▉  | 1593/2000 [1:05:06<12:22,  1.83s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9818, Requested 434. Please try again in 1.512s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1593, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9582, Requested 434. Please try again in 96ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 80%|███████▉  | 1594/2000 [1:05:09<14:35,  2.16s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9740, Requested 311. Please try again in 306ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1594, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 80%|███████▉  | 1595/2000 [1:05:12<15:36,  2.31s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1595, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 80%|███████▉  | 1596/2000 [1:05:12<12:38,  1.88s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9823, Requested 281. Please try again in 624ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1596, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 80%|███████▉  | 1597/2000 [1:05:14<11:29,  1.71s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9885, Requested 397. Please try again in 1.692s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1597, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 80%|███████▉  | 1598/2000 [1:05:17<13:42,  2.05s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9790, Requested 308. Please try again in 588ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1598, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9700, Requested 308. Please try again in 48ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 80%|███████▉  | 1599/2000 [1:05:21<17:39,  2.64s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9420, Requested 716. Please try again in 816ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1599, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 80%|████████  | 1600/2000 [1:05:23<16:18,  2.45s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9752, Requested 379. Please try again in 786ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1600, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 80%|████████  | 1601/2000 [1:05:25<15:55,  2.40s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9738, Requested 280. Please try again in 108ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1601, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 80%|████████  | 1602/2000 [1:05:27<15:33,  2.34s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9653, Requested 494. Please try again in 882ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1602, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 80%|████████  | 1603/2000 [1:05:29<15:33,  2.35s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9723, Requested 312. Please try again in 210ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1603, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 80%|████████  | 1604/2000 [1:05:32<15:08,  2.29s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1604, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 80%|████████  | 1605/2000 [1:05:32<11:32,  1.75s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9885, Requested 325. Please try again in 1.26s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1605, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 80%|████████  | 1606/2000 [1:05:34<11:55,  1.82s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9877, Requested 518. Please try again in 2.37s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1606, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9741, Requested 518. Please try again in 1.554s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 80%|████████  | 1607/2000 [1:05:37<14:04,  2.15s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9875, Requested 376. Please try again in 1.506s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1607, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9666, Requested 376. Please try again in 251ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 80%|████████  | 1608/2000 [1:05:43<21:08,  3.23s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1608, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 80%|████████  | 1609/2000 [1:05:44<16:21,  2.51s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1609, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 80%|████████  | 1610/2000 [1:05:44<12:42,  1.96s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1610, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 81%|████████  | 1611/2000 [1:05:45<09:55,  1.53s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9820, Requested 325. Please try again in 870ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1611, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9711, Requested 325. Please try again in 216ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 81%|████████  | 1612/2000 [1:05:51<18:55,  2.93s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1612, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 81%|████████  | 1613/2000 [1:05:52<14:27,  2.24s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1613, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 81%|████████  | 1614/2000 [1:05:52<11:37,  1.81s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1614, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 81%|████████  | 1615/2000 [1:05:53<09:17,  1.45s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9800, Requested 367. Please try again in 1.002s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1615, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 81%|████████  | 1616/2000 [1:05:55<10:58,  1.71s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9768, Requested 298. Please try again in 396ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1616, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 81%|████████  | 1617/2000 [1:05:58<12:40,  1.98s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1617, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 81%|████████  | 1618/2000 [1:05:59<10:21,  1.63s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9842, Requested 293. Please try again in 810ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1618, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 81%|████████  | 1619/2000 [1:06:01<11:32,  1.82s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9762, Requested 275. Please try again in 222ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1619, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 81%|████████  | 1620/2000 [1:06:02<09:57,  1.57s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9874, Requested 367. Please try again in 1.446s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1620, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9840, Requested 367. Please try again in 1.242s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 81%|████████  | 1621/2000 [1:06:06<13:55,  2.20s/it]INFO:backoff:Backing off get_labels_batch(...) for 2.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9613, Requested 402. Please try again in 90ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1621, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 81%|████████  | 1622/2000 [1:06:08<14:49,  2.35s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1622, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 81%|████████  | 1623/2000 [1:06:09<11:24,  1.81s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9794, Requested 295. Please try again in 534ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1623, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 81%|████████  | 1624/2000 [1:06:11<12:32,  2.00s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9681, Requested 336. Please try again in 102ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1624, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 81%|████████▏ | 1625/2000 [1:06:13<12:17,  1.97s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9694, Requested 318. Please try again in 72ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1625, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 81%|████████▏ | 1626/2000 [1:06:15<11:34,  1.86s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9742, Requested 430. Please try again in 1.032s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1626, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 81%|████████▏ | 1627/2000 [1:06:18<13:19,  2.14s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1627, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 81%|████████▏ | 1628/2000 [1:06:18<10:14,  1.65s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9894, Requested 405. Please try again in 1.794s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1628, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9810, Requested 405. Please try again in 1.29s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 81%|████████▏ | 1629/2000 [1:06:21<12:24,  2.01s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9809, Requested 283. Please try again in 552ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1629, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 82%|████████▏ | 1630/2000 [1:06:23<13:07,  2.13s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9698, Requested 412. Please try again in 660ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1630, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 82%|████████▏ | 1631/2000 [1:06:26<14:42,  2.39s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1631, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 82%|████████▏ | 1632/2000 [1:06:27<12:06,  1.97s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9731, Requested 290. Please try again in 125ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1632, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 82%|████████▏ | 1633/2000 [1:06:29<10:22,  1.70s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9844, Requested 403. Please try again in 1.482s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1633, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9743, Requested 403. Please try again in 876ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 82%|████████▏ | 1634/2000 [1:06:33<15:06,  2.48s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1634, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 82%|████████▏ | 1635/2000 [1:06:33<11:34,  1.90s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9691, Requested 610. Please try again in 1.806s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1635, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9400, Requested 610. Please try again in 60ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 82%|████████▏ | 1636/2000 [1:06:37<15:23,  2.54s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1636, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 82%|████████▏ | 1637/2000 [1:06:38<11:36,  1.92s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9822, Requested 353. Please try again in 1.05s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1637, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9708, Requested 353. Please try again in 366ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 82%|████████▏ | 1638/2000 [1:06:41<12:56,  2.15s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9718, Requested 318. Please try again in 216ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1638, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 82%|████████▏ | 1639/2000 [1:06:42<12:00,  2.00s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9756, Requested 315. Please try again in 426ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1639, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 82%|████████▏ | 1640/2000 [1:06:45<12:31,  2.09s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1640, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 82%|████████▏ | 1641/2000 [1:06:45<10:18,  1.72s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9815, Requested 300. Please try again in 690ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1641, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 82%|████████▏ | 1642/2000 [1:06:47<09:37,  1.61s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9888, Requested 332. Please try again in 1.32s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1642, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9702, Requested 332. Please try again in 204ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 82%|████████▏ | 1643/2000 [1:06:50<11:45,  1.98s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9748, Requested 326. Please try again in 444ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1643, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 82%|████████▏ | 1644/2000 [1:06:52<12:18,  2.07s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1644, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 82%|████████▏ | 1645/2000 [1:06:52<09:22,  1.59s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9894, Requested 308. Please try again in 1.212s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1645, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 82%|████████▏ | 1646/2000 [1:06:55<10:57,  1.86s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9783, Requested 333. Please try again in 696ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1646, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 82%|████████▏ | 1647/2000 [1:06:57<11:14,  1.91s/it]INFO:backoff:Backing off get_labels_batch(...) for 2.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9774, Requested 380. Please try again in 924ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1647, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 82%|████████▏ | 1648/2000 [1:07:00<12:32,  2.14s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1648, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 82%|████████▏ | 1649/2000 [1:07:00<09:47,  1.67s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9888, Requested 372. Please try again in 1.56s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1649, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9653, Requested 372. Please try again in 150ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 82%|████████▎ | 1650/2000 [1:07:03<11:58,  2.05s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9763, Requested 269. Please try again in 192ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1650, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 83%|████████▎ | 1651/2000 [1:07:04<10:14,  1.76s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9859, Requested 277. Please try again in 816ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1651, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 83%|████████▎ | 1652/2000 [1:07:06<10:24,  1.80s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9831, Requested 394. Please try again in 1.35s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1652, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9773, Requested 394. Please try again in 1.002s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 83%|████████▎ | 1653/2000 [1:07:08<11:01,  1.91s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9849, Requested 331. Please try again in 1.08s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1653, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9742, Requested 331. Please try again in 438ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 83%|████████▎ | 1654/2000 [1:07:12<13:40,  2.37s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1654, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 83%|████████▎ | 1655/2000 [1:07:12<10:38,  1.85s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9850, Requested 504. Please try again in 2.124s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1655, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9777, Requested 504. Please try again in 1.686s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 83%|████████▎ | 1656/2000 [1:07:15<12:43,  2.22s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9804, Requested 294. Please try again in 588ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1656, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 83%|████████▎ | 1657/2000 [1:07:17<11:40,  2.04s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9828, Requested 303. Please try again in 786ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1657, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|████████▎ | 1658/2000 [1:07:19<11:25,  2.00s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9817, Requested 283. Please try again in 600ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1658, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9732, Requested 283. Please try again in 90ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 83%|████████▎ | 1659/2000 [1:07:22<13:24,  2.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1659, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|████████▎ | 1660/2000 [1:07:23<10:17,  1.82s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9757, Requested 311. Please try again in 408ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1660, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|████████▎ | 1661/2000 [1:07:25<10:28,  1.85s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9744, Requested 379. Please try again in 738ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1661, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9663, Requested 379. Please try again in 251ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 83%|████████▎ | 1662/2000 [1:07:29<15:24,  2.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1662, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|████████▎ | 1663/2000 [1:07:30<11:48,  2.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1663, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|████████▎ | 1664/2000 [1:07:32<11:03,  1.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1664, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|████████▎ | 1665/2000 [1:07:32<08:43,  1.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1665, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|████████▎ | 1666/2000 [1:07:33<07:28,  1.34s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9843, Requested 277. Please try again in 720ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1666, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|████████▎ | 1667/2000 [1:07:35<07:55,  1.43s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9852, Requested 505. Please try again in 2.142s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1667, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9604, Requested 505. Please try again in 654ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 83%|████████▎ | 1668/2000 [1:07:40<13:52,  2.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1668, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|████████▎ | 1669/2000 [1:07:40<10:33,  1.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1669, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▎ | 1670/2000 [1:07:41<08:24,  1.53s/it]INFO:backoff:Backing off get_labels_batch(...) for 2.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9861, Requested 326. Please try again in 1.122s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1670, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▎ | 1671/2000 [1:07:43<10:06,  1.84s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9756, Requested 351. Please try again in 642ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1671, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▎ | 1672/2000 [1:07:45<10:12,  1.87s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9775, Requested 275. Please try again in 300ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 3.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9757, Requested 275. Please try again in 192ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1672, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▎ | 1673/2000 [1:07:50<14:19,  2.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1673, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▎ | 1674/2000 [1:07:50<10:54,  2.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1674, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 1675/2000 [1:07:51<09:01,  1.67s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9740, Requested 322. Please try again in 372ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1675, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 1676/2000 [1:07:54<10:07,  1.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1676, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 1677/2000 [1:07:55<08:37,  1.60s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9813, Requested 276. Please try again in 534ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1677, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9727, Requested 276. Please try again in 18ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 84%|████████▍ | 1678/2000 [1:07:59<13:18,  2.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1678, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 1679/2000 [1:08:00<10:07,  1.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1679, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 1680/2000 [1:08:00<08:02,  1.51s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9762, Requested 281. Please try again in 258ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1680, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 1681/2000 [1:08:03<09:21,  1.76s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9661, Requested 342. Please try again in 18ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1681, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 1682/2000 [1:08:05<10:20,  1.95s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9596, Requested 415. Please try again in 66ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1682, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 1683/2000 [1:08:06<09:14,  1.75s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9786, Requested 309. Please try again in 570ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1683, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 1684/2000 [1:08:08<08:34,  1.63s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9867, Requested 285. Please try again in 912ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1684, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9724, Requested 285. Please try again in 54ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 84%|████████▍ | 1685/2000 [1:08:11<11:07,  2.12s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9617, Requested 412. Please try again in 174ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1685, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 1686/2000 [1:08:13<10:52,  2.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1686, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 1687/2000 [1:08:14<09:00,  1.73s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9823, Requested 277. Please try again in 600ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1687, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 1688/2000 [1:08:15<08:33,  1.65s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9860, Requested 303. Please try again in 977ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1688, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9743, Requested 303. Please try again in 276ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 84%|████████▍ | 1689/2000 [1:08:20<13:47,  2.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1689, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 1690/2000 [1:08:21<10:33,  2.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1690, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|████████▍ | 1691/2000 [1:08:22<08:40,  1.68s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9762, Requested 373. Please try again in 810ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1691, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9649, Requested 373. Please try again in 132ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 85%|████████▍ | 1692/2000 [1:08:25<11:46,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1692, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|████████▍ | 1693/2000 [1:08:26<09:02,  1.77s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9720, Requested 294. Please try again in 84ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1693, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|████████▍ | 1694/2000 [1:08:27<08:25,  1.65s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9784, Requested 340. Please try again in 744ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1694, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|████████▍ | 1695/2000 [1:08:29<08:41,  1.71s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9809, Requested 292. Please try again in 606ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1695, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9790, Requested 292. Please try again in 492ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 85%|████████▍ | 1696/2000 [1:08:31<09:36,  1.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1696, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|████████▍ | 1697/2000 [1:08:32<07:32,  1.49s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9897, Requested 362. Please try again in 1.554s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1697, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|████████▍ | 1698/2000 [1:08:35<10:05,  2.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1698, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|████████▍ | 1699/2000 [1:08:36<08:21,  1.67s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9845, Requested 309. Please try again in 924ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1699, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|████████▌ | 1700/2000 [1:08:39<09:27,  1.89s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9751, Requested 281. Please try again in 192ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1700, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|████████▌ | 1701/2000 [1:08:41<10:04,  2.02s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9648, Requested 384. Please try again in 192ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1701, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|████████▌ | 1702/2000 [1:08:42<08:41,  1.75s/it]INFO:backoff:Backing off get_labels_batch(...) for 2.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9839, Requested 307. Please try again in 876ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1702, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|████████▌ | 1703/2000 [1:08:44<09:49,  1.98s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9724, Requested 302. Please try again in 156ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1703, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|████████▌ | 1704/2000 [1:08:46<09:43,  1.97s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9707, Requested 345. Please try again in 312ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1704, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|████████▌ | 1705/2000 [1:08:49<10:43,  2.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1705, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|████████▌ | 1706/2000 [1:08:50<08:39,  1.77s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9790, Requested 315. Please try again in 630ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1706, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9756, Requested 315. Please try again in 426ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 85%|████████▌ | 1707/2000 [1:08:53<10:08,  2.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1707, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|████████▌ | 1708/2000 [1:08:54<08:18,  1.71s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9787, Requested 292. Please try again in 474ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1708, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|████████▌ | 1709/2000 [1:08:56<08:55,  1.84s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9722, Requested 781. Please try again in 3.018s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1709, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9388, Requested 781. Please try again in 1.013s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 86%|████████▌ | 1710/2000 [1:09:01<13:26,  2.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1710, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 1711/2000 [1:09:01<10:11,  2.11s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9783, Requested 285. Please try again in 408ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1711, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 1712/2000 [1:09:03<09:22,  1.95s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9807, Requested 328. Please try again in 810ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1712, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 1713/2000 [1:09:05<09:33,  2.00s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9779, Requested 286. Please try again in 390ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1713, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 1714/2000 [1:09:07<10:04,  2.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1714, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 1715/2000 [1:09:08<07:48,  1.64s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9870, Requested 306. Please try again in 1.056s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1715, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 1716/2000 [1:09:10<07:58,  1.68s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9879, Requested 314. Please try again in 1.158s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1716, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9699, Requested 314. Please try again in 78ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 86%|████████▌ | 1717/2000 [1:09:14<11:41,  2.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1717, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 1718/2000 [1:09:15<09:01,  1.92s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9702, Requested 317. Please try again in 114ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1718, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 1719/2000 [1:09:16<08:35,  1.83s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9733, Requested 335. Please try again in 408ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1719, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9687, Requested 335. Please try again in 132ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 86%|████████▌ | 1720/2000 [1:09:19<10:15,  2.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1720, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 1721/2000 [1:09:20<08:00,  1.72s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9883, Requested 281. Please try again in 984ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1721, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 1722/2000 [1:09:22<08:12,  1.77s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9853, Requested 414. Please try again in 1.602s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1722, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9595, Requested 414. Please try again in 54ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 86%|████████▌ | 1723/2000 [1:09:26<11:40,  2.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1723, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 1724/2000 [1:09:27<09:00,  1.96s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9790, Requested 451. Please try again in 1.446s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1724, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9605, Requested 451. Please try again in 336ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 86%|████████▋ | 1725/2000 [1:09:29<09:13,  2.01s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9851, Requested 308. Please try again in 954ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1725, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9723, Requested 308. Please try again in 186ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 86%|████████▋ | 1726/2000 [1:09:31<08:54,  1.95s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9864, Requested 325. Please try again in 1.134s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1726, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▋ | 1727/2000 [1:09:33<08:53,  1.95s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9856, Requested 356. Please try again in 1.272s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1727, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▋ | 1728/2000 [1:09:35<09:35,  2.11s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9790, Requested 344. Please try again in 804ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1728, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9685, Requested 344. Please try again in 174ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 86%|████████▋ | 1729/2000 [1:09:40<13:14,  2.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1729, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▋ | 1730/2000 [1:09:41<10:25,  2.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1730, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|████████▋ | 1731/2000 [1:09:41<08:05,  1.80s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9800, Requested 272. Please try again in 432ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1731, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9753, Requested 272. Please try again in 150ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 87%|████████▋ | 1732/2000 [1:09:45<10:11,  2.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1732, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|████████▋ | 1733/2000 [1:09:45<07:57,  1.79s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9806, Requested 563. Please try again in 2.214s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1733, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9497, Requested 563. Please try again in 360ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 87%|████████▋ | 1734/2000 [1:09:48<09:27,  2.13s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9831, Requested 335. Please try again in 996ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1734, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9801, Requested 335. Please try again in 816ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 87%|████████▋ | 1735/2000 [1:09:50<08:59,  2.04s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9868, Requested 431. Please try again in 1.794s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1735, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9753, Requested 431. Please try again in 1.104s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 2.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9675, Requested 431. Please try again in 636ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 87%|████████▋ | 1736/2000 [1:09:54<11:16,  2.56s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9639, Requested 452. Please try again in 546ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1736, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|████████▋ | 1737/2000 [1:09:56<10:33,  2.41s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9709, Requested 360. Please try again in 414ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1737, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|████████▋ | 1738/2000 [1:09:57<09:07,  2.09s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9839, Requested 277. Please try again in 696ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 2.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9818, Requested 277. Please try again in 570ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1738, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|████████▋ | 1739/2000 [1:10:00<10:21,  2.38s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9608, Requested 415. Please try again in 138ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1739, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|████████▋ | 1740/2000 [1:10:03<10:13,  2.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1740, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|████████▋ | 1741/2000 [1:10:03<07:47,  1.80s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9867, Requested 385. Please try again in 1.512s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1741, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|████████▋ | 1742/2000 [1:10:05<08:13,  1.91s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9873, Requested 274. Please try again in 882ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1742, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|████████▋ | 1743/2000 [1:10:08<08:41,  2.03s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9769, Requested 301. Please try again in 420ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1743, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|████████▋ | 1744/2000 [1:10:10<08:49,  2.07s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9711, Requested 391. Please try again in 612ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1744, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|████████▋ | 1745/2000 [1:10:12<08:47,  2.07s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9735, Requested 290. Please try again in 150ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1745, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|████████▋ | 1746/2000 [1:10:13<07:39,  1.81s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9825, Requested 520. Please try again in 2.07s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1746, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9674, Requested 520. Please try again in 1.164s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 87%|████████▋ | 1747/2000 [1:10:19<12:22,  2.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1747, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|████████▋ | 1748/2000 [1:10:19<09:19,  2.22s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9615, Requested 409. Please try again in 144ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1748, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|████████▋ | 1749/2000 [1:10:20<07:45,  1.85s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9831, Requested 287. Please try again in 708ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1749, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9727, Requested 287. Please try again in 84ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 88%|████████▊ | 1750/2000 [1:10:22<07:45,  1.86s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9803, Requested 363. Please try again in 996ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1750, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 1751/2000 [1:10:24<07:34,  1.82s/it]INFO:backoff:Backing off get_labels_batch(...) for 2.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9874, Requested 315. Please try again in 1.134s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1751, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 1752/2000 [1:10:27<08:33,  2.07s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9745, Requested 380. Please try again in 750ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1752, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9652, Requested 380. Please try again in 192ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 88%|████████▊ | 1753/2000 [1:10:29<09:08,  2.22s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9685, Requested 476. Please try again in 966ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1753, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 1754/2000 [1:10:31<09:14,  2.26s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9752, Requested 344. Please try again in 576ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1754, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9670, Requested 344. Please try again in 84ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 88%|████████▊ | 1755/2000 [1:10:37<12:53,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1755, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 1756/2000 [1:10:37<09:46,  2.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1756, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 1757/2000 [1:10:38<07:32,  1.86s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9810, Requested 341. Please try again in 906ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1757, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9785, Requested 341. Please try again in 756ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 88%|████████▊ | 1758/2000 [1:10:42<09:39,  2.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1758, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 1759/2000 [1:10:42<07:36,  1.90s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9806, Requested 484. Please try again in 1.74s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1759, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9613, Requested 484. Please try again in 582ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 88%|████████▊ | 1760/2000 [1:10:46<09:28,  2.37s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9675, Requested 415. Please try again in 540ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 1.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9660, Requested 415. Please try again in 450ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1760, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 1761/2000 [1:10:48<09:05,  2.28s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9726, Requested 361. Please try again in 522ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1761, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 1762/2000 [1:10:50<08:38,  2.18s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9756, Requested 348. Please try again in 624ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1762, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 1763/2000 [1:10:52<08:45,  2.22s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9717, Requested 352. Please try again in 414ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1763, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 1764/2000 [1:10:53<07:42,  1.96s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9832, Requested 353. Please try again in 1.11s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1764, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 1765/2000 [1:10:56<08:26,  2.16s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9738, Requested 318. Please try again in 336ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1765, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 1766/2000 [1:10:58<07:33,  1.94s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9810, Requested 476. Please try again in 1.716s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1766, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 1767/2000 [1:11:00<07:49,  2.01s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9900, Requested 483. Please try again in 2.298s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1767, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9611, Requested 483. Please try again in 564ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 88%|████████▊ | 1768/2000 [1:11:03<08:58,  2.32s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9834, Requested 361. Please try again in 1.17s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1768, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9710, Requested 361. Please try again in 426ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 88%|████████▊ | 1769/2000 [1:11:06<09:58,  2.59s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9661, Requested 351. Please try again in 72ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1769, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 1770/2000 [1:11:08<09:04,  2.37s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9690, Requested 475. Please try again in 990ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1770, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 89%|████████▊ | 1771/2000 [1:11:10<08:59,  2.36s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9745, Requested 325. Please try again in 420ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1771, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9700, Requested 325. Please try again in 150ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 89%|████████▊ | 1772/2000 [1:11:14<10:32,  2.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1772, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 89%|████████▊ | 1773/2000 [1:11:15<08:03,  2.13s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9800, Requested 323. Please try again in 738ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1773, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9723, Requested 323. Please try again in 276ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 89%|████████▊ | 1774/2000 [1:11:17<08:21,  2.22s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9708, Requested 423. Please try again in 786ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1774, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 89%|████████▉ | 1775/2000 [1:11:18<07:20,  1.96s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9890, Requested 904. Please try again in 4.764s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1775, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9839, Requested 904. Please try again in 4.458s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 6.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9785, Requested 904. Please try again in 4.134s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 89%|████████▉ | 1776/2000 [1:11:27<14:42,  3.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1776, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 89%|████████▉ | 1777/2000 [1:11:28<11:10,  3.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1777, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 89%|████████▉ | 1778/2000 [1:11:28<08:23,  2.27s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9759, Requested 289. Please try again in 288ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1778, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 89%|████████▉ | 1779/2000 [1:11:29<06:53,  1.87s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9887, Requested 353. Please try again in 1.44s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1779, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9727, Requested 353. Please try again in 480ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 89%|████████▉ | 1780/2000 [1:11:31<07:11,  1.96s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9883, Requested 289. Please try again in 1.032s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1780, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9848, Requested 289. Please try again in 822ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 89%|████████▉ | 1781/2000 [1:11:36<10:07,  2.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1781, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 89%|████████▉ | 1782/2000 [1:11:37<07:40,  2.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1782, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 89%|████████▉ | 1783/2000 [1:11:37<05:50,  1.61s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9874, Requested 421. Please try again in 1.77s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1783, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9636, Requested 421. Please try again in 342ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 89%|████████▉ | 1784/2000 [1:11:41<08:32,  2.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1784, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 89%|████████▉ | 1785/2000 [1:11:42<06:49,  1.91s/it]INFO:backoff:Backing off get_labels_batch(...) for 2.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9753, Requested 300. Please try again in 318ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1785, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 89%|████████▉ | 1786/2000 [1:11:45<07:52,  2.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1786, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 89%|████████▉ | 1787/2000 [1:11:46<06:18,  1.78s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9778, Requested 287. Please try again in 390ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1787, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 89%|████████▉ | 1788/2000 [1:11:48<06:33,  1.86s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9726, Requested 343. Please try again in 414ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1788, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 89%|████████▉ | 1789/2000 [1:11:49<05:37,  1.60s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9890, Requested 296. Please try again in 1.116s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1789, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9811, Requested 296. Please try again in 642ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 90%|████████▉ | 1790/2000 [1:11:51<06:38,  1.90s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9757, Requested 372. Please try again in 774ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1790, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9724, Requested 372. Please try again in 576ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 90%|████████▉ | 1791/2000 [1:11:53<06:25,  1.85s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9827, Requested 284. Please try again in 666ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1791, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9766, Requested 284. Please try again in 300ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 90%|████████▉ | 1792/2000 [1:11:58<09:28,  2.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1792, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|████████▉ | 1793/2000 [1:11:59<07:31,  2.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1793, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|████████▉ | 1794/2000 [1:11:59<05:53,  1.72s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9761, Requested 359. Please try again in 720ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1794, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|████████▉ | 1795/2000 [1:12:02<06:37,  1.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1795, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|████████▉ | 1796/2000 [1:12:02<05:00,  1.47s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9925, Requested 364. Please try again in 1.734s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1796, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9709, Requested 364. Please try again in 438ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 90%|████████▉ | 1797/2000 [1:12:06<07:13,  2.13s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9672, Requested 414. Please try again in 516ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1797, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|████████▉ | 1798/2000 [1:12:07<06:30,  1.93s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9816, Requested 391. Please try again in 1.242s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1798, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9683, Requested 391. Please try again in 444ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 90%|████████▉ | 1799/2000 [1:12:10<06:58,  2.08s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9790, Requested 288. Please try again in 468ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1799, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 1800/2000 [1:12:12<06:37,  1.99s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9780, Requested 428. Please try again in 1.248s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1800, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 1801/2000 [1:12:14<06:46,  2.04s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9836, Requested 272. Please try again in 648ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1801, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 1802/2000 [1:12:15<05:58,  1.81s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9898, Requested 320. Please try again in 1.308s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1802, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 1803/2000 [1:12:17<06:35,  2.01s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9807, Requested 330. Please try again in 822ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1803, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 1804/2000 [1:12:19<06:16,  1.92s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9839, Requested 276. Please try again in 690ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1804, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 1805/2000 [1:12:20<05:34,  1.72s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9915, Requested 290. Please try again in 1.23s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1805, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 1806/2000 [1:12:23<05:59,  1.86s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9847, Requested 345. Please try again in 1.152s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1806, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9727, Requested 345. Please try again in 432ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 90%|█████████ | 1807/2000 [1:12:25<06:07,  1.90s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9851, Requested 349. Please try again in 1.2s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1807, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 1808/2000 [1:12:27<06:11,  1.93s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9862, Requested 324. Please try again in 1.116s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1808, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9723, Requested 324. Please try again in 282ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 90%|█████████ | 1809/2000 [1:12:32<09:15,  2.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1809, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 1810/2000 [1:12:32<06:56,  2.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1810, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 91%|█████████ | 1811/2000 [1:12:33<05:28,  1.74s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9815, Requested 329. Please try again in 864ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1811, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 91%|█████████ | 1812/2000 [1:12:35<05:42,  1.82s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9798, Requested 318. Please try again in 696ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1812, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9721, Requested 318. Please try again in 234ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 91%|█████████ | 1813/2000 [1:12:37<06:10,  1.98s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9718, Requested 304. Please try again in 132ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1813, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 91%|█████████ | 1814/2000 [1:12:39<05:20,  1.73s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9830, Requested 314. Please try again in 864ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1814, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9711, Requested 314. Please try again in 150ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 91%|█████████ | 1815/2000 [1:12:41<05:54,  1.91s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9746, Requested 463. Please try again in 1.254s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1815, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9578, Requested 463. Please try again in 246ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 91%|█████████ | 1816/2000 [1:12:44<06:44,  2.20s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9729, Requested 281. Please try again in 60ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1816, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 91%|█████████ | 1817/2000 [1:12:46<06:47,  2.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1817, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 91%|█████████ | 1818/2000 [1:12:47<05:18,  1.75s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9832, Requested 398. Please try again in 1.38s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1818, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9789, Requested 398. Please try again in 1.122s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 5.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9630, Requested 398. Please try again in 168ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 91%|█████████ | 1819/2000 [1:12:54<10:07,  3.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1819, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 91%|█████████ | 1820/2000 [1:12:54<07:34,  2.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1820, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 91%|█████████ | 1821/2000 [1:12:55<05:49,  1.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1821, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 91%|█████████ | 1822/2000 [1:12:55<04:26,  1.50s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9699, Requested 388. Please try again in 522ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1822, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 91%|█████████ | 1823/2000 [1:12:57<04:50,  1.64s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9736, Requested 292. Please try again in 168ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1823, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 91%|█████████ | 1824/2000 [1:12:59<04:33,  1.55s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9799, Requested 399. Please try again in 1.188s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1824, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 91%|█████████▏| 1825/2000 [1:13:01<04:49,  1.66s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9860, Requested 293. Please try again in 918ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1825, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9822, Requested 293. Please try again in 690ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 91%|█████████▏| 1826/2000 [1:13:02<04:41,  1.62s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9898, Requested 320. Please try again in 1.308s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1826, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 91%|█████████▏| 1827/2000 [1:13:04<05:11,  1.80s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9842, Requested 284. Please try again in 756ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1827, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9755, Requested 284. Please try again in 234ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 91%|█████████▏| 1828/2000 [1:13:08<06:37,  2.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1828, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 91%|█████████▏| 1829/2000 [1:13:09<05:18,  1.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1829, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 1830/2000 [1:13:09<04:10,  1.47s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9902, Requested 342. Please try again in 1.464s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1830, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9880, Requested 342. Please try again in 1.332s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 2.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9761, Requested 342. Please try again in 618ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 92%|█████████▏| 1831/2000 [1:13:14<06:40,  2.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1831, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 1832/2000 [1:13:14<05:01,  1.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1832, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 1833/2000 [1:13:15<03:58,  1.43s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9894, Requested 313. Please try again in 1.242s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1833, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9790, Requested 313. Please try again in 618ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 92%|█████████▏| 1834/2000 [1:13:18<05:22,  1.94s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9679, Requested 601. Please try again in 1.68s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1834, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9528, Requested 601. Please try again in 774ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 4.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9477, Requested 601. Please try again in 468ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 92%|█████████▏| 1835/2000 [1:13:24<09:04,  3.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1835, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 1836/2000 [1:13:25<06:51,  2.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1836, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 1837/2000 [1:13:26<05:28,  2.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1837, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 1838/2000 [1:13:27<04:34,  1.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1838, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 1839/2000 [1:13:27<03:30,  1.31s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9876, Requested 292. Please try again in 1.007s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1839, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 1840/2000 [1:13:30<04:18,  1.61s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9785, Requested 345. Please try again in 780ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1840, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 1841/2000 [1:13:31<04:26,  1.68s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9829, Requested 275. Please try again in 624ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1841, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 1842/2000 [1:13:33<04:33,  1.73s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9791, Requested 429. Please try again in 1.32s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1842, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 1843/2000 [1:13:36<05:10,  1.98s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9776, Requested 353. Please try again in 774ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1843, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 1844/2000 [1:13:38<05:31,  2.13s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9708, Requested 370. Please try again in 468ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1844, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 1845/2000 [1:13:39<04:37,  1.79s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9885, Requested 307. Please try again in 1.152s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1845, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9788, Requested 307. Please try again in 570ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 92%|█████████▏| 1846/2000 [1:13:43<06:25,  2.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1846, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 1847/2000 [1:13:44<04:45,  1.86s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9716, Requested 325. Please try again in 246ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1847, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 1848/2000 [1:13:46<04:53,  1.93s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9697, Requested 664. Please try again in 2.166s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1848, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9524, Requested 664. Please try again in 1.128s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 92%|█████████▏| 1849/2000 [1:13:50<06:42,  2.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1849, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▎| 1850/2000 [1:13:51<05:20,  2.14s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9809, Requested 351. Please try again in 960ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1850, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 93%|█████████▎| 1851/2000 [1:13:54<05:37,  2.26s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9731, Requested 430. Please try again in 966ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1851, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9703, Requested 430. Please try again in 798ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 93%|█████████▎| 1852/2000 [1:13:58<07:15,  2.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1852, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 93%|█████████▎| 1853/2000 [1:13:59<05:27,  2.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1853, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 93%|█████████▎| 1854/2000 [1:13:59<04:08,  1.70s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9838, Requested 319. Please try again in 941ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1854, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9775, Requested 319. Please try again in 564ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 93%|█████████▎| 1855/2000 [1:14:01<04:03,  1.68s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9882, Requested 493. Please try again in 2.25s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1855, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9598, Requested 493. Please try again in 546ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 93%|█████████▎| 1856/2000 [1:14:06<06:09,  2.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1856, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 93%|█████████▎| 1857/2000 [1:14:06<04:44,  1.99s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9805, Requested 292. Please try again in 582ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1857, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 93%|█████████▎| 1858/2000 [1:14:08<04:32,  1.92s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9810, Requested 275. Please try again in 510ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1858, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 93%|█████████▎| 1859/2000 [1:14:10<04:42,  2.00s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9721, Requested 342. Please try again in 378ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1859, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9666, Requested 342. Please try again in 48ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 93%|█████████▎| 1860/2000 [1:14:15<06:56,  2.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1860, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 93%|█████████▎| 1861/2000 [1:14:16<05:16,  2.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1861, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 93%|█████████▎| 1862/2000 [1:14:17<04:13,  1.84s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9718, Requested 325. Please try again in 258ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1862, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 93%|█████████▎| 1863/2000 [1:14:18<03:54,  1.71s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9802, Requested 660. Please try again in 2.772s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1863, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9732, Requested 660. Please try again in 2.352s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 1.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9534, Requested 660. Please try again in 1.164s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 93%|█████████▎| 1864/2000 [1:14:22<05:11,  2.29s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9813, Requested 374. Please try again in 1.122s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1864, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 93%|█████████▎| 1865/2000 [1:14:24<05:09,  2.29s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9799, Requested 299. Please try again in 588ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1865, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 93%|█████████▎| 1866/2000 [1:14:26<04:59,  2.23s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9749, Requested 355. Please try again in 624ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1866, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 93%|█████████▎| 1867/2000 [1:14:28<04:39,  2.10s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9806, Requested 357. Please try again in 977ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1867, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9769, Requested 357. Please try again in 756ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 93%|█████████▎| 1868/2000 [1:14:30<04:20,  1.97s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9877, Requested 418. Please try again in 1.77s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1868, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9652, Requested 418. Please try again in 420ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 93%|█████████▎| 1869/2000 [1:14:34<05:59,  2.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1869, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▎| 1870/2000 [1:14:35<04:39,  2.15s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9693, Requested 322. Please try again in 90ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1870, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▎| 1871/2000 [1:14:36<03:52,  1.80s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9847, Requested 363. Please try again in 1.26s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1871, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▎| 1872/2000 [1:14:38<03:59,  1.87s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9859, Requested 283. Please try again in 852ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1872, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9823, Requested 283. Please try again in 636ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 5.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9787, Requested 283. Please try again in 420ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 94%|█████████▎| 1873/2000 [1:14:44<06:37,  3.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1873, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▎| 1874/2000 [1:14:45<04:56,  2.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1874, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▍| 1875/2000 [1:14:45<03:49,  1.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1875, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▍| 1876/2000 [1:14:46<02:59,  1.45s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9843, Requested 373. Please try again in 1.296s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1876, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9705, Requested 373. Please try again in 468ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 94%|█████████▍| 1877/2000 [1:14:51<05:12,  2.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1877, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▍| 1878/2000 [1:14:52<03:58,  1.96s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9668, Requested 839. Please try again in 3.042s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1878, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9443, Requested 839. Please try again in 1.692s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 6.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9200, Requested 839. Please try again in 234ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 94%|█████████▍| 1879/2000 [1:15:01<08:41,  4.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1879, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▍| 1880/2000 [1:15:02<06:22,  3.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1880, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▍| 1881/2000 [1:15:03<04:46,  2.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1881, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▍| 1882/2000 [1:15:03<03:48,  1.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1882, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▍| 1883/2000 [1:15:04<02:59,  1.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1883, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▍| 1884/2000 [1:15:05<02:31,  1.31s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9804, Requested 307. Please try again in 666ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1884, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▍| 1885/2000 [1:15:07<03:01,  1.58s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9740, Requested 332. Please try again in 432ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1885, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▍| 1886/2000 [1:15:09<03:04,  1.62s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9779, Requested 369. Please try again in 888ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1886, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9736, Requested 369. Please try again in 630ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 94%|█████████▍| 1887/2000 [1:15:11<03:11,  1.69s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9818, Requested 372. Please try again in 1.14s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1887, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▍| 1888/2000 [1:15:13<03:35,  1.92s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9777, Requested 355. Please try again in 792ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1888, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9741, Requested 355. Please try again in 576ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 94%|█████████▍| 1889/2000 [1:15:15<03:37,  1.96s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9788, Requested 344. Please try again in 792ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1889, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▍| 1890/2000 [1:15:17<03:27,  1.89s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9842, Requested 370. Please try again in 1.272s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1890, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9806, Requested 370. Please try again in 1.056s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 95%|█████████▍| 1891/2000 [1:15:21<04:35,  2.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1891, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▍| 1892/2000 [1:15:21<03:30,  1.95s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9828, Requested 289. Please try again in 702ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1892, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▍| 1893/2000 [1:15:23<03:17,  1.85s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9855, Requested 426. Please try again in 1.686s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1893, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9777, Requested 426. Please try again in 1.218s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 95%|█████████▍| 1894/2000 [1:15:27<04:20,  2.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1894, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▍| 1895/2000 [1:15:28<03:21,  1.92s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9793, Requested 372. Please try again in 990ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1895, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9711, Requested 372. Please try again in 498ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9653, Requested 372. Please try again in 150ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 95%|█████████▍| 1896/2000 [1:15:29<03:19,  1.92s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9833, Requested 313. Please try again in 876ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1896, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▍| 1897/2000 [1:15:32<03:33,  2.07s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9735, Requested 359. Please try again in 564ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1897, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▍| 1898/2000 [1:15:34<03:41,  2.18s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9689, Requested 355. Please try again in 264ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1898, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▍| 1899/2000 [1:15:36<03:20,  1.98s/it]INFO:backoff:Backing off get_labels_batch(...) for 2.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9774, Requested 352. Please try again in 756ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1899, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▌| 1900/2000 [1:15:38<03:36,  2.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1900, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▌| 1901/2000 [1:15:39<02:47,  1.69s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9890, Requested 308. Please try again in 1.188s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1901, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9817, Requested 308. Please try again in 750ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 95%|█████████▌| 1902/2000 [1:15:43<03:40,  2.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1902, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▌| 1903/2000 [1:15:43<02:46,  1.71s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9811, Requested 354. Please try again in 990ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1903, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▌| 1904/2000 [1:15:46<03:09,  1.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1904, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▌| 1905/2000 [1:15:46<02:27,  1.55s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9911, Requested 343. Please try again in 1.524s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1905, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9766, Requested 343. Please try again in 654ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 95%|█████████▌| 1906/2000 [1:15:50<03:33,  2.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1906, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▌| 1907/2000 [1:15:51<02:48,  1.81s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9766, Requested 351. Please try again in 702ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1907, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9660, Requested 351. Please try again in 66ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 95%|█████████▌| 1908/2000 [1:15:54<03:31,  2.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1908, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▌| 1909/2000 [1:15:55<02:43,  1.80s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9763, Requested 409. Please try again in 1.032s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1909, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▌| 1910/2000 [1:15:57<02:40,  1.79s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9867, Requested 272. Please try again in 834ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1910, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9737, Requested 272. Please try again in 54ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 96%|█████████▌| 1911/2000 [1:16:02<04:11,  2.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1911, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▌| 1912/2000 [1:16:03<03:09,  2.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1912, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▌| 1913/2000 [1:16:03<02:32,  1.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1913, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▌| 1914/2000 [1:16:04<02:03,  1.43s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9831, Requested 293. Please try again in 744ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1914, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▌| 1915/2000 [1:16:06<02:07,  1.50s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9854, Requested 540. Please try again in 2.364s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1915, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9728, Requested 540. Please try again in 1.608s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 96%|█████████▌| 1916/2000 [1:16:10<03:11,  2.28s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9674, Requested 383. Please try again in 342ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1916, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▌| 1917/2000 [1:16:12<03:15,  2.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1917, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▌| 1918/2000 [1:16:13<02:27,  1.80s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9896, Requested 427. Please try again in 1.938s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1918, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9617, Requested 427. Please try again in 264ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 96%|█████████▌| 1919/2000 [1:16:16<03:07,  2.31s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9739, Requested 294. Please try again in 198ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1919, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▌| 1920/2000 [1:16:17<02:29,  1.87s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9897, Requested 527. Please try again in 2.544s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1920, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9626, Requested 527. Please try again in 918ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 96%|█████████▌| 1921/2000 [1:16:22<03:46,  2.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1921, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▌| 1922/2000 [1:16:23<02:49,  2.18s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9727, Requested 307. Please try again in 204ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1922, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▌| 1923/2000 [1:16:24<02:28,  1.93s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9807, Requested 281. Please try again in 528ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1923, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9745, Requested 281. Please try again in 156ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 96%|█████████▌| 1924/2000 [1:16:26<02:20,  1.85s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9815, Requested 345. Please try again in 960ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1924, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▋| 1925/2000 [1:16:28<02:20,  1.88s/it]INFO:backoff:Backing off get_labels_batch(...) for 2.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9847, Requested 362. Please try again in 1.254s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1925, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▋| 1926/2000 [1:16:30<02:34,  2.08s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9781, Requested 276. Please try again in 342ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1926, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▋| 1927/2000 [1:16:33<02:32,  2.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1927, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▋| 1928/2000 [1:16:33<01:56,  1.62s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9904, Requested 376. Please try again in 1.68s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1928, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9824, Requested 376. Please try again in 1.2s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 6.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9680, Requested 376. Please try again in 336ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 96%|█████████▋| 1929/2000 [1:16:42<04:20,  3.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1929, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▋| 1930/2000 [1:16:42<03:16,  2.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1930, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 97%|█████████▋| 1931/2000 [1:16:43<02:31,  2.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1931, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 97%|█████████▋| 1932/2000 [1:16:44<01:58,  1.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1932, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 97%|█████████▋| 1933/2000 [1:16:44<01:33,  1.40s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9707, Requested 369. Please try again in 456ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1933, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 97%|█████████▋| 1934/2000 [1:16:46<01:38,  1.49s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9791, Requested 353. Please try again in 864ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1934, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9764, Requested 353. Please try again in 702ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 97%|█████████▋| 1935/2000 [1:16:50<02:29,  2.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1935, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 97%|█████████▋| 1936/2000 [1:16:51<01:55,  1.80s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9655, Requested 918. Please try again in 3.438s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1936, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9634, Requested 918. Please try again in 3.312s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 97%|█████████▋| 1937/2000 [1:16:55<02:42,  2.57s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9754, Requested 473. Please try again in 1.362s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1937, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 97%|█████████▋| 1938/2000 [1:16:58<02:38,  2.55s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9781, Requested 320. Please try again in 606ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1938, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 97%|█████████▋| 1939/2000 [1:17:00<02:25,  2.38s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9761, Requested 292. Please try again in 318ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1939, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 97%|█████████▋| 1940/2000 [1:17:01<02:11,  2.19s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9760, Requested 333. Please try again in 558ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1940, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9690, Requested 333. Please try again in 138ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 97%|█████████▋| 1941/2000 [1:17:06<02:45,  2.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1941, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 97%|█████████▋| 1942/2000 [1:17:06<02:05,  2.17s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9557, Requested 524. Please try again in 486ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1942, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 97%|█████████▋| 1943/2000 [1:17:09<02:03,  2.16s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9700, Requested 363. Please try again in 378ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1943, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9667, Requested 363. Please try again in 180ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 97%|█████████▋| 1944/2000 [1:17:11<01:59,  2.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1944, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 97%|█████████▋| 1945/2000 [1:17:11<01:31,  1.66s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9901, Requested 344. Please try again in 1.47s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1945, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9665, Requested 344. Please try again in 54ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 97%|█████████▋| 1946/2000 [1:17:14<01:41,  1.87s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9843, Requested 414. Please try again in 1.542s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1946, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9600, Requested 414. Please try again in 84ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 97%|█████████▋| 1947/2000 [1:17:16<01:43,  1.95s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9880, Requested 332. Please try again in 1.272s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1947, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 97%|█████████▋| 1948/2000 [1:17:18<01:43,  2.00s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9862, Requested 507. Please try again in 2.214s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1948, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9695, Requested 507. Please try again in 1.212s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 1.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9646, Requested 507. Please try again in 918ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 97%|█████████▋| 1949/2000 [1:17:21<02:01,  2.39s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9782, Requested 452. Please try again in 1.404s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1949, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9661, Requested 452. Please try again in 678ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 98%|█████████▊| 1950/2000 [1:17:26<02:30,  3.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1950, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 1951/2000 [1:17:26<01:51,  2.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1951, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 1952/2000 [1:17:27<01:28,  1.85s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9818, Requested 437. Please try again in 1.53s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1952, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9769, Requested 437. Please try again in 1.236s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 98%|█████████▊| 1953/2000 [1:17:30<01:42,  2.18s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9749, Requested 352. Please try again in 606ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1953, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 1954/2000 [1:17:31<01:28,  1.92s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9875, Requested 438. Please try again in 1.878s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1954, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9724, Requested 438. Please try again in 972ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 7.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9652, Requested 438. Please try again in 540ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 98%|█████████▊| 1955/2000 [1:17:41<03:16,  4.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1955, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 1956/2000 [1:17:42<02:26,  3.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1956, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 1957/2000 [1:17:43<01:46,  2.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1957, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 1958/2000 [1:17:43<01:18,  1.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1958, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 1959/2000 [1:17:44<00:59,  1.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1959, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 1960/2000 [1:17:45<00:52,  1.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1960, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 1961/2000 [1:17:45<00:41,  1.07s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9859, Requested 274. Please try again in 798ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1961, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 1962/2000 [1:17:47<00:49,  1.30s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9826, Requested 310. Please try again in 816ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1962, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 1963/2000 [1:17:49<00:53,  1.45s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9836, Requested 295. Please try again in 786ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1963, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 1964/2000 [1:17:51<01:01,  1.72s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9739, Requested 347. Please try again in 516ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1964, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 1965/2000 [1:17:53<01:01,  1.77s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9771, Requested 277. Please try again in 288ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1965, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 1966/2000 [1:17:55<01:02,  1.83s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9725, Requested 322. Please try again in 282ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1966, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 1967/2000 [1:17:57<01:04,  1.95s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9674, Requested 495. Please try again in 1.013s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1967, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 1968/2000 [1:17:59<01:02,  1.94s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9822, Requested 365. Please try again in 1.122s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1968, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9794, Requested 365. Please try again in 954ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 98%|█████████▊| 1969/2000 [1:18:02<01:08,  2.21s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9705, Requested 433. Please try again in 828ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1969, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 1970/2000 [1:18:04<01:03,  2.11s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9815, Requested 352. Please try again in 1.002s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1970, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 99%|█████████▊| 1971/2000 [1:18:06<01:04,  2.24s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9736, Requested 384. Please try again in 720ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1971, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 99%|█████████▊| 1972/2000 [1:18:08<01:00,  2.18s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9782, Requested 330. Please try again in 672ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1972, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 99%|█████████▊| 1973/2000 [1:18:10<00:52,  1.93s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9883, Requested 337. Please try again in 1.32s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1973, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 99%|█████████▊| 1974/2000 [1:18:13<00:57,  2.20s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9749, Requested 292. Please try again in 246ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1974, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 99%|█████████▉| 1975/2000 [1:18:14<00:50,  2.01s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9783, Requested 291. Please try again in 444ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1975, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 99%|█████████▉| 1976/2000 [1:18:17<00:51,  2.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1976, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 99%|█████████▉| 1977/2000 [1:18:17<00:38,  1.67s/it]INFO:backoff:Backing off get_labels_batch(...) for 1.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9854, Requested 335. Please try again in 1.134s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1977, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 99%|█████████▉| 1978/2000 [1:18:20<00:41,  1.89s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9772, Requested 503. Please try again in 1.65s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1978, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9693, Requested 503. Please try again in 1.176s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 99%|█████████▉| 1979/2000 [1:18:24<00:56,  2.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1979, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 99%|█████████▉| 1980/2000 [1:18:25<00:40,  2.04s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9672, Requested 467. Please try again in 834ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1980, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 3.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9590, Requested 467. Please try again in 342ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 99%|█████████▉| 1981/2000 [1:18:29<00:54,  2.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1981, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 99%|█████████▉| 1982/2000 [1:18:30<00:38,  2.16s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9709, Requested 384. Please try again in 558ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1982, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 99%|█████████▉| 1983/2000 [1:18:32<00:33,  1.99s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9818, Requested 339. Please try again in 941ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1983, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9732, Requested 339. Please try again in 426ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 99%|█████████▉| 1984/2000 [1:18:34<00:34,  2.18s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9721, Requested 348. Please try again in 414ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1984, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 99%|█████████▉| 1985/2000 [1:18:35<00:28,  1.88s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9863, Requested 386. Please try again in 1.494s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1985, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 2.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9701, Requested 386. Please try again in 522ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 99%|█████████▉| 1986/2000 [1:18:40<00:35,  2.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1986, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 99%|█████████▉| 1987/2000 [1:18:40<00:26,  2.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1987, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 99%|█████████▉| 1988/2000 [1:18:41<00:20,  1.69s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9852, Requested 354. Please try again in 1.236s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1988, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9774, Requested 354. Please try again in 768ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            " 99%|█████████▉| 1989/2000 [1:18:44<00:21,  1.94s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9782, Requested 328. Please try again in 660ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1989, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r100%|█████████▉| 1990/2000 [1:18:45<00:18,  1.88s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9826, Requested 553. Please try again in 2.274s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1990, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 1.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9799, Requested 553. Please try again in 2.112s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 7.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9567, Requested 553. Please try again in 720ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "100%|█████████▉| 1991/2000 [1:18:55<00:37,  4.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1991, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r100%|█████████▉| 1992/2000 [1:18:55<00:24,  3.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1992, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r100%|█████████▉| 1993/2000 [1:18:56<00:16,  2.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1993, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r100%|█████████▉| 1994/2000 [1:18:57<00:11,  1.88s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9782, Requested 317. Please try again in 594ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1994, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r100%|█████████▉| 1995/2000 [1:18:58<00:08,  1.76s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9851, Requested 394. Please try again in 1.47s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1995, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9760, Requested 394. Please try again in 924ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 1.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9673, Requested 394. Please try again in 402ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "100%|█████████▉| 1996/2000 [1:19:01<00:08,  2.15s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9726, Requested 460. Please try again in 1.116s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1996, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9686, Requested 460. Please try again in 876ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "INFO:backoff:Backing off get_labels_batch(...) for 3.6s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9644, Requested 460. Please try again in 624ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "100%|█████████▉| 1997/2000 [1:19:06<00:08,  2.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1997, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r100%|█████████▉| 1998/2000 [1:19:07<00:04,  2.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1998, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r100%|█████████▉| 1999/2000 [1:19:08<00:01,  1.84s/it]INFO:backoff:Backing off get_labels_batch(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9719, Requested 482. Please try again in 1.206s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1999, Batch size: 1, Labels returned: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off get_labels_batch(...) for 4.0s (openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-BWZXek8IoyBebWyrPhEhUphD on tokens per min (TPM): Limit 10000, Used 9649, Requested 482. Please try again in 786ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
            "100%|██████████| 2000/2000 [1:19:13<00:00,  2.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 2000, Batch size: 1, Labels returned: 1\n",
            "Total labels: 2000, Expected: 2000\n",
            "              UserId   ProductId  Score  \\\n",
            "0     A1D87F6ZCVE5NK  B00813GRG4      1   \n",
            "1     A395BORC6FGVXV  B000UA0QIQ      2   \n",
            "2      A327PCT23YH90  B0009XLVG0      1   \n",
            "3     A3KLWF6WQ5BNYO  B001GVISJM      2   \n",
            "4     A3RXAU2N8KV45G  B001GVISJM      1   \n",
            "...              ...         ...    ...   \n",
            "1995  A3P5T6X3X1HCPI  B00513J4D0      1   \n",
            "1996  A3QNQQKJTL76H0  B004H4NC4Q      2   \n",
            "1997  A2GINYK25G77M2  B003F8XZSS      1   \n",
            "1998  A1UECUMTG3VWOL  B000AY9U20      2   \n",
            "1999  A3FICOMPE2KFGY  B000AY9U20      1   \n",
            "\n",
            "                                                Summary  \\\n",
            "0                                     Not as Advertised   \n",
            "1                                        Cough Medicine   \n",
            "2                  My Cats Are Not Fans of the New Food   \n",
            "3                                            poor taste   \n",
            "4                                       Nasty No flavor   \n",
            "...                                                 ...   \n",
            "1995                                     Cat Hated It!!   \n",
            "1996                        Not crazy about this flavor   \n",
            "1997              Tastless, weak, not sweet, do not buy   \n",
            "1998                        Great Taste lousy Shipping.   \n",
            "1999  Chocolate Chip Coconut Cookies not so yummy - ...   \n",
            "\n",
            "                                                   Text  \\\n",
            "0     Product arrived labeled as Jumbo Salted Peanut...   \n",
            "1     If you are looking for the secret ingredient i...   \n",
            "2     My cats have been happily eating Felidae Plati...   \n",
            "3     I love eating them and they are good for watch...   \n",
            "4     The candy is just red , No flavor . Just  plan...   \n",
            "...                                                 ...   \n",
            "1995  My cat looked at it, smelled it for a minute o...   \n",
            "1996  I found this at Wholefoods for $2.50 and bough...   \n",
            "1997  I was excited to purchase this tea and found o...   \n",
            "1998  Received product, which I purchased from Amazo...   \n",
            "1999  I finally found my most favorite cookies throu...   \n",
            "\n",
            "                                        lemmatized_text  \\\n",
            "0     product arrive label as jumbo salt peanutsthe ...   \n",
            "1     if you be look for the secret ingredient in ro...   \n",
            "2     my cat have be happily eat felidae platinum fo...   \n",
            "3     I love eat they and they be good for watch tv ...   \n",
            "4     the candy be just red no flavor just plan and ...   \n",
            "...                                                 ...   \n",
            "1995  my cat look at it smell it for a minute or so ...   \n",
            "1996  I find this at wholefood for and buy it mainly...   \n",
            "1997  I be excited to purchase this tea and find out...   \n",
            "1998  receive product which I purchase from amazon n...   \n",
            "1999  I finally find my most favorite cookie through...   \n",
            "\n",
            "                                                 Tokens  Topic Topic_string  \\\n",
            "0     ['product', 'arrive', 'label', 'jumbo', 'salt'...     71       peanut   \n",
            "1     ['look', 'secret', 'ingredient', 'robitussin',...    299         beer   \n",
            "2     ['cat', 'happily', 'eat', 'felidae', 'platinum...      0          cat   \n",
            "3     ['I', 'love', 'eat', 'good', 'watch', 'tv', 'l...     -1           be   \n",
            "4     ['candy', 'red', 'flavor', 'plan', 'chewy', 'I...     15        candy   \n",
            "...                                                 ...    ...          ...   \n",
            "1995  ['cat', 'look', 'smell', 'minute', 'take', 'on...      0          cat   \n",
            "1996  ['I', 'find', 'wholefood', 'buy', 'mainly', 'c...     -1           be   \n",
            "1997  ['I', 'excited', 'purchase', 'tea', 'find', 'g...     -1           be   \n",
            "1998  ['receive', 'product', 'I', 'purchase', 'amazo...      5       cookie   \n",
            "1999  ['I', 'finally', 'find', 'favorite', 'cookie',...      5       cookie   \n",
            "\n",
            "        label  \n",
            "0        size  \n",
            "1       taste  \n",
            "2     quality  \n",
            "3       taste  \n",
            "4       taste  \n",
            "...       ...  \n",
            "1995    taste  \n",
            "1996    taste  \n",
            "1997  quality  \n",
            "1998  quality  \n",
            "1999  quality  \n",
            "\n",
            "[2000 rows x 10 columns]\n",
            "Total time taken: 4753.69 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "<ipython-input-17-eda9d7d5e31b>:65: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['label'] = labels\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import openai\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import backoff\n",
        "import random\n",
        "\n",
        "openai.api_key = \"enter your api\"\n",
        "\n",
        "@backoff.on_exception(backoff.expo, openai.error.RateLimitError, max_tries=10, factor=2)\n",
        "def get_labels_batch(texts):\n",
        "    prompt = (\n",
        "        \"Assign a single-word label from the following list (size, taste, quantity, price, quality, other) to each of the following texts. \"\n",
        "        \"Here are a few examples: \"\n",
        "        'Example1: \"If you are looking for the secret ingredient in Robitussin I believe I have found it. I got this in addition to the Root Beer Extract I ordered (which was good) and made some cherry soda. The flavor is very medicinal.\" Label: taste; '\n",
        "        'Example2: \"This oatmeal is not good. It\\'s mushy, soft, I don\\'t like it. Quaker Oats is the way to go.\" Label: quality; '\n",
        "        'Example3: \"Hey, the description says 360 grams - that is roughly 13 ounces at under $4.00 per can. No way - that is the approximate price for a 100 gram can.\" Label: price; '\n",
        "        'Example4: \"I felt energized within five minutes, but it lasted for about 45 minutes. I paid $3.99 for this drink. I could have just drunk a cup of coffee and saved my money.\" Label: quality; '\n",
        "    )\n",
        "\n",
        "    for i, text in enumerate(texts):\n",
        "        prompt += f'Text {i+1}: \"{text}\" Label: '\n",
        "\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant that labels text.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        max_tokens=10 * len(texts)\n",
        "    )\n",
        "\n",
        "    labels = response.choices[0].message['content'].strip().split('\\n')\n",
        "\n",
        "    # Ensure we have the correct number of labels\n",
        "    if len(labels) != len(texts):\n",
        "        print(f\"Warning: Expected {len(texts)} labels, but got {len(labels)}. Retrying batch.\")\n",
        "        time.sleep(random.uniform(1, 3))  # Add random delay to avoid rate limit\n",
        "        return get_labels_batch(texts)\n",
        "\n",
        "    return [label.split(':')[-1].strip().lower() for label in labels]\n",
        "\n",
        "# Assuming df is already defined and contains the 'lemmatized_text' column\n",
        "# df = pd.read_csv('path_to_your_csv')  # Uncomment and adjust this line if df is not already loaded\n",
        "\n",
        "# Apply the function to each text entry in the DataFrame using batching\n",
        "batch_size = 1  # Reduce batch size to decrease token usage per request\n",
        "texts = df['lemmatized_text'].tolist()\n",
        "labels = []\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "for i in tqdm(range(0, len(texts), batch_size)):\n",
        "    batch_texts = texts[i:i + batch_size]\n",
        "    batch_labels = get_labels_batch(batch_texts)\n",
        "\n",
        "    # Debugging: print the length of batch_labels and check if it matches the batch size\n",
        "    print(f\"Processed batch {i // batch_size + 1}, Batch size: {len(batch_texts)}, Labels returned: {len(batch_labels)}\")\n",
        "\n",
        "    labels.extend(batch_labels)\n",
        "\n",
        "end_time = time.time()\n",
        "total_time = end_time - start_time\n",
        "\n",
        "df['label'] = labels\n",
        "\n",
        "# Debugging: Check the length of the final labels list\n",
        "print(f\"Total labels: {len(labels)}, Expected: {len(texts)}\")\n",
        "\n",
        "# Print the DataFrame with assigned labels\n",
        "print(df)\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "file_path = '/content/drive/My Drive/AI_project/dataset/labeled_reviews2000.csv'\n",
        "df.to_csv(file_path, index=False)\n",
        "\n",
        "print(f\"Total time taken: {total_time:.2f} seconds\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Label data using GPT4**"
      ],
      "metadata": {
        "id": "Qa2SJD4-9goW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install backoff"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXKxAhh73K5X",
        "outputId": "6699e0a7-6ae4-4d01-e97b-dec11aca2fe1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting backoff\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3108, in _dep_map\n",
            "    return self.__dep_map\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 2901, in __getattr__\n",
            "    raise AttributeError(attr)\n",
            "AttributeError: _DistInfoDistribution__dep_map\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 169, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/req_command.py\", line 242, in wrapper\n",
            "    return func(self, options, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/commands/install.py\", line 441, in run\n",
            "    conflicts = self._determine_conflicts(to_install)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/commands/install.py\", line 572, in _determine_conflicts\n",
            "    return check_install_conflicts(to_install)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/check.py\", line 101, in check_install_conflicts\n",
            "    package_set, _ = create_package_set_from_installed()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/check.py\", line 42, in create_package_set_from_installed\n",
            "    dependencies = list(dist.iter_dependencies())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/metadata/pkg_resources.py\", line 216, in iter_dependencies\n",
            "    return self._dist.requires(extras)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 2821, in requires\n",
            "    dm = self._dep_map\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3110, in _dep_map\n",
            "    self.__dep_map = self._compute_dependencies()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3120, in _compute_dependencies\n",
            "    reqs.extend(parse_requirements(req))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3173, in __init__\n",
            "    super(Requirement, self).__init__(requirement_string)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/packaging/requirements.py\", line 102, in __init__\n",
            "    req = REQUIREMENT.parseString(requirement_string)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 1131, in parse_string\n",
            "    loc, tokens = self._parse(instring, 0)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 3886, in parseImpl\n",
            "    loc, exprtokens = e._parse(instring, loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 4114, in parseImpl\n",
            "    return e._parse(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 3886, in parseImpl\n",
            "    loc, exprtokens = e._parse(instring, loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 4959, in parseImpl\n",
            "    loc, tokens = self_expr._parse(instring, loc, doActions, callPreParse=False)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 3886, in parseImpl\n",
            "    loc, exprtokens = e._parse(instring, loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 856, in _parseNoCache\n",
            "    tokens = fn(instring, tokens_start, ret_tokens)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 291, in wrapper\n",
            "    ret = func(*args[limit:])\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/packaging/requirements.py\", line 71, in <lambda>\n",
            "    lambda s, l, t: Marker(s[t._original_start : t._original_end])\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/packaging/markers.py\", line 278, in __init__\n",
            "    self._markers = _coerce_parse_result(MARKER.parseString(marker))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 1131, in parse_string\n",
            "    loc, tokens = self._parse(instring, 0)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 3886, in parseImpl\n",
            "    loc, exprtokens = e._parse(instring, loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 5226, in parseImpl\n",
            "    return super().parseImpl(instring, loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 4375, in parseImpl\n",
            "    return self.expr._parse(instring, loc, doActions, callPreParse=False)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 3864, in parseImpl\n",
            "    loc, resultlist = self.exprs[0]._parse(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 4114, in parseImpl\n",
            "    return e._parse(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 4375, in parseImpl\n",
            "    return self.expr._parse(instring, loc, doActions, callPreParse=False)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 3886, in parseImpl\n",
            "    loc, exprtokens = e._parse(instring, loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 5226, in parseImpl\n",
            "    return super().parseImpl(instring, loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 4375, in parseImpl\n",
            "    return self.expr._parse(instring, loc, doActions, callPreParse=False)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 3864, in parseImpl\n",
            "    loc, resultlist = self.exprs[0]._parse(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 4114, in parseImpl\n",
            "    return e._parse(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 4375, in parseImpl\n",
            "    return self.expr._parse(instring, loc, doActions, callPreParse=False)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 3864, in parseImpl\n",
            "    loc, resultlist = self.exprs[0]._parse(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 4114, in parseImpl\n",
            "    return e._parse(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 4114, in parseImpl\n",
            "    return e._parse(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 825, in _parseNoCache\n",
            "    ret_tokens = ParseResults(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/results.py\", line 136, in __new__\n",
            "    def __new__(cls, toklist=None, name=None, **kwargs):\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/main.py\", line 79, in main\n",
            "    return command.main(cmd_args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 101, in main\n",
            "    return self._main(args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 223, in _main\n",
            "    return run(options, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 206, in exc_logging_wrapper\n",
            "    logger.critical(\"Operation cancelled by user\")\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1524, in critical\n",
            "    self._log(CRITICAL, msg, args, **kwargs)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1624, in _log\n",
            "    self.handle(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1634, in handle\n",
            "    self.callHandlers(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1696, in callHandlers\n",
            "    hdlr.handle(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 968, in handle\n",
            "    self.emit(record)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/utils/logging.py\", line 172, in emit\n",
            "    style = Style(color=\"red\")\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import openai\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import backoff\n",
        "\n",
        "openai.api_key = \"enter your api\"\n",
        "\n",
        "@backoff.on_exception(backoff.expo, openai.error.RateLimitError, max_tries=10)\n",
        "def get_labels_batch(texts):\n",
        "    prompt = (\n",
        "        \"Assign a single-word label from the following list (size, taste, quantity, price, quality, other) to each of the following texts. \"\n",
        "        \"Here are a few examples: \"\n",
        "        'Example1: \"If you are looking for the secret ingredient in Robitussin I believe I have found it. I got this in addition to the Root Beer Extract I ordered (which was good) and made some cherry soda. The flavor is very medicinal.\" Label: taste; '\n",
        "        'Example2: \"This oatmeal is not good. It\\'s mushy, soft, I don\\'t like it. Quaker Oats is the way to go.\" Label: quality; '\n",
        "        'Example3: \"Hey, the description says 360 grams - that is roughly 13 ounces at under $4.00 per can. No way - that is the approximate price for a 100 gram can.\" Label: price; '\n",
        "        'Example4: \"I felt energized within five minutes, but it lasted for about 45 minutes. I paid $3.99 for this drink. I could have just drunk a cup of coffee and saved my money.\" Label: quality; '\n",
        "    )\n",
        "\n",
        "    for i, text in enumerate(texts):\n",
        "        prompt += f'Text {i+1}: \"{text}\" Label: '\n",
        "\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant that labels text.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        max_tokens=10 * len(texts)\n",
        "    )\n",
        "\n",
        "    labels = response.choices[0].message['content'].strip().split('\\n')\n",
        "    return [label.split(':')[-1].strip().lower() for label in labels]\n",
        "\n",
        "# Assuming df is already defined and contains the 'lemmatized_text' column\n",
        "# df = pd.read_csv('path_to_your_csv')  # Uncomment and adjust this line if df is not already loaded\n",
        "\n",
        "# Apply the function to each text entry in the DataFrame using batching\n",
        "batch_size = 10\n",
        "texts = df['lemmatized_text'].tolist()\n",
        "labels = []\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "for i in tqdm(range(0, len(texts), batch_size)):\n",
        "    batch_texts = texts[i:i + batch_size]\n",
        "    batch_labels = get_labels_batch(batch_texts)\n",
        "    labels.extend(batch_labels)\n",
        "\n",
        "end_time = time.time()\n",
        "total_time = end_time - start_time\n",
        "\n",
        "df['label'] = labels\n",
        "\n",
        "# Print the DataFrame with assigned labels\n",
        "print(df)\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "file_path = '/content/drive/My Drive/AI_project/dataset/labeled_reviews2000.csv'\n",
        "df.to_csv(file_path, index=False)\n",
        "\n",
        "print(f\"Total time taken: {total_time:.2f} seconds\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "48vKgseFzRce",
        "outputId": "98ca558a-867a-48a7-c2da-de543d483b33"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'openai'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-24b3f9b097ea>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mopenai\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackoff\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'openai'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(labels)"
      ],
      "metadata": {
        "id": "nA0YXAD9EEg9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install openai==0.28"
      ],
      "metadata": {
        "id": "NB8dfCFyNXVb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/drive/My Drive/AI_project/dataset/labeled_reviews2.csv'\n",
        "df2 = pd.read_csv(file_path, engine='python')\n",
        "print(df2)"
      ],
      "metadata": {
        "id": "7_t2NcwfSpaN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode labels (0 for negative, 1 for positive)\n",
        "df['label'] = df['label'].str.lower()\n",
        "label_dict = {\"other\": 0, \"size\": 1, \"taste\": 2, \"quantity\": 3, \"quality\": 4, \"price\": 5}\n",
        "df['label_numerical'] = df['label'].map(label_dict)\n",
        "print(df[\"label\"].unique())"
      ],
      "metadata": {
        "id": "M0l3_wGG80SX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get summary statistics for numeric columns\n",
        "df[\"ProductId\"].nunique()\n"
      ],
      "metadata": {
        "id": "MKIcm6UO4TTb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **BertCLassifier**"
      ],
      "metadata": {
        "id": "KgLLKa-Ly7TP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#Load data\n",
        "# Path to your CSV file\n",
        "file_path = '/content/drive/My Drive/AI_project/dataset/labeled_reviews2000.csv'\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(file_path, engine='python')\n",
        "\n",
        "# Example DataFrame\n",
        "#df = df.head(500)\n",
        "#df = clean_df.head(1000)\n",
        "\n",
        "\n",
        "# Step 1: Print unique values of the 'category' column\n",
        "unique_values = df['label'].unique()\n",
        "print(\"Unique values (original):\", unique_values)\n",
        "\n",
        "# Step 2: Convert them to lowercase\n",
        "unique_values_lower = [value.lower() for value in unique_values]\n",
        "print(\"Unique values (lowercase):\", unique_values_lower)\n"
      ],
      "metadata": {
        "id": "mmPn63Ka1t3Y",
        "outputId": "b0465065-8b31-4e94-f332-7744ab4ae0af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Unique values (original): ['size' 'taste' 'quality' 'other' 'price' 'quantity']\n",
            "Unique values (lowercase): ['size', 'taste', 'quality', 'other', 'price', 'quantity']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode labels\n",
        "df['label']  = df['label'] .apply(clean_text)\n",
        "df['label'] = df['label'].str.lower()\n",
        "label_dict = {\"other\": 0, \"size\": 1, \"taste\": 2, \"quantity\": 3, \"quality\": 4, \"price\": 5}\n",
        "df['label_numerical'] = df['label'].map(label_dict)\n",
        "print(df[\"label\"].unique())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPOSjb5cgHNd",
        "outputId": "e300d554-708b-423e-8bb5-ecdad72e17d6",
        "collapsed": true
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['size' 'taste' 'quality' 'other' 'price' 'quantity']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df[\"label_numerical\"].unique())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G7i-qivrotrz",
        "outputId": "74f0bcd2-af12-4b62-de2a-b463f924dedd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 2 4 0 5 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Train the whole model**"
      ],
      "metadata": {
        "id": "-7UXmd1j7_Jx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "170aCV2eBypA",
        "outputId": "2ad8d049-aad2-4dd8-d604-6a0b5ea646ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697,
          "referenced_widgets": [
            "11fcd5eb3a164d8398e8b5cd689152f0",
            "a8a8b7c789b74a41a8d39f83421a31c5",
            "3bb6f019591549cfa50e361fd62f2017",
            "aab5373c0fc4462ab509cfecc493f93c",
            "5a0369bbb7764d1795843ce3050a4727",
            "98448f8d03494b44a3f01ce4418408c3",
            "cf1122f71ea4460896d1e09d890a66bf",
            "c50728bd76764232b0fc3413f1076635",
            "6ee6fa3f7c364f80b06aa825bbfa00a6",
            "c263ca7759284c68a90678dc0d350fae",
            "35b39dfbbb7e4164bd17c457079f02e9",
            "00fd311ce31d41dfae0b4fa0242425dd",
            "f1c8500613934a3dbbbad2811ca307b7",
            "fce807fad99a4e8789b68639d813a476",
            "1f7560833d314ee4872c3d621f464f3e",
            "5cde719b74d04ca5b28aecc8a8c7b3d8",
            "5476fbd21e6f430ea241e6a689f28071",
            "482f74db1e27450c9f4a1bc305c429bd",
            "500203697f644b19ab3479f86b4adbc2",
            "b92bb4853b814a44ae886bc83d48f830",
            "5f60b5c2649940c4849356ba3e549ae4",
            "e4b31b75c90745e6a4e45ff2bfbddd1c",
            "6d29348bf06645caaebacd0a6988aad9",
            "3a6a2587957d41fc81efc0b837aae68c",
            "f4a01f27634b4ecca416a7bdf64f84ce",
            "95f2e7e6821c42c2a0a49aad175a5c40",
            "fabad275643a4fdba74051f38945d96b",
            "1df0cfb7cbdd4d3296942e1f68594286",
            "74dffccac0cc4d3a8a15f0b458438986",
            "e7723362f60e40c9a8ab81d076f9c9d9",
            "11b6a95aa5de4960b3e30825b321bd2f",
            "80bebc4f0a4d4801aaaaf65ecc579dad",
            "53d7e28507554d7badcb4f9dffe240ea",
            "6154eb9739674748962fc8f348fc4b1a",
            "0ef6b06574db44fa84c37758458bb241",
            "33b46c7e03bf4fdcb2dd8c758ca860ae",
            "d73b16f6164048dca85665551beae33e",
            "ff07e102ae6e471dbe6d923d36d0db60",
            "cc8c4ff3c52b4c38885f5532c14e59e7",
            "4513cc60ac4a4b8f97eb6296e8306ea3",
            "56286267b48840f2977ef1313679eb62",
            "487462ff3de54c829ffbc480d76d1f2d",
            "2d86cef952dc41d0ba18f14b904149ed",
            "765c5ca1651f4dfb90f2a88d09fd4e83",
            "5efee83e7fbf498ba8989a53e1c3196d",
            "f1e1fb16d78f4beab82a8ea8d599b8c8",
            "cfe430ddd65c45a09dc11053f21547bd",
            "e7d2807e4c224312b9e0e54bec8b5e85",
            "6ab45337868b4e24ac3872aa0e01f720",
            "4fb7ee4efa644dcf81897ae9519833d5",
            "4a8367e13bdb4575b7bac8b14fe9d346",
            "161f3317ff974e99951ab24f38a3eb7f",
            "dcdfb973d6cf4540b514566ea0d53b56",
            "f356c26b2dec4b829e07c9b2b33ccf85",
            "30d7c7f9ab314f5b9af6a1b3b76d24d7"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "11fcd5eb3a164d8398e8b5cd689152f0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "00fd311ce31d41dfae0b4fa0242425dd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6d29348bf06645caaebacd0a6988aad9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6154eb9739674748962fc8f348fc4b1a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5efee83e7fbf498ba8989a53e1c3196d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4, Training Loss: 1.0301, Validation Loss: 0.9577\n",
            "Epoch 2/4, Training Loss: 0.6337, Validation Loss: 0.7049\n",
            "Epoch 3/4, Training Loss: 0.3498, Validation Loss: 0.6352\n",
            "Epoch 4/4, Training Loss: 0.1770, Validation Loss: 0.6305\n",
            "Accuracy: 0.8100\n",
            "Precision: 0.8149\n",
            "Recall: 0.8100\n",
            "F1 Score: 0.8051\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.52      0.58        21\n",
            "           1       0.75      0.75      0.75         8\n",
            "           2       0.83      0.91      0.87       139\n",
            "           3       0.80      0.29      0.42        14\n",
            "           4       0.85      0.80      0.83       189\n",
            "           5       0.62      0.90      0.73        29\n",
            "\n",
            "    accuracy                           0.81       400\n",
            "   macro avg       0.75      0.69      0.70       400\n",
            "weighted avg       0.81      0.81      0.81       400\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "\n",
        "# Encode labels (0 for negative, 1 for positive)\n",
        "\"\"\"df['label'] = df['label'].str.lower()\n",
        "label_dict = {\"other\": 0, \"size\": 1, \"taste\": 2, \"quantity\": 3, \"quality\": 4, \"price\": 5}\n",
        "df['label_numerical'] = df['label'].map(label_dict)\n",
        "print(df[\"label_numerical\"])\"\"\"\n",
        "\n",
        "# Custom dataset class\n",
        "class FeedbackDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_len):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            return_token_type_ids=False,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt',\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'label_numerical': torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "# Initialize the tokenizer\n",
        "#tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased')\n",
        "#tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
        "#tokenizer = BertTokenizer.from_pretrained('bert-large-cased')\n",
        "\n",
        "# Initialize the model\n",
        "#model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=6)\n",
        "model = BertForSequenceClassification.from_pretrained('bert-large-uncased', num_labels=6)\n",
        "#model = BertForSequenceClassification.from_pretrained('bert-base-cased', num_labels=6)\n",
        "#model = BertForSequenceClassification.from_pretrained('bert-large-cased', num_labels=6)\n",
        "\n",
        "# Create dataset\n",
        "texts = df['lemmatized_text'].tolist()\n",
        "#texts = df['Text'].tolist()\n",
        "labels = df['label_numerical'].tolist()\n",
        "\n",
        "# Split dataset into train and eval (using 80-20 split)\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(texts, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create custom dataset instances\n",
        "train_dataset = FeedbackDataset(texts=train_texts, labels=train_labels, tokenizer=tokenizer, max_len=128)\n",
        "val_dataset = FeedbackDataset(texts=val_texts, labels=val_labels, tokenizer=tokenizer, max_len=128)\n",
        "\n",
        "# Custom collate function for padding\n",
        "def custom_collate_fn(batch):\n",
        "    input_ids = [item['input_ids'] for item in batch]\n",
        "    attention_mask = [item['attention_mask'] for item in batch]\n",
        "    labels = [item['label_numerical'] for item in batch]\n",
        "\n",
        "    input_ids = pad_sequence(input_ids, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
        "    attention_mask = pad_sequence(attention_mask, batch_first=True, padding_value=0)\n",
        "    labels = torch.stack(labels)\n",
        "\n",
        "    return {\n",
        "        'input_ids': input_ids,\n",
        "        'attention_mask': attention_mask,\n",
        "        'label_numerical': labels\n",
        "    }\n",
        "#The DataLoader is a PyTorch class that provides an iterable over a dataset, handling the batching, shuffling, and loading of data.\n",
        "# Create DataLoaders with custom collate function\n",
        "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=custom_collate_fn)\n",
        "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, collate_fn=custom_collate_fn)\n",
        "\n",
        "\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "model.to(device)\n",
        "\n",
        "# Optimizer\n",
        "optimizer = AdamW(model.parameters(), lr=0.00001)\n",
        "\n",
        "# Training function\n",
        "def train_epoch(model, data_loader, optimizer, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch in data_loader:\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['label_numerical'].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        total_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    return total_loss / len(data_loader)\n",
        "\n",
        "# Early stopping class\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=3, min_delta=0):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.counter = 0\n",
        "        self.best_loss = None\n",
        "        self.early_stop = False\n",
        "\n",
        "    def __call__(self, val_loss):\n",
        "        if self.best_loss is None:\n",
        "            self.best_loss = val_loss\n",
        "        elif val_loss > self.best_loss - self.min_delta:\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_loss = val_loss\n",
        "            self.counter = 0\n",
        "\n",
        "# Evaluation function\n",
        "def eval_model(model, data_loader, device):\n",
        "    model.eval()\n",
        "    predictions, true_labels = [], []\n",
        "    total_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in data_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['label_numerical'].to(device)\n",
        "\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "            total_loss += loss.item()\n",
        "            logits = outputs.logits\n",
        "            preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
        "            predictions.extend(preds)\n",
        "            true_labels.extend(labels.cpu().numpy())\n",
        "    return predictions, true_labels, total_loss / len(data_loader)\n",
        "\n",
        "# Training and evaluation loop\n",
        "num_epochs = 4\n",
        "early_stopping = EarlyStopping(patience=3, min_delta=0.001)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss = train_epoch(model, train_loader, optimizer, device)\n",
        "    predictions, true_labels, val_loss = eval_model(model, val_loader, device)\n",
        "\n",
        "    print(f'Epoch {epoch + 1}/{num_epochs}, Training Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}')\n",
        "\n",
        "    early_stopping(val_loss)\n",
        "    if early_stopping.early_stop:\n",
        "        print(\"Early stopping\")\n",
        "        break\n",
        "\n",
        "# After training your model, save the model and tokenizer\n",
        "model.save_pretrained('/content/drive/My Drive/AI_project/models/bert_large_uncased_2000')\n",
        "tokenizer.save_pretrained('/content/drive/My Drive/AI_project/models/tokenizer_large_uncased_2000')\n",
        "\n",
        "# Evaluate the model\n",
        "predictions, true_labels, tl = eval_model(model, val_loader, device)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy = accuracy_score(true_labels, predictions)\n",
        "precision = precision_score(true_labels, predictions, average='weighted', pos_label=1)\n",
        "recall = recall_score(true_labels, predictions, average='weighted', pos_label=1)\n",
        "f1 = f1_score(true_labels, predictions, average='weighted', pos_label=1)\n",
        "class_report = classification_report(true_labels, predictions)\n",
        "\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "print('Classification Report:')\n",
        "print(class_report)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Train the 2 last layers**"
      ],
      "metadata": {
        "id": "GGQX7hu88hqX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "# Custom dataset class\n",
        "class FeedbackDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_len):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            return_token_type_ids=False,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt',\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'label_numerical': torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "# Initialize the tokenizer\n",
        "#tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased')\n",
        "#tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
        "#tokenizer = BertTokenizer.from_pretrained('bert-large-cased')\n",
        "\n",
        "# Initialize the model\n",
        "#model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=6)\n",
        "model = BertForSequenceClassification.from_pretrained('bert-large-uncased', num_labels=6)\n",
        "#model = BertForSequenceClassification.from_pretrained('bert-base-cased', num_labels=6)\n",
        "#model = BertForSequenceClassification.from_pretrained('bert-large-cased', num_labels=6)\n",
        "\n",
        "# Freeze all layers except the last two\n",
        "for name, param in model.named_parameters():\n",
        "    if 'encoder.layer' in name and name.split('.')[2].isdigit():\n",
        "        layer_num = int(name.split('.')[2])\n",
        "        if layer_num < 22:  # Assuming BERT large has 24 layers\n",
        "            param.requires_grad = False\n",
        "\n",
        "# Create dataset\n",
        "texts = df['Text'].tolist()\n",
        "labels = df['label_numerical'].tolist()\n",
        "\n",
        "# Split dataset into train and eval (using 80-20 split)\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(texts, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create custom dataset instances\n",
        "train_dataset = FeedbackDataset(texts=train_texts, labels=train_labels, tokenizer=tokenizer, max_len=128)\n",
        "val_dataset = FeedbackDataset(texts=val_texts, labels=val_labels, tokenizer=tokenizer, max_len=128)\n",
        "\n",
        "# Custom collate function for padding\n",
        "def custom_collate_fn(batch):\n",
        "    input_ids = [item['input_ids'] for item in batch]\n",
        "    attention_mask = [item['attention_mask'] for item in batch]\n",
        "    labels = [item['label_numerical'] for item in batch]\n",
        "\n",
        "    input_ids = pad_sequence(input_ids, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
        "    attention_mask = pad_sequence(attention_mask, batch_first=True, padding_value=0)\n",
        "    labels = torch.stack(labels)\n",
        "\n",
        "    return {\n",
        "        'input_ids': input_ids,\n",
        "        'attention_mask': attention_mask,\n",
        "        'label_numerical': labels\n",
        "    }\n",
        "\n",
        "# Create DataLoaders with custom collate function\n",
        "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=custom_collate_fn)\n",
        "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, collate_fn=custom_collate_fn)\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "model.to(device)\n",
        "\n",
        "# Optimizer\n",
        "optimizer = AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=0.00001)\n",
        "\n",
        "# Training function\n",
        "def train_epoch(model, data_loader, optimizer, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch in data_loader:\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['label_numerical'].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        total_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    return total_loss / len(data_loader)\n",
        "\n",
        "# Early stopping class\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=3, min_delta=0):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.counter = 0\n",
        "        self.best_loss = None\n",
        "        self.early_stop = False\n",
        "\n",
        "    def __call__(self, val_loss):\n",
        "        if self.best_loss is None:\n",
        "            self.best_loss = val_loss\n",
        "        elif val_loss > self.best_loss - self.min_delta:\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_loss = val_loss\n",
        "            self.counter = 0\n",
        "\n",
        "# Evaluation function\n",
        "def eval_model(model, data_loader, device):\n",
        "    model.eval()\n",
        "    predictions, true_labels = [], []\n",
        "    total_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in data_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['label_numerical'].to(device)\n",
        "\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "            total_loss += loss.item()\n",
        "            logits = outputs.logits\n",
        "            preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
        "            predictions.extend(preds)\n",
        "            true_labels.extend(labels.cpu().numpy())\n",
        "    return predictions, true_labels, total_loss / len(data_loader)\n",
        "\n",
        "# Training and evaluation loop\n",
        "num_epochs = 20\n",
        "early_stopping = EarlyStopping(patience=3, min_delta=0.001)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss = train_epoch(model, train_loader, optimizer, device)\n",
        "    predictions, true_labels, val_loss = eval_model(model, val_loader, device)\n",
        "\n",
        "    print(f'Epoch {epoch + 1}/{num_epochs}, Training Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}')\n",
        "\n",
        "    early_stopping(val_loss)\n",
        "    if early_stopping.early_stop:\n",
        "        print(\"Early stopping\")\n",
        "        break\n",
        "\n",
        "# After training your model, save the model and tokenizer\n",
        "model.save_pretrained('/content/drive/My Drive/AI_project/models/bert_large_uncased_2layer_500')\n",
        "tokenizer.save_pretrained('/content/drive/My Drive/AI_project/models/tokenizer_large_cased_2layer_500')\n",
        "\n",
        "# Evaluate the model\n",
        "predictions, true_labels, tl = eval_model(model, val_loader, device)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy = accuracy_score(true_labels, predictions)\n",
        "precision = precision_score(true_labels, predictions, average='weighted', pos_label=1)\n",
        "recall = recall_score(true_labels, predictions, average='weighted', pos_label=1)\n",
        "f1 = f1_score(true_labels, predictions, average='weighted', pos_label=1)\n",
        "class_report = classification_report(true_labels, predictions)\n",
        "\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "print('Classification Report:')\n",
        "print(class_report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 858,
          "referenced_widgets": [
            "2216b99bbf6f43689a444ed8365a7828",
            "ab09dde0d4fa46ad9dbe5fac8156a97c",
            "d00a485fa5894e178fb784e4181b8adf",
            "efb9fd467dd04298b6cf0786d790600e",
            "c9738764a7bb492c8aa893f9d145bd3a",
            "813daa86bad94254a5fd72b67ea53e1f",
            "6382122cf3fe4d8495770d63e5e83d23",
            "79f0a99cee0e4afa8ac5bdb5d22e444b",
            "cf3a2075c64a4ccfa4c2abd6ebe75c60",
            "401e4bf5816a4e22a7a01af92e58d367",
            "ade50622339143e2beb6c976f8a8e5cf",
            "9cb2372a06b54df18af74108572c412c",
            "f3661b9b87ec4c57b5842608bb588e0a",
            "d9f0e3a4ac6e4116a71a2da490af2798",
            "91661b4586d242ce9274731c81bc3e68",
            "624f361203b3445a88d7f61600b9f94b",
            "b47b6228b3e84b3d819ee941fa37fb63",
            "cfe428c12adc4a46b4b712e36ebb3347",
            "1f9bc17b491c408ab969499f309de11d",
            "24b8ae1771a0402d9d5826250053b7d0",
            "81fda0ba2e724baeb91506881d7aedf4",
            "fdeb6b5811b74c98b507aac363ac8a48",
            "a9590a7961a94518a35eb56317a65fad",
            "d73a0c8f096b425989ead4fbd4f79e3e",
            "200ffb06266247d4bb010a69f6e22cc1",
            "946eb9f1a177417187a9e83152b3dc63",
            "401a7972c9a44838b78d6cd4c54f696a",
            "4d6df94a64a844a78ad271fc2d92ddf9",
            "9a9e8246cbef4584a0f40af4276b70bc",
            "74e4685a3ea743ffb0fbfa8f81c118e2",
            "b94f5dc6f0fb47e0a77c5a2994b3c0d4",
            "914f7bcd6fa6473a9b656c4af92f5d17",
            "449c8cd468c544308b6d7b7efa8e6220",
            "dbdabe547d4e47f5b446015c5368fe6e",
            "e8d8acced74d40cca6913077bb7dc701",
            "8c03caaf6aa240069ed85ad842576e08",
            "250fcd9181c54a66a163edb43e63ed4d",
            "2ed14f68a18540f78e8ee3b972d92ecf",
            "75131d08e7474c7fae77f388a580e62e",
            "f17a6a71d5214fd8b492424313a8af9e",
            "be7bed1fde8d4702acbf4d40e298ac90",
            "42d73cea32b84637b3165f3c94e0cead",
            "3ad9e09693764941b40d23e1f02f6a32",
            "b17b7986ec9f4313876104cc5122c2bf",
            "1c0c222658f448b78e268a9426a93c49",
            "c92fff3cd44f410bb4e7a54368a96d34",
            "c1030ad924d04666aa9cf9cbf940e7bc",
            "cc9e1d495cb44b27b3ce2506b80626d0",
            "70ee65d8dcf24da49e56e7aa2fa190f0",
            "150446e344764082a3bd511d0b77662f",
            "78768c77f073478ca3d5befcb4d4ec90",
            "a8126da8ac214474a699e70f54d1a9dc",
            "74ea9099471d4d6a8dd02015865a5de6",
            "bc843da3e09d4d0ba8ff05378b33ab24",
            "6e490a9989d4433984938a552071b802"
          ]
        },
        "id": "nrlOWqym4VsH",
        "outputId": "f9bf3da3-6490-44b1-83a3-bb99a88273ca"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2216b99bbf6f43689a444ed8365a7828"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9cb2372a06b54df18af74108572c412c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a9590a7961a94518a35eb56317a65fad"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dbdabe547d4e47f5b446015c5368fe6e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1c0c222658f448b78e268a9426a93c49"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20, Training Loss: 1.1339, Validation Loss: 1.0039\n",
            "Epoch 2/20, Training Loss: 0.7929, Validation Loss: 0.7249\n",
            "Epoch 3/20, Training Loss: 0.5245, Validation Loss: 0.6229\n",
            "Epoch 4/20, Training Loss: 0.3140, Validation Loss: 0.7247\n",
            "Epoch 5/20, Training Loss: 0.2023, Validation Loss: 0.9372\n",
            "Epoch 6/20, Training Loss: 0.1245, Validation Loss: 0.7386\n",
            "Early stopping\n",
            "Accuracy: 0.7825\n",
            "Precision: 0.7847\n",
            "Recall: 0.7825\n",
            "F1 Score: 0.7816\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.52      0.51        21\n",
            "           1       1.00      0.50      0.67         8\n",
            "           2       0.83      0.83      0.83       139\n",
            "           3       0.38      0.36      0.37        14\n",
            "           4       0.79      0.82      0.81       189\n",
            "           5       0.85      0.76      0.80        29\n",
            "\n",
            "    accuracy                           0.78       400\n",
            "   macro avg       0.73      0.63      0.66       400\n",
            "weighted avg       0.78      0.78      0.78       400\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Load data and model to eval**"
      ],
      "metadata": {
        "id": "q40WgXeKjegq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import pickle\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "\n",
        "# Define the custom dataset class\n",
        "class FeedbackDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_len=512):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            return_token_type_ids=False,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt',\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'label_numerical': torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "# Load the dataset\n",
        "with open('/content/drive/My Drive/AI_project/dataset/val_data.pkl', 'rb') as f:\n",
        "    data, labels = pickle.load(f)\n",
        "\n",
        "# Custom collate function for padding\n",
        "def custom_collate_fn(batch):\n",
        "    input_ids = [item['input_ids'] for item in batch]\n",
        "    attention_mask = [item['attention_mask'] for item in batch]\n",
        "    labels = [item['label_numerical'] for item in batch]\n",
        "\n",
        "    input_ids = pad_sequence(input_ids, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
        "    attention_mask = pad_sequence(attention_mask, batch_first=True, padding_value=0)\n",
        "    labels = torch.stack(labels)\n",
        "\n",
        "    return {\n",
        "        'input_ids': input_ids,\n",
        "        'attention_mask': attention_mask,\n",
        "        'label_numerical': labels\n",
        "    }\n",
        "\n",
        "# Load the tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('/content/drive/My Drive/AI_project/models/tokenizer_model6')\n",
        "\n",
        "# Load the model\n",
        "model = BertForSequenceClassification.from_pretrained('/content/drive/My Drive/AI_project/models/bert_label_model6')\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "model.to(device)\n",
        "\n",
        "# Create the validation dataset and DataLoader\n",
        "val_dataset = FeedbackDataset(data, labels, tokenizer=tokenizer, max_len=128)\n",
        "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, collate_fn=custom_collate_fn)\n",
        "\n",
        "# Define the evaluation function\n",
        "def eval_model(model, data_loader, device):\n",
        "    model.eval()\n",
        "    predictions, true_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in data_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['label_numerical'].to(device)\n",
        "\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            logits = outputs.logits\n",
        "            preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
        "            predictions.extend(preds)\n",
        "            true_labels.extend(labels.cpu().numpy())\n",
        "    return predictions, true_labels\n",
        "\n",
        "# Evaluate the model\n",
        "predictions, true_labels = eval_model(model, val_loader, device)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy = accuracy_score(true_labels, predictions)\n",
        "precision = precision_score(true_labels, predictions, average='weighted', pos_label=1)\n",
        "recall = recall_score(true_labels, predictions, average='weighted', pos_label=1)\n",
        "f1 = f1_score(true_labels, predictions, average='weighted', pos_label=1)\n",
        "class_report = classification_report(true_labels, predictions)\n",
        "\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "print('Classification Report:')\n",
        "print(class_report)\n"
      ],
      "metadata": {
        "id": "O6g4ec3HzwQg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Test GPT2 to generate product suggestion**\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "toLb0wv-_pF7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "#file_path = '/content/drive/My Drive/AI_project/dataset/labeled_reviews_example_gpt4.csv'\n",
        "file_path = '/content/drive/My Drive/AI_project/dataset/labeled_reviews2000.csv'\n",
        "df = pd.read_csv(file_path, engine='python')\n",
        "import torch\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "\n",
        "# Ensure you have GPU support if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "import torch\n",
        "import pandas as pd\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer, DataCollatorForLanguageModeling, Trainer, TrainingArguments\n",
        "\n",
        "# Ensure you have GPU support if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load the pre-trained GPT-2 model and tokenizer\n",
        "#model_name = \"gpt2\"\n",
        "#model_name = \"gpt2-large\"\n",
        "model_name = \"gpt2-xl\"\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name).to(device)\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Move model to the appropriate device (GPU or CPU)\n",
        "model.to(device)\n",
        "\"\"\"# Assuming you have a DataFrame with 'lemmatized_text' and 'label' columns\n",
        "data = {\n",
        "    'lemmatized_text': [\n",
        "        \"If you are looking for the secret ingredient in Robitussin I believe I have found it. I got this in addition to the Root Beer Extract I ordered (which was good) and made some cherry soda. The flavor is very medicinal.\",\n",
        "        \"This oatmeal is not good. It's mushy, soft, I don't like it. Quaker Oats is the way to go.\",\n",
        "        \"Hey, the description says 360 grams - that is roughly 13 ounces at under $4.00 per can. No way - that is the approximate price for a 100 gram can.\"\n",
        "    ],\n",
        "    'label': ['taste', 'quality', 'price']\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\"\"\"\n",
        "\n",
        "# Example Data Collator and Dataset (replace with actual paths and variables)\n",
        "# Here we skip the fine-tuning part for simplicity\n",
        "# Fine-tuning should be done similarly to the previous code snippet if needed\n",
        "\n",
        "def generate_improvement_suggestion(feedback, category, max_input_length=512, max_new_tokens=50):\n",
        "    examples = [\n",
        "        {\n",
        "            \"feedback\": \"If you are looking for the secret ingredient in Robitussin I believe I have found it. I got this in addition to the Root Beer Extract I ordered (which was good) and made some cherry soda. The flavor is very medicinal.\",\n",
        "            \"category\": \"taste\",\n",
        "            \"suggestion\": \"Improve the taste of the soda by using natural ingredients.\"\n",
        "        },\n",
        "        {\n",
        "            \"feedback\": \"This oatmeal is not good. It's mushy, soft, I don't like it. Quaker Oats is the way to go.\",\n",
        "            \"category\": \"quality\",\n",
        "            \"suggestion\": \"Use high-quality whole grain oats that maintain a good texture when cooked.\"\n",
        "        },\n",
        "        {\n",
        "            \"feedback\": \"Hey, the description says 360 grams - that is roughly 13 ounces at under $4.00 per can. No way - that is the approximate price for a 100 gram can.\",\n",
        "            \"category\": \"price\",\n",
        "            \"suggestion\": \"Increase the product quantity or reduce the price to provide better value.\"\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    # Construct the prompt with examples\n",
        "    prompt = \"Here are some suggestions for improving the product quality based on negative customer feedback. Each suggestion should be one sentence and specific to the feedback category:\\n\\n\"\n",
        "    for example in examples:\n",
        "        prompt += f\"Feedback: \\\"{example['feedback']}\\\"\\nCategory: {example['category']}\\nSuggestion: {example['suggestion']}\\n\\n\"\n",
        "\n",
        "    # Add the new feedback and category\n",
        "    prompt += f\"Feedback: \\\"{feedback}\\\"\\nCategory: {category}\\nSuggestion:\"\n",
        "\n",
        "    # Encode the input prompt\n",
        "    inputs = tokenizer.encode(prompt, return_tensors='pt', truncation=True, max_length=max_input_length).to(device)\n",
        "\n",
        "    # Generate text\n",
        "    outputs = model.generate(\n",
        "        inputs,\n",
        "        max_new_tokens=max_new_tokens,  # Limit the number of new tokens generated\n",
        "        num_return_sequences=1,\n",
        "        no_repeat_ngram_size=2,\n",
        "        do_sample=True,\n",
        "        top_k=50,\n",
        "        top_p=0.95,\n",
        "        temperature=0.7,\n",
        "        early_stopping=True\n",
        "    )\n",
        "\n",
        "    # Decode the generated text\n",
        "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    # Extract and return the generated suggestion\n",
        "    improvement_suggestion = generated_text.split(\"Suggestion:\")[-1].strip().split('\\n')[0]\n",
        "    return improvement_suggestion\n",
        "suggestions = []\n",
        "# Example usage with DataFrame\n",
        "for index, row in df.iterrows():\n",
        "    feedback = row['lemmatized_text']\n",
        "    category = row['label']\n",
        "    suggestion = generate_improvement_suggestion(feedback, category)\n",
        "    print(f\"Feedback: {feedback}\\nCategory: {category}\\nGenerated Suggestion: {suggestion}\\n\")\n",
        "    suggestions.append(suggestion)\n",
        "\n",
        "# Add the suggestions to the DataFrame\n",
        "df['suggestions'] = suggestions\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YqUI8wTFf17k"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "AYBl0y6wtWC5",
        "aLUxEWVVJ58b",
        "js5JlvBxKFU5",
        "7B4qUbCEKKm8",
        "Xt5iq8tWKTLd",
        "JINM-go0fhgy",
        "Os5nM01J9Jtp",
        "gyLT5rT5N6vM",
        "eudRmPpw5qmD",
        "cQ3u1GoWnQf5",
        "q40WgXeKjegq"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "11fcd5eb3a164d8398e8b5cd689152f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a8a8b7c789b74a41a8d39f83421a31c5",
              "IPY_MODEL_3bb6f019591549cfa50e361fd62f2017",
              "IPY_MODEL_aab5373c0fc4462ab509cfecc493f93c"
            ],
            "layout": "IPY_MODEL_5a0369bbb7764d1795843ce3050a4727"
          }
        },
        "a8a8b7c789b74a41a8d39f83421a31c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98448f8d03494b44a3f01ce4418408c3",
            "placeholder": "​",
            "style": "IPY_MODEL_cf1122f71ea4460896d1e09d890a66bf",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "3bb6f019591549cfa50e361fd62f2017": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c50728bd76764232b0fc3413f1076635",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6ee6fa3f7c364f80b06aa825bbfa00a6",
            "value": 48
          }
        },
        "aab5373c0fc4462ab509cfecc493f93c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c263ca7759284c68a90678dc0d350fae",
            "placeholder": "​",
            "style": "IPY_MODEL_35b39dfbbb7e4164bd17c457079f02e9",
            "value": " 48.0/48.0 [00:00&lt;00:00, 1.20kB/s]"
          }
        },
        "5a0369bbb7764d1795843ce3050a4727": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98448f8d03494b44a3f01ce4418408c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf1122f71ea4460896d1e09d890a66bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c50728bd76764232b0fc3413f1076635": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ee6fa3f7c364f80b06aa825bbfa00a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c263ca7759284c68a90678dc0d350fae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35b39dfbbb7e4164bd17c457079f02e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "00fd311ce31d41dfae0b4fa0242425dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f1c8500613934a3dbbbad2811ca307b7",
              "IPY_MODEL_fce807fad99a4e8789b68639d813a476",
              "IPY_MODEL_1f7560833d314ee4872c3d621f464f3e"
            ],
            "layout": "IPY_MODEL_5cde719b74d04ca5b28aecc8a8c7b3d8"
          }
        },
        "f1c8500613934a3dbbbad2811ca307b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5476fbd21e6f430ea241e6a689f28071",
            "placeholder": "​",
            "style": "IPY_MODEL_482f74db1e27450c9f4a1bc305c429bd",
            "value": "vocab.txt: 100%"
          }
        },
        "fce807fad99a4e8789b68639d813a476": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_500203697f644b19ab3479f86b4adbc2",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b92bb4853b814a44ae886bc83d48f830",
            "value": 231508
          }
        },
        "1f7560833d314ee4872c3d621f464f3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f60b5c2649940c4849356ba3e549ae4",
            "placeholder": "​",
            "style": "IPY_MODEL_e4b31b75c90745e6a4e45ff2bfbddd1c",
            "value": " 232k/232k [00:00&lt;00:00, 6.07MB/s]"
          }
        },
        "5cde719b74d04ca5b28aecc8a8c7b3d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5476fbd21e6f430ea241e6a689f28071": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "482f74db1e27450c9f4a1bc305c429bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "500203697f644b19ab3479f86b4adbc2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b92bb4853b814a44ae886bc83d48f830": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5f60b5c2649940c4849356ba3e549ae4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4b31b75c90745e6a4e45ff2bfbddd1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6d29348bf06645caaebacd0a6988aad9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3a6a2587957d41fc81efc0b837aae68c",
              "IPY_MODEL_f4a01f27634b4ecca416a7bdf64f84ce",
              "IPY_MODEL_95f2e7e6821c42c2a0a49aad175a5c40"
            ],
            "layout": "IPY_MODEL_fabad275643a4fdba74051f38945d96b"
          }
        },
        "3a6a2587957d41fc81efc0b837aae68c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1df0cfb7cbdd4d3296942e1f68594286",
            "placeholder": "​",
            "style": "IPY_MODEL_74dffccac0cc4d3a8a15f0b458438986",
            "value": "tokenizer.json: 100%"
          }
        },
        "f4a01f27634b4ecca416a7bdf64f84ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7723362f60e40c9a8ab81d076f9c9d9",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_11b6a95aa5de4960b3e30825b321bd2f",
            "value": 466062
          }
        },
        "95f2e7e6821c42c2a0a49aad175a5c40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80bebc4f0a4d4801aaaaf65ecc579dad",
            "placeholder": "​",
            "style": "IPY_MODEL_53d7e28507554d7badcb4f9dffe240ea",
            "value": " 466k/466k [00:00&lt;00:00, 10.8MB/s]"
          }
        },
        "fabad275643a4fdba74051f38945d96b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1df0cfb7cbdd4d3296942e1f68594286": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74dffccac0cc4d3a8a15f0b458438986": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e7723362f60e40c9a8ab81d076f9c9d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11b6a95aa5de4960b3e30825b321bd2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "80bebc4f0a4d4801aaaaf65ecc579dad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53d7e28507554d7badcb4f9dffe240ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6154eb9739674748962fc8f348fc4b1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0ef6b06574db44fa84c37758458bb241",
              "IPY_MODEL_33b46c7e03bf4fdcb2dd8c758ca860ae",
              "IPY_MODEL_d73b16f6164048dca85665551beae33e"
            ],
            "layout": "IPY_MODEL_ff07e102ae6e471dbe6d923d36d0db60"
          }
        },
        "0ef6b06574db44fa84c37758458bb241": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc8c4ff3c52b4c38885f5532c14e59e7",
            "placeholder": "​",
            "style": "IPY_MODEL_4513cc60ac4a4b8f97eb6296e8306ea3",
            "value": "config.json: 100%"
          }
        },
        "33b46c7e03bf4fdcb2dd8c758ca860ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56286267b48840f2977ef1313679eb62",
            "max": 571,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_487462ff3de54c829ffbc480d76d1f2d",
            "value": 571
          }
        },
        "d73b16f6164048dca85665551beae33e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d86cef952dc41d0ba18f14b904149ed",
            "placeholder": "​",
            "style": "IPY_MODEL_765c5ca1651f4dfb90f2a88d09fd4e83",
            "value": " 571/571 [00:00&lt;00:00, 30.7kB/s]"
          }
        },
        "ff07e102ae6e471dbe6d923d36d0db60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc8c4ff3c52b4c38885f5532c14e59e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4513cc60ac4a4b8f97eb6296e8306ea3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "56286267b48840f2977ef1313679eb62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "487462ff3de54c829ffbc480d76d1f2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2d86cef952dc41d0ba18f14b904149ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "765c5ca1651f4dfb90f2a88d09fd4e83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5efee83e7fbf498ba8989a53e1c3196d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f1e1fb16d78f4beab82a8ea8d599b8c8",
              "IPY_MODEL_cfe430ddd65c45a09dc11053f21547bd",
              "IPY_MODEL_e7d2807e4c224312b9e0e54bec8b5e85"
            ],
            "layout": "IPY_MODEL_6ab45337868b4e24ac3872aa0e01f720"
          }
        },
        "f1e1fb16d78f4beab82a8ea8d599b8c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4fb7ee4efa644dcf81897ae9519833d5",
            "placeholder": "​",
            "style": "IPY_MODEL_4a8367e13bdb4575b7bac8b14fe9d346",
            "value": "model.safetensors: 100%"
          }
        },
        "cfe430ddd65c45a09dc11053f21547bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_161f3317ff974e99951ab24f38a3eb7f",
            "max": 1344951957,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dcdfb973d6cf4540b514566ea0d53b56",
            "value": 1344951957
          }
        },
        "e7d2807e4c224312b9e0e54bec8b5e85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f356c26b2dec4b829e07c9b2b33ccf85",
            "placeholder": "​",
            "style": "IPY_MODEL_30d7c7f9ab314f5b9af6a1b3b76d24d7",
            "value": " 1.34G/1.34G [00:12&lt;00:00, 174MB/s]"
          }
        },
        "6ab45337868b4e24ac3872aa0e01f720": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4fb7ee4efa644dcf81897ae9519833d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a8367e13bdb4575b7bac8b14fe9d346": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "161f3317ff974e99951ab24f38a3eb7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dcdfb973d6cf4540b514566ea0d53b56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f356c26b2dec4b829e07c9b2b33ccf85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30d7c7f9ab314f5b9af6a1b3b76d24d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2216b99bbf6f43689a444ed8365a7828": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ab09dde0d4fa46ad9dbe5fac8156a97c",
              "IPY_MODEL_d00a485fa5894e178fb784e4181b8adf",
              "IPY_MODEL_efb9fd467dd04298b6cf0786d790600e"
            ],
            "layout": "IPY_MODEL_c9738764a7bb492c8aa893f9d145bd3a"
          }
        },
        "ab09dde0d4fa46ad9dbe5fac8156a97c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_813daa86bad94254a5fd72b67ea53e1f",
            "placeholder": "​",
            "style": "IPY_MODEL_6382122cf3fe4d8495770d63e5e83d23",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "d00a485fa5894e178fb784e4181b8adf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79f0a99cee0e4afa8ac5bdb5d22e444b",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cf3a2075c64a4ccfa4c2abd6ebe75c60",
            "value": 48
          }
        },
        "efb9fd467dd04298b6cf0786d790600e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_401e4bf5816a4e22a7a01af92e58d367",
            "placeholder": "​",
            "style": "IPY_MODEL_ade50622339143e2beb6c976f8a8e5cf",
            "value": " 48.0/48.0 [00:00&lt;00:00, 3.32kB/s]"
          }
        },
        "c9738764a7bb492c8aa893f9d145bd3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "813daa86bad94254a5fd72b67ea53e1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6382122cf3fe4d8495770d63e5e83d23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "79f0a99cee0e4afa8ac5bdb5d22e444b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf3a2075c64a4ccfa4c2abd6ebe75c60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "401e4bf5816a4e22a7a01af92e58d367": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ade50622339143e2beb6c976f8a8e5cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9cb2372a06b54df18af74108572c412c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f3661b9b87ec4c57b5842608bb588e0a",
              "IPY_MODEL_d9f0e3a4ac6e4116a71a2da490af2798",
              "IPY_MODEL_91661b4586d242ce9274731c81bc3e68"
            ],
            "layout": "IPY_MODEL_624f361203b3445a88d7f61600b9f94b"
          }
        },
        "f3661b9b87ec4c57b5842608bb588e0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b47b6228b3e84b3d819ee941fa37fb63",
            "placeholder": "​",
            "style": "IPY_MODEL_cfe428c12adc4a46b4b712e36ebb3347",
            "value": "vocab.txt: 100%"
          }
        },
        "d9f0e3a4ac6e4116a71a2da490af2798": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f9bc17b491c408ab969499f309de11d",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_24b8ae1771a0402d9d5826250053b7d0",
            "value": 231508
          }
        },
        "91661b4586d242ce9274731c81bc3e68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81fda0ba2e724baeb91506881d7aedf4",
            "placeholder": "​",
            "style": "IPY_MODEL_fdeb6b5811b74c98b507aac363ac8a48",
            "value": " 232k/232k [00:00&lt;00:00, 3.43MB/s]"
          }
        },
        "624f361203b3445a88d7f61600b9f94b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b47b6228b3e84b3d819ee941fa37fb63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfe428c12adc4a46b4b712e36ebb3347": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1f9bc17b491c408ab969499f309de11d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24b8ae1771a0402d9d5826250053b7d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "81fda0ba2e724baeb91506881d7aedf4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fdeb6b5811b74c98b507aac363ac8a48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a9590a7961a94518a35eb56317a65fad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d73a0c8f096b425989ead4fbd4f79e3e",
              "IPY_MODEL_200ffb06266247d4bb010a69f6e22cc1",
              "IPY_MODEL_946eb9f1a177417187a9e83152b3dc63"
            ],
            "layout": "IPY_MODEL_401a7972c9a44838b78d6cd4c54f696a"
          }
        },
        "d73a0c8f096b425989ead4fbd4f79e3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d6df94a64a844a78ad271fc2d92ddf9",
            "placeholder": "​",
            "style": "IPY_MODEL_9a9e8246cbef4584a0f40af4276b70bc",
            "value": "tokenizer.json: 100%"
          }
        },
        "200ffb06266247d4bb010a69f6e22cc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_74e4685a3ea743ffb0fbfa8f81c118e2",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b94f5dc6f0fb47e0a77c5a2994b3c0d4",
            "value": 466062
          }
        },
        "946eb9f1a177417187a9e83152b3dc63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_914f7bcd6fa6473a9b656c4af92f5d17",
            "placeholder": "​",
            "style": "IPY_MODEL_449c8cd468c544308b6d7b7efa8e6220",
            "value": " 466k/466k [00:00&lt;00:00, 2.51MB/s]"
          }
        },
        "401a7972c9a44838b78d6cd4c54f696a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d6df94a64a844a78ad271fc2d92ddf9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a9e8246cbef4584a0f40af4276b70bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "74e4685a3ea743ffb0fbfa8f81c118e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b94f5dc6f0fb47e0a77c5a2994b3c0d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "914f7bcd6fa6473a9b656c4af92f5d17": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "449c8cd468c544308b6d7b7efa8e6220": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dbdabe547d4e47f5b446015c5368fe6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e8d8acced74d40cca6913077bb7dc701",
              "IPY_MODEL_8c03caaf6aa240069ed85ad842576e08",
              "IPY_MODEL_250fcd9181c54a66a163edb43e63ed4d"
            ],
            "layout": "IPY_MODEL_2ed14f68a18540f78e8ee3b972d92ecf"
          }
        },
        "e8d8acced74d40cca6913077bb7dc701": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75131d08e7474c7fae77f388a580e62e",
            "placeholder": "​",
            "style": "IPY_MODEL_f17a6a71d5214fd8b492424313a8af9e",
            "value": "config.json: 100%"
          }
        },
        "8c03caaf6aa240069ed85ad842576e08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be7bed1fde8d4702acbf4d40e298ac90",
            "max": 571,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_42d73cea32b84637b3165f3c94e0cead",
            "value": 571
          }
        },
        "250fcd9181c54a66a163edb43e63ed4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ad9e09693764941b40d23e1f02f6a32",
            "placeholder": "​",
            "style": "IPY_MODEL_b17b7986ec9f4313876104cc5122c2bf",
            "value": " 571/571 [00:00&lt;00:00, 25.1kB/s]"
          }
        },
        "2ed14f68a18540f78e8ee3b972d92ecf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75131d08e7474c7fae77f388a580e62e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f17a6a71d5214fd8b492424313a8af9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "be7bed1fde8d4702acbf4d40e298ac90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42d73cea32b84637b3165f3c94e0cead": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3ad9e09693764941b40d23e1f02f6a32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b17b7986ec9f4313876104cc5122c2bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1c0c222658f448b78e268a9426a93c49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c92fff3cd44f410bb4e7a54368a96d34",
              "IPY_MODEL_c1030ad924d04666aa9cf9cbf940e7bc",
              "IPY_MODEL_cc9e1d495cb44b27b3ce2506b80626d0"
            ],
            "layout": "IPY_MODEL_70ee65d8dcf24da49e56e7aa2fa190f0"
          }
        },
        "c92fff3cd44f410bb4e7a54368a96d34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_150446e344764082a3bd511d0b77662f",
            "placeholder": "​",
            "style": "IPY_MODEL_78768c77f073478ca3d5befcb4d4ec90",
            "value": "model.safetensors: 100%"
          }
        },
        "c1030ad924d04666aa9cf9cbf940e7bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a8126da8ac214474a699e70f54d1a9dc",
            "max": 1344951957,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_74ea9099471d4d6a8dd02015865a5de6",
            "value": 1344951957
          }
        },
        "cc9e1d495cb44b27b3ce2506b80626d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc843da3e09d4d0ba8ff05378b33ab24",
            "placeholder": "​",
            "style": "IPY_MODEL_6e490a9989d4433984938a552071b802",
            "value": " 1.34G/1.34G [00:09&lt;00:00, 244MB/s]"
          }
        },
        "70ee65d8dcf24da49e56e7aa2fa190f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "150446e344764082a3bd511d0b77662f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78768c77f073478ca3d5befcb4d4ec90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a8126da8ac214474a699e70f54d1a9dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74ea9099471d4d6a8dd02015865a5de6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bc843da3e09d4d0ba8ff05378b33ab24": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e490a9989d4433984938a552071b802": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}